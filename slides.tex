\documentclass{beamer} 

\usepackage{hayesmacros}

\usetheme{metropolis}
\setsansfont{Fira Sans}  % be sure to compile with XeLaTeX

\usepackage{natbib}
\usepackage{ulem}
\usepackage{fontawesome5}

\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\setbeamercolor{background canvas}{bg=white}
\setbeamercolor{normal text}{fg=black}
\setbeamercolor{frametitle}{bg=black, fg=white}

\hypersetup{colorlinks,citecolor=cyan, urlcolor=cyan, linkcolor=black}

\title{Estimating network-mediated causal effects via spectral embeddings}
\date{2022-10-14}
\author{Alex Hayes}
\institute{University of Wisconsin-Madison}


\begin{document}

\maketitle

\begin{frame}{Motivating example}

    \begin{columns}

        \column{0.4 \textwidth}

        \textbf{Do age and access to spending money cause adolescents to drink \faIcon{beer}?}

        \column{0.6 \textwidth}

        Data

        \begin{itemize}
            \item Social network of 129 adolescents in secondary school in Glasgow, measured in 1995
            \item Spending money available to each adolescent
            \item Smoking (tobacco \& marijuana) and drinking behaviors
            \item Many potential controls
        \end{itemize}

    \end{columns}

\end{frame}

\begin{frame}
    \centering
    \vspace{3mm}
    \begin{figure}
        \includegraphics[width=\textwidth]{figures/glasgow-degree.png}
    \end{figure}

\end{frame}

\begin{frame}
    \centering
    \vspace{3mm}
    \begin{figure}
        \includegraphics[width=\textwidth]{figures/glasgow-friendgroups.png}
    \end{figure}
\end{frame}


\begin{frame}{Stochastic blockmodels (SBMs)}

    \begin{columns}
        \column{0.45\textwidth}

        \begin{figure}
            \includegraphics[width=\textwidth]{figures/assortative.png}
        \end{figure}

        \column{0.55\textwidth}

        $d$ ``blocks'' or communities

        $Z_{i \cdot} \in \set{0, 1}^d$ one-hot indicator of node $i$'s block

        \vspace{4mm}

        $Z$ is latent (i.e. unobserved)

        \vspace{4mm}

        $B \in [0, 1]^{d \times d}$ inter-block edge probabilities

        $\P[Z]{A_{ij} = 1} = Z_{i \cdot} B Z_{j \cdot}^T$

    \end{columns}

\end{frame}

\begin{frame}{Stochastic blockmodels are good for intuition}

    ...but they do not encode a rich notion of homophily. SBMs can be extended:

    \begin{itemize}
        \item Differing node popularity
        \item Membership in multiple groups
        \item Partial memberships in groups
        \item Membership in multiple groups with group-specific popularity
        \item Etc, etc
    \end{itemize}

    All of these extensions can be captured in a more general model

\end{frame}

\begin{frame}{Sub-gamma random dot product graphs}

    \begin{definition}

        Let $A \in \R^{n \times n}$ be a random symmetric matrix, such as the adjacency matrix of an undirected graph. Let $\E[\X]{A} = \X \X^T$ be the expectation of $A$ conditional on $\X \in \R^{n \times d}$, which has independent and identically distributed rows $\X_{1 \cdot}, \dots, \X_{n \cdot}$. Conditional on $\X$, the elements of the upper triangle of $A - \E[\X]{A}$ are $(\nu_n, b_n)$-subgamma random variables.

    \end{definition}

    \textbf{Intuition}: the \emph{latent positions} $\X$ are very rich measures of community membership and node identity that live in $\R^d$

\end{frame}

\begin{frame}{Sub-gamma random dot product graphs}

    \begin{remark}
        We consider symmetric positive semi-definite $\E[\X]{A}$ to simplify notation, but everything works for generic $\E[\X]{A}$.

        This implies possible applications to spatial networks, text data, psychometric surveys, imaging data, and omics panels.
    \end{remark}

    \begin{remark}
        $\X$ is only identifiable up to orthogonal transformation, since $\E[\X]{A} = \X \X^T = (\X Q) (\X Q)^T$ for any $d \times d$ orthogonal matrix $Q$.
    \end{remark}

\end{frame}

\begin{frame}{Estimation via the adjacency spectral embedding}


    \begin{definition}[ASE]

        Given a network $A$, the $\widehat{d}$-dimensional \emph{adjacency spectral embedding} of $A$ is

        \begin{align*}
            \Xhat = \Uhat \Shat^{1/2}
        \end{align*}

        \noindent where $\Uhat \Shat \Uhat^T$ is the rank-$\widehat{d}$ truncated singular value decomposition of $A$.

    \end{definition}

    The analyst must specify $\widehat{d}$

\end{frame}

\begin{frame}{Uniform consistency of the adjacency spectral embedding}

    \begin{lemma}[\cite{levin_recovering_2022}]

        Under the sub-gamma random dot product model and some additional omitted conditions, if $\widehat{d} = d$, there is some $d \times d$ orthogonal matrix $Q$ such that

        \begin{equation*}
            \max_{i \in [n]} \, \norm*{\Xhat_{i \cdot} - \X_{i \cdot} Q} = \op{1}.
        \end{equation*}

    \end{lemma}

\end{frame}

\section{Behavior that varies over a network}

\begin{frame}{Notation}
    \begin{columns}
        \column{0.45\textwidth}

        \begin{figure}
            \includegraphics[width=\textwidth]{figures/assortative.png}
        \end{figure}

        \column{0.55\textwidth}

        Network $A \in \R^{n \times n}$

        Latent positions $\X_{1 \cdot}, ..., \X_{n \cdot} \in \R^d$

        Nodal covariates $\W_{1 \cdot}, ..., \W_{n \cdot} \in \R^{p}$

        Nodal outcomes $Y_1, ..., Y_n \in \R$

        \vspace{6mm}

        Partition $\W_i = (T_i, \C_{i \cdot})$

        Treatment $T_i \in \set{0, 1}$

        Controls $\C_{i \cdot} \in \R^{p'}$

    \end{columns}
\end{frame}

\begin{frame}{A regression model for latent position}

    Idea: interventions $T_i$ can cause community membership $\X_{i \cdot}$

    \begin{align*}
        \underbrace{\E[T_i, \C_{i \cdot}]{\X_{i \cdot}}}_{\R^{1 \times d}}
         & = \underbrace{\thetazero}_{\R^{1 \times d}}
        + \underbrace{T_i}_{\{0, 1\}} \underbrace{\thetat}_{\R^{1 \times d}}
        + \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\Thetac}_{\R^{p' \times d}}
        + \underbrace{T_i}_{\{0, 1\}} \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\Thetatc}_{\R^{p' \times d}}.
    \end{align*}

    Example: I like frisbee so I joined an ultimate frisbee team (MUFA) and am likely to form connections to other frisbee players

\end{frame}

\begin{frame}{A regression model for outcomes}

    Idea: community membership $\X_{i \cdot}$ can cause outcomes $Y_i$

    \begin{align*}
        \underbrace{\E[T_i, \C_{i \cdot}, \X_{i \cdot}]{Y_i}}_{\R}
         & = \underbrace{\betazero}_{\R}
        + \underbrace{T_i}_{\{0, 1\}} \underbrace{\betat}_{\R}
        + \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\betac}_{\R^{p'}}
        + \underbrace{\X_{i \cdot}}_{\R^{1 \times d}} \underbrace{\betax}_{\R^d}
    \end{align*}

    Example: I'm on a frisbee team, and the frisbee team goes to the Great Dane together after each game

\end{frame}

\begin{frame}{Some hints at where the causal stuff is going}

    The network \emph{mediates} the relationship between treatments $T_i$ and outcomes $Y_i$

    \begin{itemize}
        \item I like frisbee, and this might cause me to go the Great Dane more or less often, independent of my friends. This is a \emph{direct effect}
        \item I like frisbee, which causes me to be on a frisbee team, which in term causes me to go the Great Dane with my frisbee team. This is an \emph{indirect effect}
        \item The total effect of liking frisbee is some combination of the direct and indirect effect
    \end{itemize}

\end{frame}

\begin{frame}{Causal estimands}

    \textbf{Warning:} slight change in notation. Now we consider a single node, and let $Y_{t x}$ denote a counterfactual.

    \begin{itemize}
        \item \emph{Average treatment effect}: how much the outcome $Y$ would change on average if the treatment $T$ were changed from $T = t$ to $T = t^*$

              \begin{equation*}
                  \ate = \E{Y_t - Y_{t^*}}
              \end{equation*}

        \item \emph{Controlled direct effect}: how much the outcome $Y$ would change on average if the mediator $\X$ were fixed at level $x$ uniformly in the population, but the treatment were changed from $T = t$ to $T = t^*$

              \begin{equation*}
                  \cde = \E{Y_{t \, x} - Y_{t^* \, x}}
              \end{equation*}

    \end{itemize}

\end{frame}

\begin{frame}{Causal estimands}

    \begin{itemize}
        \item \emph{Natural direct effect}: how much the outcome $Y$ would change if the exposure $T$ were set at level $T = t^*$ versus $T = t$ but for each individual the mediator $\X$ were kept at the level it would have taken, for that individual, if $T$ had been set to $t^*$

              \begin{equation*}
                  \nde = \E{Y_{t \, \X_{t^*}} - Y_{t^* \, \X_{t^*}}}
              \end{equation*}

        \item Captures the effect of the exposure on the outcome that would remain if we were to disable the pathway from the exposure to the mediator

    \end{itemize}

\end{frame}

\begin{frame}{Causal estimands}

    \begin{itemize}
        \item \emph{Natural indirect effect}: how much the outcome $Y$ would change on average if the exposure were fixed at level $T = t^*$ but the mediator $\X$ were changed from the level it would take if $T = t$ to the level it would take if $T = t^*$

              \begin{equation*}
                  \nie = \E{Y_{t \, \X_{t}} - Y_{t \, \X_{t^*}}}
              \end{equation*}

        \item Captures the effect of the exposure on the outcome that operates by changing the mediator
    \end{itemize}

    \begin{equation*}
        \ate = \nde + \nie
    \end{equation*}

\end{frame}

\begin{frame}{Causal identification in the frisbee example}

    \centering

    \begin{figure}
        \includegraphics[width=1.2\textwidth]{figures/great-dane.pdf}
        \caption{Directed acyclic graph (DAG) for node $i$. Portions of the DAG corresponding to nodes $j \neq i$ are omitted. Social identities are latent.}
        \label{fig:great-dane}
    \end{figure}

\end{frame}

\begin{frame}{Causal identification more generally}

    \centering

    \begin{figure}
        \includegraphics[width=0.9\textwidth]{figures/mediating.png}
        \caption{Directed acyclic graph (DAG) for node $i$. Portions of the DAG corresponding to nodes $j \neq i$ are omitted. $\X_i$ and $\X_j$ are not observed.}
        \label{fig:mediating}
    \end{figure}

\end{frame}



\begin{frame}{Semi-parametric causal identification}

    Recall the regression models:

    \begin{equation*}
        \begin{aligned}
            \underbrace{\E[T_i, \C_{i \cdot}, \X_{i \cdot}]{Y_i}}_{\R}
             & = \underbrace{\betazero}_{\R}
            + \underbrace{T_i}_{\{0, 1\}} \underbrace{\betat}_{\R}
            + \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\betac}_{\R^{p'}}
            + \underbrace{\X_{i \cdot}}_{\R^{1 \times d}} \underbrace{\betax}_{\R^d}, \\
            \underbrace{\E[T_i, \C_{i \cdot}]{\X_{i \cdot}}}_{\R^{1 \times d}}
             & = \underbrace{\thetazero}_{\R^{1 \times d}}
            + \underbrace{T_i}_{\{0, 1\}} \underbrace{\thetat}_{\R^{1 \times d}}
            + \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\Thetac}_{\R^{p' \times d}}
            + \underbrace{T_i}_{\{0, 1\}} \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\Thetatc}_{\R^{p' \times d}}.
        \end{aligned}
    \end{equation*}

    Then:

    \begin{align*}
        \cdef & = \ndef = \paren*{t - t^*} \, \betat                                                \\
        \nief & = \paren*{t - t^*} \, \thetat \, \betax + (t - t^*) \, \mu_c \, \Thetatc \, \betax.
    \end{align*}

\end{frame}


\begin{frame}{Regression estimators}

    \textbf{Challenge}: regression models depend on $\X$, but we only have an estimate $\Xhat$.

    \vspace{3mm}

    Turns out this is fine. Let $\Dhat = \begin{bmatrix} \W & \Xhat \end{bmatrix} \in \mathbb{R}^{n \times (p + d)}$. We estimate $\betaw$ and $\betax$ via ordinary least squares as follows

    \begin{align*}
        \begin{bmatrix}
            \betawhat \\
            \betaxhat
        \end{bmatrix}
         & = \paren*{\Dhat^T \Dhat}^{-1} \Dhat^T Y \\
        \Thetahat
         & = \paren*{\W^T \W}^{-1} \W^T \Xhat.
    \end{align*}
\end{frame}

\begin{frame}{Causal estimators}

    To estimate $\nde$ and $\nie$ in our semi-parametric setting, we combine regression coefficients from the network regression models:

    \begin{align*}
        \cdehat & = \ndehat = \paren*{t - t^*} \, \betathat                                                                              & \text{and} \\
        \niehat & = \paren*{t - t^*} \, \thetathat \, \betaxhat + \paren*{t - t^*} \cdot \widehat{\mu}_c \cdot \Thetatchat \, \betaxhat.
    \end{align*}

    It's standard to fit two regressions and multiply coefficients to estimate an indirect effect like this \citep{vanderweele_mediation_2014}.

\end{frame}


\begin{frame}{Main statistical result}

    \begin{theorem}[Regression coefficients are asymptotically normal]

        \vspace{2mm}

        Under some mild assumptions

        \begin{equation*}
            \begin{aligned}
                \sqrt{ n } \,
                 & \Sigmahatbeta^{-1/2}
                \begin{pmatrix}
                    \betawhat - \betaw \\
                    Q \, \betaxhat - \betax
                \end{pmatrix}
                \to
                \Normal{0}{I_d}, and     \\
                \sqrt{ n } \,
                 & \Sigmahattheta^{-1/2}
                \begin{pmatrix}
                    \vecc \paren*{\Thetahat \, Q^T} - \Thetavec
                \end{pmatrix}
                \to
                \Normal{0}{I_{p d}}.
            \end{aligned}
        \end{equation*}

        \noindent where $\Sigmahattheta^{-1/2}$ and $\Sigmahatbeta^{-1/2}$ are the robust covariance estimators based on $(\Dhat, Y, \betahat)$ and $(\W, \Xhat, \Thetahat)$, respectively.
    \end{theorem}
\end{frame}

\begin{frame}{Main causal result}

    \begin{theorem}[Causal estimators are asymptotically normal]

        \vspace{2mm}

        Under the same statistical assumptions as before, plus mediating homophily,

        \begin{align*}
            \sqrt{n \, \sigmahatnde} \paren*{\ndehat - \nde}
             & \to
            \Normal{0}{1}, \text { and } \\
            \sqrt{n \, \sigmahatnie} \paren*{\niehat - \nie}
             & \to
            \Normal{0}{1}.
        \end{align*}

        \noindent where $\sigmahatnde$ and $\sigmahatnie$ are rather unfriendly variance estimators derived via the delta method and the previous theorem.

    \end{theorem}

\end{frame}

\begin{frame}
    \centering
    \vspace{3mm}
    \begin{figure}
        \includegraphics[width=\textwidth]{figures/glasgow-alcohol.png}
    \end{figure}
\end{frame}

\begin{frame}
    \centering
    \vspace{3mm}
    \begin{figure}
        \includegraphics[width=\textwidth]{figures/glasgow-estimates.png}
    \end{figure}
\end{frame}


\begin{frame}{Thank you! Questions?}

    \textbf{Follow-up work we're interested in}

    \begin{itemize}
        \item Better identifiability via varimax rotation
        \item Extension to GLMs
        \item Accommodating network interference
    \end{itemize}

    Contact me if you'd like to work on any of these!

    \begin{itemize}
        \item[] \faIcon{twitter} \href{https://twitter.com/alexpghayes}{@alexpghayes}
        \item[] \faIcon{inbox} \href{mailto:alex.hayes@wisc.edu}{alex.hayes@wisc.edu}
        \item[] \faIcon{dice-four} \url{https://www.alexpghayes.com}
    \end{itemize}

\end{frame}


\section{Appendix}

\begin{frame}{Choosing $\widehat{d}$: overestimating the embedding dimension is fine}

    \centering

    \begin{figure}
        \includegraphics[width=\textwidth]{figures/misspecification/block2_normal_misspecification_loss_average.png}
    \end{figure}

\end{frame}

\begin{frame}{A more natural parameterization for the regressions}

    $\X$ is not the most intuitive way to parameterize a blockmodel. Suppose that $Z \in \R^{n \times d}$ and $B \in \R^{d \times d}$ are arbitrary full-rank matrices such that $\E[Z, B]{A} = Z B Z^T$. If

    \begin{align*}
        \Z = W \Theta' + \xi',                     \qquad \text{ and } \qquad
        Y  = W \betaw + Z \betaz + \varepsilon'
    \end{align*}

    \noindent then there exist $\Theta, \betax, \xi, \varepsilon$ such that

    \begin{align*}
        \X = W \Theta + \xi,                     \qquad \text{ and } \qquad
        Y  = W \betaw + \X \betax + \varepsilon.
    \end{align*}

\end{frame}

\begin{frame}{Interference and contagion}

    Interference and contagion effects are allowed \emph{so long as they happen in the latent space}. Suppose

    \begin{align*}
        \E[\W_{i \cdot}, \X_{i \cdot}]{Y_i}
        = \W_{i \cdot} \betaw + \X_{i \cdot} \beta'_\text{x} + \delta_\text{y} \sum_{j} \X_{i \cdot}^T \X_{j \cdot} Y_j
    \end{align*}

    This latent space contagion model is a special parametric case of the regression outcome model (take $\betax = \beta'_\text{x} + \X^T Y \delta_\text{y}$).

\end{frame}



% \begin{frame}{Overcontrol bias}

%     TODO: include result from Appendix of paper

% \end{frame}

\begin{frame}{Identifying assumptions}

    We require that natural direct and indirect effects are identified, as follows from consistency, positivity, and sequential ignorability \citep{imai_identification_2010}.

    \begin{itemize}

        \item Consistency:

              \begin{equation*}
                  \begin{aligned}
                       & \text{if $T = t$, then $\X_t = X$ with probability 1, and}               \\
                       & \text{if $T = t$ and $\X = x$, then $Y_{t \, x} = Y$ with probability 1}
                  \end{aligned}
              \end{equation*}

        \item Positivity:

              \begin{equation*}
                  \begin{aligned}
                      \P[T, \C]{x} & > 0 \text{ for each }  x \in \supp(\X) \\
                      \P[\C]{t}    & > 0 \text{ for each }  t \in \supp(T)
                  \end{aligned}
              \end{equation*}

    \end{itemize}

\end{frame}

\begin{frame}{Identifying assumptions}

    \begin{itemize}

        \item Sequential ignorability:

              \begin{equation*}
                  \begin{aligned}
                      \set{Y_{t^* \, x}, \X_t} \indep T & \cond \C        \\
                      \set{Y_{t^* \, x}} \indep \X      & \cond T = t, \C
                  \end{aligned}
              \end{equation*}

    \end{itemize}

    This is a criminally strong assumption, in all honesty. Requires the mediator $\X$ to be unconfounded with the outcome $Y$.

\end{frame}


\begin{frame}{Interventions on a network}

    \begin{figure}
        \includegraphics[width=\textwidth]{figures/intervention.pdf}
        \caption{Canonical intervention when $\C$ is highly informative.}
        \label{fig:intervention}
    \end{figure}
\end{frame}

\begin{frame}{Interventions on a network}

    \begin{align*}
        \underbrace{\E[T_i, \C_{i \cdot}]{\Z_{i \cdot}}}_{\R^{1 \times d}}
         & = \underbrace{\thetazero}_{\R^{1 \times d}}
        + \underbrace{T_i}_{\{0, 1\}} \underbrace{\thetat}_{\R^{1 \times d}}
        + \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\Thetac}_{\R^{p' \times d}}
        + \underbrace{T_i}_{\{0, 1\}} \underbrace{\C_{i \cdot}}_{\R^{1 \times p'}} \underbrace{\Thetatc}_{\R^{p' \times d}}.
    \end{align*}

    In Figure \ref{fig:intervention}, $\C$ are latent parameters for a DC-SBM and $\thetazero = \vec 0, \thetat = \vec 0, \Thetac = I_k$ and

    \begin{align*}
        \Thetatc =
        \begin{bmatrix}
            -1 & 2 & 0  & 0 & 0 \\
            0  & 0 & 0  & 0 & 0 \\
            0  & 1 & -1 & 0 & 0 \\
            0  & 0 & 0  & 0 & 0 \\
            0  & 0 & 0  & 0 & 0 \\
        \end{bmatrix}
    \end{align*}
\end{frame}

\begin{frame}{Interventions allowed}

    Provided that controls $\C_{i \cdot}$ are sufficiently informative about group membership $\X_{i \cdot}$, treatment $T_i$ is allowed to cause:

    \begin{itemize}
        \item Changes in popularity within a group
        \item Movement to a new friend group
        \item Becoming a member of a new friend group while remaining in current friend group
        \item Friendships becoming more or less likely between distinct friend groups
        \item Combinations of the above
    \end{itemize}

\end{frame}

\bibliographystyle{chicago}
\bibliography{references}

\end{document}
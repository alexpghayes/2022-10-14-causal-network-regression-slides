
@inproceedings{10.1007/978-3-540-77004-6_11,
  title = {Random Dot Product Graph Models for Social Networks},
  booktitle = {Algorithms and Models for the Web-Graph},
  author = {Young, Stephen J. and Scheinerman, Edward R.},
  editor = {Bonato, Anthony and Chung, Fan R. K.},
  year = {2007},
  pages = {138--149},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  abstract = {Inspired by the recent interest in combining geometry with random graph models, we explore in this paper two generalizations of the random dot product graph model proposed by Kraetzl, Nickel and Scheinerman, and Tucker [1,2]. In particular we consider the properties of clustering, diameter and degree distribution with respect to these models. Additionally we explore the conductance of these models and show that in a geometric sense, the conductance is constant.},
  isbn = {978-3-540-77004-6}
}

@article{airoldi_mixed_2008,
  title = {Mixed {{Membership Stochastic Blockmodels}}},
  author = {Airoldi, Edoardo M and Blei, David M and Fienberg, Stephen E and Xing, Eric P},
  year = {2008},
  journal = {Journal of Machine Learning Research},
  abstract = {Consider data consisting of pairwise measurements, such as presence or absence of links between pairs of objects. These data arise, for instance, in the analysis of protein interactions and gene regulatory networks, collections of author-recipient email, and social networks. Analyzing pairwise measurements with probabilistic models requires special assumptions, since the usual independence or exchangeability assumptions no longer hold. Here we introduce a class of variance allocation models for pairwise measurements: mixed membership stochastic blockmodels. These models combine global parameters that instantiate dense patches of connectivity (blockmodel) with local parameters that instantiate node-specific variability in the connections (mixed membership). We develop a general variational inference algorithm for fast approximate posterior inference. We demonstrate the advantages of mixed membership stochastic blockmodels with applications to social networks and protein interaction networks.},
  langid = {english},
  file = {/home/alex/Zotero/storage/IEWP9NKB/Airoldi et al. - Mixed Membership Stochastic Blockmodels.pdf}
}

@article{alter_singular_2000,
  title = {Singular Value Decomposition for Genome-Wide Expression Data Processing and Modeling},
  author = {Alter, Orly and Brown, Patrick O. and Botstein, David},
  year = {2000},
  month = aug,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {97},
  number = {18},
  pages = {10101--10106},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.97.18.10101},
  abstract = {We describe the use of singular value decomposition in transforming genome-wide expression data from genes \texttimes{} arrays space to reduced diagonalized ``eigengenes'' \texttimes{} ``eigenarrays'' space, where the eigengenes (or eigenarrays) are unique orthonormal superpositions of the genes (or arrays). Normalizing the data by filtering out the eigengenes (and eigenarrays) that are inferred to represent noise or experimental artifacts enables meaningful comparison of the expression of different genes across different arrays in different experiments. Sorting the data according to the eigengenes and eigenarrays gives a global picture of the dynamics of gene expression, in which individual genes and arrays appear to be classified into groups of similar regulation and function, or similar cellular state and biological phenotype, respectively. After normalization and sorting, the significant eigengenes and eigenarrays can be associated with observed genome-wide effects of regulators, or with measured samples, in which these regulators are overactive or underactive, respectively.},
  langid = {english},
  file = {/home/alex/Zotero/storage/JH7XYS32/Alter et al. - 2000 - Singular value decomposition for genome-wide expre.pdf}
}

@article{andrews_insights_2021,
  title = {Insights into the "Cross-World" Independence Assumption of Causal Mediation Analysis},
  author = {Andrews, Ryan M. and Didelez, Vanessa},
  year = {2021},
  month = mar,
  journal = {Epidemiology},
  volume = {32},
  number = {2},
  eprint = {2003.10341},
  eprinttype = {arxiv},
  pages = {209--219},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000001313},
  abstract = {Causal mediation analysis is a useful tool for epidemiological research, but it has been criticized for relying on a ``cross-world'' independence assumption that is empirically difficult to verify and problematic to justify based on background knowledge. In the present article, we aim to assist the applied researcher in understanding this assumption. Synthesizing what is known about the cross-world independence assumption, we discuss the relationship between assumptions for causal mediation analyses, causal models, and non-parametric identification of natural direct and indirect effects. In particular, we give a practical example of an applied setting where the cross-world independence assumption is violated even without any post-treatment confounding. Further, we review possible alternatives to the cross-world independence assumption, including the use of bounds that avoid the assumption altogether. Finally, we carry out a numerical study in which the cross-world independence assumption is violated to assess the ensuing bias in estimating natural direct and indirect effects. We conclude with recommendations for carrying out causal mediation analyses.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/KLDEKB66/Andrews and Didelez - 2021 - Insights into the cross-world independence assum.pdf}
}

@article{aronow_estimating_2017,
  title = {Estimating {{Average Causal Effects Under General Interference}}, with {{Application}} to a {{Social Network Experiment}}},
  author = {Aronow, Peter M. and Samii, Cyrus},
  year = {2017},
  month = dec,
  journal = {The Annals of Applied Statistics},
  volume = {11},
  number = {4},
  eprint = {1305.6156},
  eprinttype = {arxiv},
  issn = {1932-6157},
  doi = {10.1214/16-AOAS1005},
  abstract = {This paper presents a randomization-based framework for estimating causal effects under interference between units, motivated by challenges that arise in analyzing experiments on social networks. The framework integrates three components: (i) an experimental design that defines the probability distribution of treatment assignments, (ii) a mapping that relates experimental treatment assignments to exposures received by units in the experiment, and (iii) estimands that make use of the experiment to answer questions of substantive interest. We develop the case of estimating average unit-level causal effects from a randomized experiment with interference of arbitrary but known form. The resulting estimators are based on inverse probability weighting. We provide randomization-based variance estimators that account for the complex clustering that can occur when interference is present. We also establish consistency and asymptotic normality under local dependence assumptions. We discuss refinements including covariate-adjusted effect estimators and ratio estimation. We evaluate empirical performance in realistic settings with a naturalistic simulation using social network data from American schools. We then present results from a field experiment on the spread of anti-conflict norms and behavior among school students.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62-07; 62G05; 62P25,Mathematics - Statistics Theory,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/3VWC6V4J/1305.6156.pdf}
}

@article{athreya_limit_2015,
  title = {A {{Limit Theorem}} for {{Scaled Eigenvectors}} of {{Random Dot Product Graphs}}},
  author = {Athreya, A. and Priebe, C. E. and Tang, M. and Lyzinski, V. and Marchette, D. J. and Sussman, D. L.},
  year = {2015},
  journal = {Sankhya A: The Indian Journal of Statistics},
  volume = {78},
  number = {1},
  pages = {1--18},
  issn = {0976-836X, 0976-8378},
  doi = {10.1007/s13171-015-0071-x},
  abstract = {We prove a central limit theorem for the components of the largest eigenvectors of the adjacency matrix of a finite-dimensional random dot product graph whose true latent positions are unknown. We use the spectral embedding of the adjacency matrix to construct consistent estimates for the latent positions, and we show that the appropriately scaled differences between the estimated and true latent positions converge to a mixture of Gaussian random variables. We state several corollaries, including an alternate proof of a central limit theorem for the first eigenvector of the adjacency matrix of an Erdo\H{}s-R\textasciiacute enyi random graph.},
  langid = {english},
  file = {/home/alex/Zotero/storage/BFYWSDKV/Athreya et al. - 2016 - A Limit Theorem for Scaled Eigenvectors of Random .pdf}
}

@article{auerbach_identication_2021,
  title = {Identification and {{Estimation}} of a {{Partially Linear Regression Model}} Using {{Network Data}}},
  author = {Auerbach, Eric},
  year = {2021},
  pages = {26},
  abstract = {I study a regression model in which one covariate is an unknown function of a latent driver of link formation in a network. Rather than specify and fit a parametric network formation model, I introduce a new method based on matching pairs of agents with similar columns of the squared adjacency matrix, the ijth entry of which contains the number of other agents linked to both agents i and j. The intuition behind this approach is that for a large class of network formation models the columns of the squared adjacency matrix characterize all of the identifiable information about individual linking behavior. In this paper, I describe the model, formalize this intuition, and provide consistent estimators for the parameters of the regression model.},
  langid = {english},
  file = {/home/alex/Zotero/storage/G6D7UNSA/Auerbach - Identiﬁcation and Estimation of a Partially Linear.pdf}
}

@article{basse_limitations_2018,
  title = {Limitations of {{Design-based Causal Inference}} and {{A}}/{{B Testing}} under {{Arbitrary}} and {{Network Interference}}},
  author = {Basse, Guillaume W. and Airoldi, Edoardo M.},
  year = {2018},
  month = aug,
  journal = {Sociological Methodology},
  volume = {48},
  number = {1},
  pages = {136--151},
  issn = {0081-1750, 1467-9531},
  doi = {10.1177/0081175018782569},
  abstract = {Randomized experiments on a network often involve interference between connected units, namely, a situation in which an individual's treatment can affect the response of another individual. Current approaches to deal with interference, in theory and in practice, often make restrictive assumptions on its structure\textemdash for instance, assuming that interference is local\textemdash even when using otherwise nonparametric inference strategies. This reliance on explicit restrictions on the interference mechanism suggests a shared intuition that inference is impossible without any assumptions on the interference structure. In this paper, we begin by formalizing this intuition in the context of a classical nonparametric approach to inference, referred to as design-based inference of causal effects. Next, we show how, always in the context of design-based inference, even parametric structural assumptions that allow the existence of unbiased estimators cannot guarantee a decreasing variance even in the large sample limit. This lack of concentration in large samples is often observed empirically, in randomized experiments in which interference of some form is expected to be present. This result has direct consequences for the design and analysis of large experiments\textemdash for instance, in online social platforms\textemdash where the belief is that large sample sizes automatically guarantee small variance. More broadly, our results suggest that although strategies for causal inference in the presence of interference borrow their formalism and main concepts from the traditional causal inference literature, much of the intuition from the no-interference case do not easily transfer to the interference setting.},
  langid = {english},
  file = {/home/alex/Zotero/storage/H8EH8C8U/Basse and Airoldi - 2018 - Limitations of Design-based Causal Inference and A.pdf}
}

@article{basse_model-assisted_2018,
  title = {Model-Assisted Design of Experiments in the Presence of Network-Correlated Outcomes},
  author = {Basse, Guillaume W and Airoldi, Edoardo M},
  year = {2018},
  month = dec,
  journal = {Biometrika},
  volume = {105},
  number = {4},
  pages = {849--858},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asy036},
  abstract = {In this paper we consider how to assign treatment in a randomized experiment in which the correlation among the outcomes is informed by a network available pre-intervention. Working within the potential outcome causal framework, we develop a class of models that posit such a correlation structure among the outcomes. We use these models to develop restricted randomization strategies for allocating treatment optimally, by minimizing the mean squared error of the estimated average treatment effect. Analytical decompositions of the mean squared error, due both to the model and to the randomization distribution, provide insights into aspects of the optimal designs. In particular, the analysis suggests new notions of balance based on specific network quantities, in addition to classical covariate balance. The resulting balanced optimal restricted randomization strategies are still design-unbiased when the model used to derive them does not hold. We illustrate how the proposed treatment allocation strategies improve on allocations that ignore the network structure.},
  langid = {english},
  file = {/home/alex/Zotero/storage/PEDNW5LW/Basse and Airoldi - 2018 - Model-assisted design of experiments in the presen.pdf}
}

@book{bhatia_matrix_1997,
  title = {Matrix Analysis},
  author = {Bhatia, Rajendra},
  year = {1997},
  publisher = {{Springer}},
  abstract = {The aim of this book is to present a substantial part of matrix analysis that is functional analytic in spirit. Much of this will be of interest to graduate students and research workers in operator theory, operator algebras, mathematical physics, and numerical analysis. The book can be used as a basic text for graduate courses on advanced linear algebra and matrix analysis. It can also be used as supplementary text for courses in operator theory and numerical analysis. Among topics covered are the theory of majorization, variational principles of eigenvalues, operator monotone and convex functions, perturbation of matrix functions, and matrix inequalities. Much of this is presented for the first time in a unified way in a textbook. The reader will learn several powerful methods and techniques of wide applicability, and see connections with other areas of mathematics. A large selection of matrix inequalities will make this book a valuable reference for students and researchers who are working in numerical analysis, mathematical physics and operator theory.},
  isbn = {978-1-4612-0653-8},
  langid = {english},
  annotation = {OCLC: 883391978},
  file = {/home/alex/Zotero/storage/ZRI78HNQ/Bhatia - 1997 - Matrix analysis.pdf}
}

@article{bhattacharya_causal_nodate,
  title = {Causal {{Inference Under Interference And Network Uncertainty}}},
  author = {Bhattacharya, Rohit and Malinsky, Daniel and Shpitser, Ilya},
  pages = {11},
  abstract = {Classical causal and statistical inference methods typically assume the observed data consists of independent realizations. However, in many applications this assumption is inappropriate due to a network of dependences between units in the data. Methods for estimating causal effects have been developed in the setting where the structure of dependence between units is known exactly [10, 36, 20], but in practice there is often substantial uncertainty about the precise network structure. This is true, for example, in trial data drawn from vulnerable communities where social ties are difficult to query directly. In this paper we combine techniques from the structure learning and interference literatures in causal inference, proposing a general method for estimating causal effects under data dependence when the structure of this dependence is not known a priori. We demonstrate the utility of our method on synthetic datasets which exhibit network dependence.},
  langid = {english},
  file = {/home/alex/Zotero/storage/BIICXYDF/Bhattacharya et al. - Causal Inference Under Interference And Network Un.pdf}
}

@article{bjorck_numerical_1973,
  title = {Numerical {{Methods}} for {{Computing Angles Between Linear Subspaces}}},
  author = {Bjorck, Ake and Golub, Gene H.},
  year = {1973},
  month = jul,
  journal = {Mathematics of Computation},
  volume = {27},
  number = {123},
  pages = {579},
  issn = {00255718},
  doi = {10.2307/2005662},
  abstract = {Assume that two subspaces F and G of a unitary space are defined as the ranges (or null spaces) of given rectangular matrices A and B. Accurate numerical methods are developed for computing the principal angles Ok(F,G) and orthogonal sets of principal vectors Ilk E F and Uk C G, k = 1, 2, ... , q = dim(G) {$<$} dim(F). An important application in statistics is computing the canonical correlations 0Uk = COSOkbetween two sets of variates. A perturbation analysis shows that the condition number for Okessentially is max(K(A), K(B)), where K denotes the condition number of a matrix. The algorithms are based on a preliminary QR-factorization of A and B (or A"l and B"), for which either the method of Householder transformations (HT) or the modified Gram-Schmidt method (MGS) is used. Then cos 6k and sin Okare computed as the singular values of certain related matrices. Experimental results are given, which indicates that MGS gives ok with equal precision and fewer arithmetic operations than HT. However, HT gives principal vectors, which are orthogonal to working accuracy, which is not generally true for MGS. Finally, the case when A and/or B are rank deficient is discussed.},
  langid = {english},
  file = {/home/alex/Zotero/storage/9LRVF67P/Bjorck and Golub - 1973 - Numerical Methods for Computing Angles Between Lin.pdf}
}

@incollection{blume_identification_2010,
  title = {Identification of {{Social Interactions}}},
  author = {Blume, Lawrence and Brock, William and Durlauf, Steven and Ioannides, Yannis},
  year = {2010},
  pages = {154},
  langid = {english},
  file = {/home/alex/Zotero/storage/WR4LEX9N/Blume et al. - Identification of Social Interactions.pdf}
}

@book{bonato_algorithms_2007,
  title = {Algorithms and Models for the {{Web-graph}}: 5th International Workshop, {{WAW}} 2007, {{San Diego}}, {{CA}}, {{USA}}, {{December}} 11-12, 2007 ; Proceedings},
  shorttitle = {Algorithms and Models for the {{Web-graph}}},
  editor = {Bonato, Anthony and Chung, Fan R. K.},
  year = {2007},
  series = {Lecture Notes in Computer Science},
  number = {4863},
  publisher = {{Springer}},
  address = {{Berlin Heidelberg}},
  isbn = {978-3-540-77003-9},
  langid = {english},
  file = {/home/alex/Zotero/storage/L9KIUS97/Bonato and Chung - 2007 - Algorithms and models for the Web-graph 5th inter.pdf}
}

@article{bond_61-million-person_2012,
  title = {A 61-Million-Person Experiment in Social Influence and Political Mobilization},
  author = {Bond, Robert M. and Fariss, Christopher J. and Jones, Jason J. and Kramer, Adam D. I. and Marlow, Cameron and Settle, Jaime E. and Fowler, James H.},
  year = {2012},
  month = sep,
  journal = {Nature},
  volume = {489},
  number = {7415},
  pages = {295--298},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature11421},
  abstract = {Human behaviour is thought to spread through face-to-face social networks, but it is difficult to identify social influence effects in observational studies9\textendash 13, and it is unknown whether online social networks operate in the same way14\textendash 19. Here we report results from a randomized controlled trial of political mobilization messages delivered to 61 million Facebook users during the 2010 US congressional elections. The results show that the messages directly influenced political self-expression, information seeking and real-world voting behaviour of millions of people. Furthermore, the messages not only influenced the users who received them but also the users' friends, and friends of friends. The effect of social transmission on real-world voting was greater than the direct effect of the messages themselves, and nearly all the transmission occurred between `close friends' who were more likely to have a face-to-face relationship. These results suggest that strong ties are instrumental for spreading both online and real-world behaviour in human social networks.},
  langid = {english},
  file = {/home/alex/Zotero/storage/UXMCAW2E/Bond et al. - 2012 - A 61-million-person experiment in social influence.pdf}
}

@book{boos_essential_2013,
  title = {Essential {{Statistical Inference}}},
  author = {Boos, Dennis D and Stefanski, L. A},
  year = {2013},
  series = {Springer {{Texts}} in {{Statistics}}},
  volume = {120},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-4818-1},
  isbn = {978-1-4614-4817-4 978-1-4614-4818-1},
  langid = {english},
  keywords = {reference},
  file = {/home/alex/Zotero/storage/MGLJ3HBR/Boos and Stefanski - 2013 - Essential Statistical Inference.pdf}
}

@book{boucheron_concentration_2013,
  title = {Concentration {{Inequalities}}: {{A Nonasymptotic Theory}} of {{Independence}}},
  shorttitle = {Concentration {{Inequalities}}},
  author = {Boucheron, St{\'e}phane and Lugosi, G{\'a}bor and Massart, Pascal},
  year = {2013},
  month = feb,
  publisher = {{Oxford University Press}},
  doi = {10.1093/acprof:oso/9780199535255.001.0001},
  isbn = {978-0-19-953525-5},
  langid = {english},
  file = {/home/alex/Zotero/storage/KPTGTNWF/Boucheron et al. - 2013 - Concentration Inequalities A Nonasymptotic Theory.pdf}
}

@book{bowker_sorting_1999,
  title = {Sorting Things out: Classification and Its Consequences},
  shorttitle = {Sorting Things Out},
  author = {Bowker, Geoffrey C. and Star, Susan Leigh},
  year = {1999},
  series = {Inside Technology},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-02461-7},
  langid = {english},
  lccn = {BD175 .B68 1999},
  keywords = {Classification,Knowledge; Sociology of},
  file = {/home/alex/Zotero/storage/A76JSKAG/Bowker and Star - 1999 - Sorting things out classification and its consequ.pdf}
}

@article{cai_network_2021,
  title = {Network Regression and Supervised Centrality Estimation},
  author = {Cai, Junhui and Yang, Dan and Zhu, Wu and Shen, Haipeng and Zhao, Linda},
  year = {2021},
  month = nov,
  journal = {arXiv:2111.12921 [cs, econ, stat]},
  eprint = {2111.12921},
  eprinttype = {arxiv},
  primaryclass = {cs, econ, stat},
  abstract = {The centrality in a network is a popular metric for agents' network positions and is often used in regression models to model the network effect on an outcome variable of interest. In empirical studies, researchers often adopt a two-stage procedure to first estimate the centrality and then infer the network effect using the estimated centrality. Despite its prevalent adoption, this two-stage procedure lacks theoretical backing and can fail in both estimation and inference. We, therefore, propose a unified framework, under which we prove the shortcomings of the two-stage in centrality estimation and the undesirable consequences in the regression. We then propose a novel supervised network centrality estimation (SuperCENT) methodology that simultaneously yields superior estimations of the centrality and the network effect and provides valid and narrower confidence intervals than those from the twostage. We showcase the superiority of SuperCENT in predicting the currency risk premium based on the global trade network.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks,Economics - Econometrics,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/RBRQTC6E/Cai et al. - 2021 - Network regression and supervised centrality estim.pdf}
}

@article{calvo-armengol_peer_nodate,
  title = {Peer Effects and Social Networks in Education},
  author = {{Calv{\'o}-Armengol}, A and Patacchini, E and Zenou, Y},
  pages = {61},
  abstract = {This paper studies whether structural properties of friendship networks affect individual outcomes in education. We first develop a model that shows that, at the Nash equilibrium, the outcome of each individual embedded in a network is proportional to her Katz-Bonacich centrality measure. This measure takes into account both direct and indirect friends of each individual but puts less weight to her distant friends. We then bring the model to the data by using a very detailed dataset of adolescent friendship networks. We show that, after controlling for observable individual characteristics and unobservable network specific factors, the individual's position in a network (as measured by her Katz-Bonacich centrality) is a key determinant of her level of activity. A standard deviation increase in the KatzBonacich centrality increases the pupil school performance by more than 7 percent of one standard deviation.},
  langid = {english},
  file = {/home/alex/Zotero/storage/7925H2UY/Calvó-Armengol et al. - Peer effects and social networks in education.pdf}
}

@article{cape_two--infinity_2019,
  title = {The Two-to-Infinity Norm and Singular Subspace Geometry with Applications to High-Dimensional Statistics},
  author = {Cape, Joshua and Tang, Minh and Priebe, Carey E.},
  year = {2019},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {47},
  number = {5},
  pages = {2405--2439},
  issn = {0090-5364},
  doi = {10.1214/18-AOS1752},
  langid = {english},
  file = {/home/alex/Zotero/storage/GFQH37TE/Cape et al. - 2019 - The two-to-infinity norm and singular subspace geo.pdf}
}

@article{carrell_is_nodate,
  title = {Is {{Poor Fitness Contagious}}? {{Evidence}} from {{Randomly Assigned Friends}}},
  author = {Carrell, Scott E and Davis, UC and Hoekstra, Mark and West, James E},
  pages = {25},
  abstract = {The increase in obesity over the past thirty years has led researchers to investigate the role of social networks as a contributing factor. However, several challenges make it difficult to demonstrate a causal link between friends' physical fitness and own fitness using observational data. To overcome these problems, we exploit data from a unique setting in which individuals are randomly assigned to peer groups. We find statistically significant peer effects that are 40 to 70 percent as large as the own effect of prior fitness scores on current fitness outcomes. Evidence suggests that the effects are caused primarily by friends who were the least fit, thus supporting the provocative notion that poor physical fitness spreads on a person-to-person basis.},
  langid = {english},
  file = {/home/alex/Zotero/storage/FRYHKYYM/Carrell et al. - Is Poor Fitness Contagious Evidence from Randomly.pdf}
}

@article{carrell_knowing_2021,
  title = {Knowing {{What}} It {{Takes}}: {{The Effect}} of {{Information About Returns}} to {{Studying}} on {{Study Effort}} and {{Achievement}}},
  shorttitle = {Knowing {{What}} It {{Takes}}},
  author = {Carrell, Scott and Rury, Derek},
  year = {2021},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3970822},
  abstract = {We study the effect of providing students with information on returns to study effort in a large introductory microeconomics course. To do so, we use granular time-use data from the course's online homework module to estimate the association between study time and course performance. We use the same data as well as course outcome data to measure the impact of this information on several important outcomes, such as study effort as well as exam and overall course performance. We find that the treatment led to a 13\% short-term increase in study effort for all students. We find similar effects on homework scores. Focusing on the role of beliefs about returns to study effort, we see that short term study effort greatly increased for those students who originally over-estimated their returns to study effort. In contrast, we find more long term effects for students who originally under-estimated the returns to study effort. These students outperformed students who had over-estimated the returns to study effort both on measures of exam performance as well as overall course performance. We also see strong evidence that low-income students increased their study effort through out the course, along with evidence of large effects on their exam and course performance. We see these results as signs of a dominant substitution effect, as students substitute into studying upon learning that academic achievement is now less expensive.},
  langid = {english},
  file = {/home/alex/Zotero/storage/V3DBHDD5/Carrell and Rury - 2021 - Knowing What it Takes The Effect of Information A.pdf}
}

@article{carrell_long-run_2018,
  title = {The {{Long-Run Effects}} of {{Disruptive Peers}}},
  author = {Carrell, Scott E. and Hoekstra, Mark and Kuka, Elira},
  year = {2018},
  month = nov,
  journal = {American Economic Review},
  volume = {108},
  number = {11},
  pages = {3377--3415},
  issn = {0002-8282},
  doi = {10.1257/aer.20160763},
  abstract = {A large and growing literature has documented the importance of peer effects in education. However, there is relatively little evidence on the long-run educational and labor market consequences of childhood peers. We examine this question by linking administrative data on elementary school students to subsequent test scores, college attendance and completion, and earnings. To distinguish the effect of peers from confounding factors, we exploit the population variation in the proportion of children from families linked to domestic violence, who have been shown to disrupt contemporaneous behavior and learning. Results show that exposure to a disruptive peer in classes of 25 during elementary school reduces earnings at age 24 to 28 by 3 percent. We estimate that differential exposure to children linked to domestic violence explains 5 percent of the rich-poor earnings gap in our data, and that each year of exposure to a disruptive peer reduces the present discounted value of classmates' future earnings by \$80,000. (JEL I21, I26, J13, J24, J31)},
  langid = {english},
  file = {/home/alex/Zotero/storage/VLWWGVNJ/Carrell et al. - 2018 - The Long-Run Effects of Disruptive Peers.pdf}
}

@article{carrell_my_nodate,
  title = {My {{Professor Cares}}: {{Experimental Evidence}} on the {{Role}} of {{Faculty Engagement}}},
  author = {Carrell, Scott E and Kurlaender, Michal},
  pages = {53},
  abstract = {Despite a growing body of literature that instructors ``matter'' in higher education, there is virtually no evidence about how their actions influence student outcomes. We provide experimental evidence on the impact of specific faculty behaviors aimed at increasing student success. We test the effect of professor feedback on student success in higher education classrooms though a "light-touch" randomized intervention. We present results from a small pilot in an introductory-level microeconomics course at a comprehensive research university, and the scale-up conducted in over 43 classrooms and nearly 4,000 students at a large broad-access university. The intervention consisted of several strategically-timed E-mails to students from the professor indicating keys to success in the class, the students' current standing in the course, and a reminder of when the professor is available. Results from the pilot show that students in the treatment group scored higher on exams, homework assignments, and final course grade. Results from the scaled-up experiment are more mixed\textemdash we find significant positive effects on student perceptions of the professor and course for all students. However, we only find positive achievement effects for our target population, first year students from underrepresented minority groups. Finally, we replicated the pilot to test the robustness of these results and again find positive effects on student achievement. We conclude that in certain settings and with some students, targeted feedback from professors can lead to meaningful gains in achievement.},
  langid = {english},
  file = {/home/alex/Zotero/storage/SGLZA8CS/Carrell and Kurlaender - My Professor Cares Experimental Evidence on the R.pdf}
}

@article{carrell_natural_2013,
  title = {From {{Natural Variation}} to {{Optimal Policy}}? {{The Importance}} of {{Endogenous Peer Group Formation}}},
  shorttitle = {From {{Natural Variation}} to {{Optimal Policy}}?},
  author = {Carrell, Scott E. and Sacerdote, Bruce I. and West, James E.},
  year = {2013},
  journal = {Econometrica},
  volume = {81},
  number = {3},
  pages = {855--882},
  issn = {1468-0262},
  doi = {10.3982/ECTA10168},
  abstract = {We take cohorts of entering freshmen at the United States Air Force Academy and assign half to peer groups designed to maximize the academic performance of the lowest ability students. Our assignment algorithm uses nonlinear peer effects estimates from the historical pre-treatment data, in which students were randomly assigned to peer groups. We find a negative and significant treatment effect for the students we intended to help. We provide evidence that within our ``optimally'' designed peer groups, students avoided the peers with whom we intended them to interact and instead formed more homogeneous subgroups. These results illustrate how policies that manipulate peer groups for a desired social outcome can be confounded by changes in the endogenous patterns of social interactions within the group.},
  langid = {english},
  keywords = {homophily,Peer effects,social network formation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA10168},
  file = {/home/alex/Zotero/storage/4KI4NS3J/Carrell et al. - 2013 - From Natural Variation to Optimal Policy The Impo.pdf;/home/alex/Zotero/storage/DA546M6N/ECTA10168.html}
}

@article{carrell_peer_nodate,
  title = {Peer {{Effects}} in {{Academic Cheating}}},
  author = {Carrell, Scott E and Malmstrom, Frederick V and West, James E},
  pages = {35},
  abstract = {Using self-reported academic cheating from the classes of 1959 through 2002 at the three major United States military service academies (Air Force, Army, and Navy), we measure how peer cheating influences individual cheating behavior. We find higher levels of peer cheating result in a substantially increased probability that an individual will cheat. One additional college student who cheated in high school drives approximately 0.33 to 0.47 additional college students to cheat. One additional college cheater drives approximately 0.61 to 0.75 additional college students to cheat. These results imply, in equilibrium, the social multiplier for academic cheating is approximately three.},
  langid = {english},
  file = {/home/alex/Zotero/storage/LGL3FQK6/Carrell et al. - Peer Effects in Academic Cheating.pdf}
}

@article{che_network_2021,
  title = {Network {{Mediation Analysis Using Model-Based Eigenvalue Decomposition}}},
  author = {Che, Chang and Jin, Ick Hoon and Zhang, Zhiyong},
  year = {2021},
  month = jan,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {28},
  number = {1},
  pages = {148--161},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2020.1721292},
  abstract = {This paper proposes a new two-stage network mediation method based on the use of a latent network approach \textendash{} model-based eigenvalue decomposition \textendash{} for analyzing social network data with nodal covariates. In the decomposition stage of the observed network, no assumption on the metric of the latent space structure is required. In the mediation stage, the most important eigenvectors of a network are used as mediators. This method further offers an innovative way for controlling for the conditional covariates, and it only considers the information left in the network. We demonstrate this approach in a detailed tutorial R code provided for four separate cases \textendash{} unconditional and conditional model-based eigenvalue decompositions for either a continuous outcome or a binary outcome \textendash{} to show its applicability to empirical network data.},
  langid = {english},
  file = {/home/alex/Zotero/storage/7GLNEJHV/Che et al. - 2021 - Network Mediation Analysis Using Model-Based Eigen.pdf}
}

@article{chen_estimating_2021,
  title = {Estimating {{Graph Dimension}} with {{Cross-validated Eigenvalues}}},
  author = {Chen, Fan and Roch, Sebastien and Rohe, Karl and Yu, Shuqi},
  year = {2021},
  month = aug,
  journal = {arXiv:2108.03336 [cs, math, stat]},
  eprint = {2108.03336},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  abstract = {In applied multivariate statistics, estimating the number of latent dimensions or the number of clusters is a fundamental and recurring problem. One common diagnostic is the scree plot, which shows the largest eigenvalues of the data matrix in decreasing order; the user searches for a ``gap'' or ``elbow'' in the decaying eigenvalues; unfortunately, these patterns can hide beneath the bias of the sample eigenvalues. This methodological problem is conceptually difficult because, in many situations, there is only enough signal to detect a subset of the k population dimensions/eigenvectors. In this situation, one could argue that the correct choice of k is the number of detectable dimensions. We alleviate these problems with cross-validated eigenvalues. Under a large class of random graph models, without any parametric assumptions, we provide a p-value for each sample eigenvector. It tests the null hypothesis that this sample eigenvector is orthogonal to (i.e., uncorrelated with) the true latent dimensions. This approach naturally adapts to problems where some dimensions are not statistically detectable. In scenarios where all k dimensions can be estimated, we prove that our procedure consistently estimates k. In simulations and a data example, the proposed estimator compares favorably to alternative approaches in both computational and statistical performance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Statistics Theory,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/BGAI4YCT/Chen et al. - 2021 - Estimating Graph Dimension with Cross-validated Ei.pdf}
}

@article{chen_high-dimensional_2016,
  title = {High-Dimensional {{Multivariate Mediation}}: With {{Application}} to {{Neuroimaging Data}}},
  shorttitle = {High-Dimensional {{Multivariate Mediation}}},
  author = {Ch{\'e}n, Oliver Y. and Crainiceanu, Ciprian M. and Ogburn, Elizabeth L. and Caffo, Brian S. and Wager, Tor D. and Lindquist, Martin A.},
  year = {2016},
  month = sep,
  journal = {arXiv:1511.09354 [stat]},
  eprint = {1511.09354},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Mediation analysis is an important tool in the behavioral sciences for investigating the role of intermediate variables that lie in the path between a treatment and an outcome variable. The influence of the intermediate variable on the outcome is often explored using a linear structural equation model (LSEM), with model coefficients interpreted as possible effects. While there has been significant research on the topic, little work has been done when the intermediate variable (mediator) is a high-dimensional vector. In this work we introduce a novel method for identifying potential mediators in this setting called the directions of mediation (DMs). DMs linearly combine potential mediators into a smaller number of orthogonal components, with components ranked by the proportion of the LSEM likelihood (assuming normally distributed errors) each accounts for. This method is well suited for cases when many potential mediators are measured. Examples of high-dimensional potential mediators are brain images composed of hundreds of thousands of voxels, genetic variation measured at millions of SNPs, or vectors of thousands of variables in large-scale epidemiological studies. We demonstrate the method using a functional magnetic resonance imaging (fMRI) study of thermal pain where we are interested in determining which brain locations mediate the relationship between the application of a thermal stimulus and self-reported pain.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/TZQM6WHK/Chén et al. - 2016 - High-dimensional Multivariate Mediation with Appl.pdf}
}

@article{chen_matrix_nodate,
  title = {Matrix Concentration Inequalities},
  author = {Chen, Yuxin},
  pages = {32},
  langid = {english},
  file = {/home/alex/Zotero/storage/A6XGCG3Y/Chen - Matrix concentration inequalities.pdf}
}

@article{chen_perturbation_2016,
  title = {On Perturbation Bounds for Orthogonal Projections},
  author = {Chen, Yan Mei and Chen, Xiao Shan and Li, Wen},
  year = {2016},
  month = oct,
  journal = {Numerical Algorithms},
  volume = {73},
  number = {2},
  pages = {433--444},
  issn = {1017-1398, 1572-9265},
  doi = {10.1007/s11075-016-0102-2},
  abstract = {In this paper, we present some new perturbation bounds for the orthogonal projections onto the column and row spaces of a matrix, which improve some existing results. Numerical examples are presented to illustrate our results.},
  langid = {english},
  file = {/home/alex/Zotero/storage/Q2NTJME4/Chen et al. - 2016 - On perturbation bounds for orthogonal projections.pdf}
}

@article{chen_sequential_2018,
  title = {Sequential Sampling Enhanced Composite Likelihood Approach to Estimation of Social Intercorrelations in Large-Scale Networks},
  author = {Chen, Yan and Qi, Youran and Liu, Qing and Chien, Peter},
  year = {2018},
  month = dec,
  journal = {Quantitative Marketing and Economics},
  volume = {16},
  number = {4},
  pages = {409--440},
  issn = {1570-7156, 1573-711X},
  doi = {10.1007/s11129-018-9199-z},
  abstract = {The increasing access to large social network data has generated substantial interest in the marketing community. However, due to its large scale, traditional analysis methods often become inadequate. In this paper, we propose a sequential sampling enhanced composite likelihood approach for efficient estimation of social intercorrelations in large-scale networks using the spatial model. Given a known population network, the proposed approach sequentially takes small samples from the network, and adaptively improves model parameter estimates through learnings obtained from previous samples. In comparison to population-based maximum likelihood estimation that is computationally prohibitive when the network size is large, the proposed approach makes it computationally feasible to analyze large networks and provide efficient estimation of social intercorrelations among members in large networks. In comparison to sample-based estimation that relies on information purely from the sample and produces underestimation bias in social intercorrelation estimates, the proposed approach effectively uses information from the population without compromising computation efficiency. Through simulation studies based on simulated networks and real networks, we demonstrate significant advantages of the proposed approach over benchmark estimation methods and discuss managerial implications. We also discuss extension of the proposed approach in the context of an unknown population network structure, as well as in an alternative form of the spatial model.},
  langid = {english},
  file = {/home/alex/Zotero/storage/HARFK4RT/Chen et al. - 2018 - Sequential sampling enhanced composite likelihood .pdf}
}

@article{cheng_causal_2021,
  title = {Causal {{Mediation Analysis}} with {{Hidden Confounders}}},
  author = {Cheng, Lu and Guo, Ruocheng and Liu, Huan},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.11724 [cs, stat]},
  eprint = {2102.11724},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {An important problem in causal inference is to break down the total effect of treatment into different causal pathways and quantify the causal effect in each pathway. Causal mediation analysis (CMA) is a formal statistical approach for identifying and estimating these causal effects. Central to CMA is the sequential ignorability assumption that implies all pre-treatment confounders are measured and they can capture different types of confounding, e.g., post-treatment confounders and hidden confounders. Typically unverifiable in observational studies, this assumption restrains both the coverage and practicality of conventional methods. This work, therefore, aims to circumvent the stringent assumption by following a causal graph with a unified confounder and its proxy variables. Our core contribution is an algorithm that combines deep latent-variable models and proxy strategy to jointly infer a unified surrogate confounder and estimate different causal effects in CMA from observed variables. Empirical evaluations using both synthetic and semi-synthetic datasets validate the effectiveness of the proposed method.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/YHDHZRFF/Cheng et al. - 2021 - Causal Mediation Analysis with Hidden Confounders.pdf}
}

@article{cheng_estimating_2021,
  title = {Estimating the Natural Indirect Effect and the Mediation Proportion via the Product Method},
  author = {Cheng, Chao and Spiegelman, Donna and Li, Fan},
  year = {2021},
  month = aug,
  journal = {arXiv:2108.08417 [stat]},
  eprint = {2108.08417},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The natural indirect effect (NIE) and mediation proportion (MP) are two measures of primary interest in mediation analysis. The standard approach for estimating NIE and MP is through the product method, which involves an model for the outcome conditional on the mediator and exposure and another model describing the exposure\textendash mediator relationship. The purpose of this article is to comprehensively develop and investigate the finite-sample performance of NIE and MP estimators via the product method. With four common data types, we propose closed-form interval estimators via the theory of estimating equations and multivariate delta method, and evaluate its empirical performance relative to the bootstrap approach. In addition, we have observed that the rare outcome assumption is frequently invoked to approximate the NIE and MP with a binary outcome, although this approximation may lead to non-negligible bias when the outcome is common. We therefore introduce the exact expressions for NIE and MP with a binary outcome without the rare outcome assumption and compare its performance with the approximate estimators. Based upon these theoretical developments and empirical studies, we offer several practical recommendations to inform practice. An R package mediateP is developed to implement the methods for point and variance estimation discussed in this paper.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/IFBVGDFI/Cheng et al. - 2021 - Estimating the natural indirect effect and the med.pdf}
}

@article{cheng_web_nodate,
  title = {Web {{Material}} for ``{{Estimating}} the Natural Indirect Effect and the Mediation Proportion via the Product Method"},
  author = {Cheng, Chao and Spiegelman, Donna and Li, Fan},
  pages = {18},
  langid = {english},
  file = {/home/alex/Zotero/storage/KVUBQPRP/Cheng et al. - Web Material for “Estimating the natural indirect .pdf}
}

@article{chin_regression_2019,
  title = {Regression {{Adjustments}} for {{Estimating}} the {{Global Treatment Effect}} in {{Experiments}} with {{Interference}}},
  author = {Chin, Alex},
  year = {2019},
  month = sep,
  journal = {Journal of Causal Inference},
  volume = {7},
  number = {2},
  pages = {20180026},
  issn = {2193-3685, 2193-3677},
  doi = {10.1515/jci-2018-0026},
  abstract = {Standard estimators of the global average treatment effect can be biased in the presence of interference. This paper proposes regression adjustment estimators for removing bias due to interference in Bernoulli randomized experiments. We use a fitted model to predict the counterfactual outcomes of global control and global treatment. Our work differs from standard regression adjustments in that the adjustment variables are constructed from functions of the treatment assignment vector, and that we allow the researcher to use a collection of any functions correlated with the response, turning the problem of detecting interference into a feature engineering problem. We characterize the distribution of the proposed estimator in a linear model setting and connect the results to the standard theory of regression adjustments under SUTVA. We then propose an estimator that allows for flexible machine learning estimators to be used for fitting a nonlinear interference functional form. We propose conducting statistical inference via bootstrap and resampling methods, which allow us to sidestep the complicated dependences implied by interference and instead rely on empirical covariance structures. Such variance estimation relies on an exogeneity assumption akin to the standard unconfoundedness assumption invoked in observational studies. In simulation experiments, our methods are better at debiasing estimates than existing inverse propensity weighted estimators based on neighborhood exposure modeling. We use our method to reanalyze an experiment concerning weather insurance adoption conducted on a collection of villages in rural China.},
  langid = {english},
  file = {/home/alex/Zotero/storage/2AMPAZBM/Chin - 2019 - Regression Adjustments for Estimating the Global T.pdf}
}

@article{chu_graph_2021,
  title = {Graph {{Infomax Adversarial Learning}} for {{Treatment Effect Estimation}} with {{Networked Observational Data}}},
  author = {Chu, Zhixuan and Rathbun, Stephen L. and Li, Sheng},
  year = {2021},
  month = aug,
  journal = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  eprint = {2106.02881},
  eprinttype = {arxiv},
  pages = {176--184},
  doi = {10.1145/3447548.3467302},
  abstract = {Treatment effect estimation from observational data is a critical research topic across many domains. The foremost challenge in treatment effect estimation is how to capture hidden confounders. Recently, the growing availability of networked observational data offers a new opportunity to deal with the issue of hidden confounders. Unlike networked data in traditional graph learning tasks, such as node classification and link detection, the networked data under the causal inference problem has its particularity, i.e., imbalanced network structure. In this paper, we propose a Graph Infomax Adversarial Learning (GIAL) model for treatment effect estimation, which makes full use of the network structure to capture more information by recognizing the imbalance in network structure. We evaluate the performance of our GIAL model on two benchmark datasets, and the results demonstrate superiority over the state-of-the-art methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {68U01,Computer Science - Machine Learning,H.0,I.0,I.2},
  file = {/home/alex/Zotero/storage/7ZRLKMHK/Chu et al. - 2021 - Graph Infomax Adversarial Learning for Treatment E.pdf}
}

@article{cinelli_making_2020,
  title = {Making Sense of Sensitivity: Extending Omitted Variable Bias},
  shorttitle = {Making Sense of Sensitivity},
  author = {Cinelli, Carlos and Hazlett, Chad},
  year = {2020},
  month = feb,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {82},
  number = {1},
  pages = {39--67},
  issn = {13697412},
  doi = {10.1111/rssb.12348},
  abstract = {We extend the omitted variable bias framework with a suite of tools for sensitivity analysis in regression models that does not require assumptions on the functional form of the treatment assignment mechanism nor on the distribution of the unobserved confounders, naturally handles multiple confounders, possibly acting non-linearly, exploits expert knowledge to bound sensitivity parameters and can be easily computed by using only standard regression results. In particular, we introduce two novel sensitivity measures suited for routine reporting.The robustness value describes the minimum strength of association that unobserved confounding would need to have, both with the treatment and with the outcome, to change the research conclusions. The partial R2 of the treatment with the outcome shows how strongly confounders explaining all the residual outcome variation would have to be associated with the treatment to eliminate the estimated effect. Next, we offer graphical tools for elaborating on problematic confounders, examining the sensitivity of point estimates and t-values, as well as `extreme scenarios'. Finally, we describe problems with a common `benchmarking' practice and introduce a novel procedure to bound the strength of confounders formally on the basis of a comparison with observed covariates. We apply these methods to a running example that estimates the effect of exposure to violence on attitudes toward peace.},
  langid = {english},
  file = {/home/alex/Zotero/storage/YL5XMQLP/Cinelli and Hazlett - 2020 - Making sense of sensitivity extending omitted var.pdf}
}

@article{clark_approach_2021,
  title = {An {{Approach}} to {{Causal Inference}} over {{Stochastic Networks}}},
  author = {Clark, Duncan A. and Handcock, Mark S.},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.14145 [stat]},
  eprint = {2106.14145},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Claiming causal inferences in network settings necessitates careful consideration of the often complex dependency between outcomes for actors. Of particular importance are treatment spillover or outcome interference effects. We consider causal inference when the actors are connected via an underlying network structure. Our key contribution is a model for causality when the underlying network is unobserved and the actor covariates evolve stochastically over time. We develop a joint model for the relational and covariate generating process that avoids restrictive separability assumptions and deterministic network assumptions that do not hold in the majority of social network settings of interest. Our framework utilizes the highly general class of Exponential-family Random Network models (ERNM) of which Markov Random Fields (MRF) and Exponential-family Random Graph models (ERGM) are special cases. We present potential outcome based inference within a Bayesian framework, and propose a simple modification to the exchange algorithm to allow for sampling from ERNM posteriors. We present results of a simulation study demonstrating the validity of the approach. Finally, we demonstrate the value of the framework in a case-study of smoking over time in the context of adolescent friendship networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/U59478MW/Clark and Handcock - 2021 - An Approach to Causal Inference over Stochastic Ne.pdf}
}

@article{cohen-cole_is_nodate-1,
  title = {Is {{Obesity Contagious}}? {{Social Networks}} vs. {{Environmental Factors}} in the {{Obesity Epidemic}}},
  author = {{Cohen-Cole}, Ethan and Fletcher, Jason M},
  pages = {18},
  abstract = {This note's aim is to investigate the sensitivity of Christakis and Fowler's claim (NEJM July 26, 2007) that obesity has spread through social networks. It is well known in the economics literature that failure to include contextual effects can lead to spurious inference on ``social network effects.'' We replicate the NEJM results using their specification and a complementary dataset. We find that point estimates of the ``social network effect'' are reduced and become statistically indistinguishable from zero once standard econometric techniques are implemented. We further note the presence of estimation bias resulting from use of an incorrectly specified dynamic model.},
  langid = {english},
  file = {/home/alex/Zotero/storage/Z5HVVIFD/Cohen-Cole and Fletcher - Is Obesity Contagious Social Networks vs. Environ.pdf}
}

@article{coifman_diffusion_2006,
  title = {Diffusion Maps},
  author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
  year = {2006},
  month = jul,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {21},
  number = {1},
  pages = {5--30},
  issn = {10635203},
  doi = {10.1016/j.acha.2006.04.006},
  abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.},
  langid = {english},
  file = {/home/alex/Zotero/storage/RT9VUISC/Coifman and Lafon - 2006 - Diffusion maps.pdf}
}

@inproceedings{cristali_using_2021,
  title = {Using {{Embeddings}} to {{Estimate Peer Influence}} on {{Social Networks}}},
  booktitle = {35th {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Cristali, Irina and Veitch, Victor},
  year = {2021},
  pages = {9},
  address = {{Sydney, Australia.}},
  langid = {english},
  file = {/home/alex/Zotero/storage/FEYYL3NH/Cristali and Veitch - Using Embeddings to Estimate Peer Inﬂuence on Soci.pdf}
}

@article{damour_comment_2019,
  title = {Comment: {{Reflections}} on the {{Deconfounder}}},
  shorttitle = {Comment},
  author = {D'Amour, Alexander},
  year = {2019},
  month = oct,
  journal = {arXiv:1910.08042 [stat]},
  eprint = {1910.08042},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The aim of this comment (set to appear in a formal discussion in JASA) is to draw out some conclusions from an extended back-and-forth I have had with Wang and Blei regarding the deconfounder method proposed in "The Blessings of Multiple Causes" [arXiv:1805.06826]. I will make three points here. First, in my role as the critic in this conversation, I will summarize some arguments about the lack of causal identification in the bulk of settings where the "informal" message of the paper suggests that the deconfounder could be used. This is a point that is discussed at length in D'Amour 2019 [arXiv:1902.10286], which motivated the results concerning causal identification in Theorems 6--8 of "Blessings". Second, I will argue that adding parametric assumptions to the working model in order to obtain identification of causal parameters (a strategy followed in Theorem 6 and in the experimental examples) is a risky strategy, and should only be done when extremely strong prior information is available. Finally, I will consider the implications of the nonparametric identification results provided for a narrow, but non-trivial, set of causal estimands in Theorems 7 and 8. I will highlight that these results may be even more interesting from the perspective of detecting causal identification from observed data, under relatively weak assumptions about confounders.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/AV76BEBC/D'Amour - 2019 - Comment Reflections on the Deconfounder.pdf}
}

@article{di_maria_networks_2022,
  title = {Networks as Mediating Variables: A {{Bayesian}} Latent Space Approach},
  shorttitle = {Networks as Mediating Variables},
  author = {Di Maria, Chiara and Abbruzzo, Antonino and Lovison, Gianfranco},
  year = {2022},
  month = feb,
  journal = {Statistical Methods \& Applications},
  issn = {1618-2510, 1613-981X},
  doi = {10.1007/s10260-022-00621-w},
  abstract = {The use of network analysis to investigate social structures has recently seen a rise due to the high availability of data and the numerous insights it can provide into different fields. Most analyses focus on the topological characteristics of networks and the estimation of relationships between the nodes. We adopt a different perspective by considering the whole network as a random variable conveying the effect of an exposure on a response. This point of view represents a classical mediation setting, where the interest lies in estimating the indirect effect, that is, the effect propagated through the mediating variable. We introduce a latent space model mapping the network into a space of smaller dimension by considering the hidden positions of the units in the network. The coordinates of each node are used as mediators in the relationship between the exposure and the response. We further extend mediation analysis in the latent space framework by using Generalised Linear Models instead of linear ones, as previously done in the literature, adopting an approach based on derivatives to obtain the effects of interest. A Bayesian approach allows us to get the entire distribution of the indirect effect, generally unknown, and compute the corresponding highest density interval, which gives accurate and interpretable bounds for the mediated effect. Finally, an application to social interactions among a group of adolescents and their attitude toward substance use is presented.},
  langid = {english},
  file = {/home/alex/Zotero/storage/BDWQACZV/Di Maria et al. - 2022 - Networks as mediating variables a Bayesian latent.pdf}
}

@article{ding_cooperative_2022,
  title = {Cooperative Learning for Multi-View Analysis},
  author = {Ding, Daisy Yi and Narasimhan, Balasubramanian and Tibshirani, Robert},
  year = {2022},
  month = jan,
  journal = {arXiv:2112.12337 [q-bio, stat]},
  eprint = {2112.12337},
  eprinttype = {arxiv},
  primaryclass = {q-bio, stat},
  abstract = {We propose a new method for supervised learning with multiple sets of features (``views''). Cooperative learning combines the usual squared error loss of predictions with an ``agreement'' penalty to encourage the predictions from different data views to agree. By varying the weight of the agreement penalty, we get a continuum of solutions that include the well-known early and late fusion approaches. Cooperative learning chooses the degree of agreement (or fusion) in an adaptive manner, using a validation set or cross-validation to estimate test set prediction error. One version of our fitting procedure is modular, where one can choose different fitting mechanisms (e.g. lasso, random forests, boosting, neural networks) appropriate for different data views. In the setting of cooperative regularized linear regression, the method combines the lasso penalty with the agreement penalty. The method can be especially powerful when the different data views share some underlying relationship in their signals that we aim to strengthen, while each view has idiosyncratic noise that we aim to reduce. We illustrate the effectiveness of our proposed method on simulated and real data examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Quantitative Biology - Quantitative Methods,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/89IQMAUW/Ding et al. - 2022 - Cooperative learning for multi-view analysis.pdf}
}

@article{doreian_estimating_1981,
  title = {Estimating {{Linear Models}} with {{Spatially Distributed Data}}},
  author = {Doreian, Patrick},
  year = {1981},
  journal = {Sociological Methodology},
  volume = {12},
  pages = {359},
  issn = {00811750},
  doi = {10.2307/270747},
  langid = {english},
  file = {/home/alex/Zotero/storage/LZXKKIPY/Doreian - 1981 - Estimating Linear Models with Spatially Distribute.pdf}
}

@book{dudley_uniform_1999,
  title = {Uniform Central Limit Theorems},
  author = {Dudley, R. M.},
  year = {1999},
  series = {Cambridge Studies in Advanced Mathematics},
  number = {63},
  publisher = {{Cambridge University Press}},
  address = {{New York}},
  isbn = {978-0-521-46102-3},
  langid = {english},
  lccn = {QA273.67 .D84 1999},
  keywords = {Central limit theorem},
  file = {/home/alex/Zotero/storage/LGJTPDR5/Dudley - 1999 - Uniform central limit theorems.pdf}
}

@article{dukes_proximal_2021,
  title = {Proximal Mediation Analysis},
  author = {Dukes, Oliver and Shpitser, Ilya and Tchetgen, Eric J. Tchetgen},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.11904 [stat]},
  eprint = {2109.11904},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {A common concern when trying to draw causal inferences from observational data is that the measured covariates are insufficiently rich to account for all sources of confounding. In practice, many of the covariates may only be proxies of the latent confounding mechanism. Recent work has shown that in certain settings where the standard `no unmeasured confounding' assumption fails, proxy variables can be leveraged to identify causal effects. Results currently exist for the total causal effect of an intervention, but little consideration has been given to learning about the direct or indirect pathways of the effect through a mediator variable. In this work, we describe three separate proximal identification results for natural direct and indirect effects in the presence of unmeasured confounding. We then develop a semiparametric framework for inference on natural (in)direct effects, which leads us to locally efficient, multiply robust estimators.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/BQ9ZFAZX/Dukes et al. - 2021 - Proximal mediation analysis.pdf}
}

@article{eckles_design_2014,
  title = {Design and Analysis of Experiments in Networks: {{Reducing}} Bias from Interference},
  shorttitle = {Design and Analysis of Experiments in Networks},
  author = {Eckles, Dean and Karrer, Brian and Ugander, Johan},
  year = {2014},
  month = aug,
  journal = {arXiv:1404.7530 [physics, stat]},
  eprint = {1404.7530},
  eprinttype = {arxiv},
  primaryclass = {physics, stat},
  abstract = {Estimating the effects of interventions in networks is complicated when the units are interacting, such that the outcomes for one unit may depend on the treatment assignment and behavior of many or all other units (i.e., there is interference). When most or all units are in a single connected component, it is impossible to directly experimentally compare outcomes under two or more global treatment assignments since the network can only be observed under a single assignment. Familiar formalism, experimental designs, and analysis methods assume the absence of these interactions, and result in biased estimators of causal effects of interest. While some assumptions can lead to unbiased estimators, these assumptions are generally unrealistic, and we focus this work on realistic assumptions. Thus, in this work, we evaluate methods for designing and analyzing randomized experiments that aim to reduce this bias and thereby reduce overall error. In design, we consider the ability to perform random assignment to treatments that is correlated in the network, such as through graph cluster randomization. In analysis, we consider incorporating information about the treatment assignment of network neighbors. We prove sufficient conditions for bias reduction through both design and analysis in the presence of potentially global interference. Through simulations of the entire process of experimentation in networks, we measure the performance of these methods under varied network structure and varied social behaviors, finding substantial bias and error reductions. These improvements are largest for networks with more clustering and data generating processes with both stronger direct effects of the treatment and stronger interactions between units.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/QKXU98J6/Eckles et al. - 2014 - Design and analysis of experiments in networks Re.pdf}
}

@article{egami_how_nodate,
  title = {How to {{Make Causal Inferences Using Texts}}},
  author = {Egami, Naoki and Fong, Christian J and Grimmer, Justin and Roberts, Margaret E and Stewart, Brandon M},
  pages = {68},
  abstract = {New text as data techniques offer a great promise: the ability to inductively discover measures that are useful for testing social science theories of interest from large collections of text. We introduce a conceptual framework for making causal inferences with discovered measures as a treatment or outcome. Our framework enables researchers to discover high-dimensional textual interventions and estimate the ways that observed treatments affect text-based outcomes. We argue that nearly all text-based causal inferences depend upon a latent representation of the text and we provide a framework to learn the latent representation. But estimating this latent representation, we show, creates new risks: we may introduce an identification problem or overfit. To address these risks we describe a split-sample framework and apply it to estimate causal effects from an experiment on immigration attitudes and a study on bureaucratic response. Our work provides a rigorous foundation for textbased causal inferences.},
  langid = {english},
  file = {/home/alex/Zotero/storage/ZMP9YNZC/Egami et al. - How to Make Causal Inferences Using Texts.pdf}
}

@article{egami_identification_2021,
  title = {Identification and {{Estimation}} of {{Causal Peer Effects Using Double Negative Controls}} for {{Unmeasured Network Confounding}}},
  author = {Egami, Naoki and Tchetgen, Eric J. Tchetgen},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.01933 [stat]},
  eprint = {2109.01933},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Scientists have been interested in estimating causal peer effects to understand how people's behaviors are affected by their network peers. However, it is well known that identification and estimation of causal peer effects are challenging in observational studies for two reasons. The first is the identification challenge due to unmeasured network confounding, for example, homophily bias and contextual confounding. The second issue is network dependence of observations, which one must take into account for valid statistical inference. Negative control variables, also known as placebo variables, have been widely used in observational studies including peer effect analysis over networks, although they have been used primarily for bias detection. In this article, we establish a formal framework which leverages a pair of negative control outcome and exposure variables (double negative controls) to nonparametrically identify causal peer effects in the presence of unmeasured network confounding. We then propose a generalized method of moments estimator for causal peer effects, and establish its consistency and asymptotic normality under an assumption about {$\psi$}-network dependence. Finally, we provide a network heteroskedasticity and autocorrelation consistent variance estimator. Our methods are illustrated with an application to peer effects in education.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/F37XY29E/Egami and Tchetgen - 2021 - Identification and Estimation of Causal Peer Effec.pdf}
}

@article{ehrhardt_network_2019,
  title = {Network {{Modularity}} in the {{Presence}} of {{Covariates}}},
  author = {Ehrhardt, Beate and Wolfe, Patrick J.},
  year = {2019},
  month = jan,
  journal = {SIAM Review},
  volume = {61},
  number = {2},
  pages = {261--276},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/17M1111528},
  abstract = {We characterize the large-sample properties of network modularity in the presence of covariates, under a natural and flexible null model. This provides for the first time an objective measure of whether or not a particular value of modularity is meaningful. In particular, our results quantify the strength of the relation between observed community structure and the interactions in a network. Our technical contribution is to provide limit theorems for modularity when a community assignment is given by nodal features or covariates. These theorems hold for a broad class of network models over a range of sparsity regimes, as well as for weighted, multiedge, and power-law networks. This allows us to assign p-values to observed community structure, which we validate using several benchmark examples from the literature. We conclude by applying this methodology to investigate a multiedge network of corporate email interactions.},
  langid = {english},
  file = {/home/alex/Zotero/storage/SW8UKQKX/Ehrhardt and Wolfe - 2019 - Network Modularity in the Presence of Covariates.pdf}
}

@article{farbmacher_causal_2021,
  title = {Causal Mediation Analysis with Double Machine Learning},
  author = {Farbmacher, Helmut and Huber, Martin and Laff{\'e}rs, Luk{\'a}{\v s} and Langen, Henrika and Spindler, Martin},
  year = {2021},
  month = feb,
  journal = {arXiv:2002.12710 [econ]},
  eprint = {2002.12710},
  eprinttype = {arxiv},
  primaryclass = {econ},
  abstract = {This paper combines causal mediation analysis with double machine learning to control for observed confounders in a data-driven way under a selection-on-observables assumption in a highdimensional setting. We consider the average indirect effect of a binary treatment operating through an intermediate variable (or mediator) on the causal path between the treatment and the outcome, as well as the unmediated direct effect. Estimation is based on efficient score functions, which possess a multiple robustness property w.r.t. misspecifications of the outcome, mediator, and treatment models. This property is key for selecting these models by double machine learning, which is combined with data splitting to prevent overfitting in the estimation of the effects of interest. We demonstrate that the direct and indirect effect estimators are asymptotically normal and root-n consistent under specific regularity conditions and investigate the finite sample properties of the suggested methods in a simulation study when considering lasso as machine learner. We also provide an empirical application to the U.S. National Longitudinal Survey of Youth, assessing the indirect effect of health insurance coverage on general health operating via routine checkups as mediator, as well as the direct effect. We find a moderate short-term effect of health insurance coverage on general health which is, however, not mediated by routine checkups.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Economics - Econometrics},
  file = {/home/alex/Zotero/storage/P65S722U/Farbmacher et al. - 2021 - Causal mediation analysis with double machine lear.pdf}
}

@article{feder_causal_2021,
  title = {Causal {{Inference}} in {{Natural Language Processing}}: {{Estimation}}, {{Prediction}}, {{Interpretation}} and {{Beyond}}},
  shorttitle = {Causal {{Inference}} in {{Natural Language Processing}}},
  author = {Feder, Amir and Keith, Katherine A. and Manzoor, Emaad and Pryzant, Reid and Sridhar, Dhanya and {Wood-Doughty}, Zach and Eisenstein, Jacob and Grimmer, Justin and Reichart, Roi and Roberts, Margaret E. and Stewart, Brandon M. and Veitch, Victor and Yang, Diyi},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.00725 [cs]},
  eprint = {2109.00725},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the remaining challenges. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects, encompassing settings where text is used as an outcome, treatment, or as a means to address confounding. In addition, we explore potential uses of causal inference to improve the performance, robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the computational linguistics community.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/alex/Zotero/storage/I854HWH9/Feder et al. - 2021 - Causal Inference in Natural Language Processing E.pdf}
}

@article{feder_causalm_2021,
  title = {{{CausaLM}}: {{Causal Model Explanation Through Counterfactual Language Models}}},
  shorttitle = {{{CausaLM}}},
  author = {Feder, Amir and Oved, Nadav and Shalit, Uri and Reichart, Roi},
  year = {2021},
  month = may,
  journal = {Computational Linguistics},
  eprint = {2005.13407},
  eprinttype = {arxiv},
  pages = {1--54},
  issn = {0891-2017, 1530-9312},
  doi = {10.1162/coli_a_00404},
  abstract = {Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination. As all machine learning based methods, they are as good as their training data, and can also capture unwanted biases. While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high level language concepts. A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology. To bridge that gap, we propose CausaLM, a framework for producing causal model explanations using counterfactual language representation models. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance. A byproduct of our method is a language representation model that is unaffected by the tested concept, which can be useful in mitigating unwanted bias ingrained in the data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/alex/Zotero/storage/R6UMPKFA/Feder et al. - 2021 - CausaLM Causal Model Explanation Through Counterf.pdf}
}

@inproceedings{finlayson_causal_2021,
  title = {Causal {{Analysis}} of {{Syntactic Agreement Mechanisms}} in {{Neural Language Models}}},
  booktitle = {Proceedings of the 59th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 11th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Finlayson, Matthew and Mueller, Aaron and Gehrmann, Sebastian and Shieber, Stuart and Linzen, Tal and Belinkov, Yonatan},
  year = {2021},
  pages = {1828--1843},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.acl-long.144},
  abstract = {Targeted syntactic evaluations have demonstrated the ability of language models to perform subject-verb agreement given difficult contexts. To elucidate the mechanisms by which the models accomplish this behavior, this study applies causal mediation analysis to pre-trained neural language models. We investigate the magnitude of models' preferences for grammatical inflections, as well as whether neurons process subject-verb agreement similarly across sentences with different syntactic structures. We uncover similarities and differences across architectures and model sizes\textemdash notably, that larger models do not necessarily learn stronger preferences. We also observe two distinct mechanisms for producing subject-verb agreement depending on the syntactic structure of the input sentence. Finally, we find that language models rely on similar sets of neurons when given sentences with similar syntactic structure.},
  langid = {english},
  file = {/home/alex/Zotero/storage/3NWJV3BG/Finlayson et al. - 2021 - Causal Analysis of Syntactic Agreement Mechanisms .pdf}
}

@incollection{floch_6_nodate,
  title = {6. {{Spatial}} Econometrics - Common Models},
  booktitle = {. {{Spatial}} Econometrics},
  author = {Floch, Jean-Michel},
  pages = {29},
  langid = {english},
  file = {/home/alex/Zotero/storage/MMSWCTYR/Floch - 6. Spatial econometrics - common models.pdf}
}

@article{forastiere_identification_2021,
  title = {Identification and {{Estimation}} of {{Treatment}} and {{Interference Effects}} in {{Observational Studies}} on {{Networks}}},
  author = {Forastiere, Laura and Airoldi, Edoardo M. and Mealli, Fabrizia},
  year = {2021},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {116},
  number = {534},
  pages = {901--918},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2020.1768100},
  abstract = {Causal inference on a population of units connected through a network often presents technical challenges, including how to account for interference. In the presence of interference, for instance, potential outcomes of a unit depend on their treatment as well as on the treatments of other units, such as their neighbors in the network. In observational studies, a further complication is that the typical unconfoundedness assumption must be extended\textemdash say, to include the treatment of neighbors, and individual and neighborhood covariates\textemdash to guarantee identification and valid inference. Here, we propose new estimands that define treatment and interference effects. We then derive analytical expressions for the bias of a naive estimator that wrongly assumes away interference. The bias depends on the level of interference but also on the degree of association between individual and neighborhood treatments. We propose an extended unconfoundedness assumption that accounts for interference, and we develop new covariateadjustment methods that lead to valid estimates of treatment and interference effects in observational studies on networks. Estimation is based on a generalized propensity score that balances individual and neighborhood covariates across units under different levels of individual treatment and of exposure to neighbors' treatment. We carry out simulations, calibrated using friendship networks and covariates in a nationally representative longitudinal study of adolescents in grades 7\textendash 12 in the United States, to explore finite-sample performance in different realistic settings. Supplementary materials for this article are available online.},
  langid = {english},
  file = {/home/alex/Zotero/storage/LURRBK6L/Forastiere et al. - 2021 - Identification and Estimation of Treatment and Int.pdf}
}

@article{fosdick_testing_2015,
  title = {Testing and {{Modeling Dependencies Between}} a {{Network}} and {{Nodal Attributes}}},
  author = {Fosdick, Bailey K. and Hoff, Peter D.},
  year = {2015},
  month = jul,
  journal = {Journal of the American Statistical Association},
  volume = {110},
  number = {511},
  pages = {1047--1056},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2015.1008697},
  abstract = {Network analysis is often focused on characterizing the dependencies between network relations and node-level attributes. Potential relationships are typically explored by modeling the network as a function of the nodal attributes or by modeling the attributes as a function of the network.},
  langid = {english},
  file = {/home/alex/Zotero/storage/7BXAIL3C/Fosdick and Hoff - 2015 - Testing and Modeling Dependencies Between a Networ.pdf}
}

@article{founta_survey_nodate,
  title = {A {{Survey}} of {{Online Hate Speech}} through the {{Causal Lens}}},
  author = {Founta, Antigoni and Specia, Lucia},
  pages = {9},
  langid = {english},
  file = {/home/alex/Zotero/storage/2QXYKD37/Founta and Specia - A Survey of Online Hate Speech through the Causal .pdf}
}

@article{fredrickson_permutation_2019,
  title = {Permutation and Randomization Tests for Network Analysis},
  author = {Fredrickson, Mark M. and Chen, Yuguo},
  year = {2019},
  month = oct,
  journal = {Social Networks},
  volume = {59},
  pages = {171--183},
  issn = {03788733},
  doi = {10.1016/j.socnet.2019.08.001},
  abstract = {Permutation tests have a long history in testing hypotheses of independence between nodal attributes and network structure, though they are often thought less informative than parametric modeling techniques. In this paper, we show that when the nodal attribute is random assignment to a treatment condition, permutation tests provide a valid test of the causal effect of treatment. We discuss existing test statistics used in network permutation tests and propose several new statistics. In simulations we find that these statistics perform well compared to parametric tests and that specific statistics can be selected to provide power against common network models. We illustrate the methods with gene-wide association study performed on randomized study participants and an observational study of gender membership on Scandinavian corporate boards.},
  langid = {english},
  file = {/home/alex/Zotero/storage/THZLTSMN/Fredrickson and Chen - 2019 - Permutation and randomization tests for network an.pdf}
}

@article{frisch_partial_1933,
  title = {Partial {{Time Regressions}} as {{Compared}} with {{Individual Trends}}},
  author = {Frisch, Ragnar and Waugh, Frederick V.},
  year = {1933},
  month = oct,
  journal = {Econometrica},
  volume = {1},
  number = {4},
  pages = {387},
  issn = {00129682},
  doi = {10.2307/1907330},
  langid = {english},
  file = {/home/alex/Zotero/storage/NXTKKMMI/Frisch and Waugh - 1933 - Partial Time Regressions as Compared with Individu.pdf}
}

@article{fulcher_estimation_2018,
  title = {Estimation of Natural Indirect Effects Robust to Unmeasured Confounding and Mediator Measurement Error},
  author = {Fulcher, Isabel R. and Shi, Xu and Tchetgen, Eric J. Tchetgen},
  year = {2018},
  month = aug,
  journal = {arXiv:1808.03692 [stat]},
  eprint = {1808.03692},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The use of causal mediation analysis to evaluate the pathways by which an exposure affects an outcome is widespread in the social and biomedical sciences. Recent advances in this area have established formal conditions for identification and estimation of natural direct and indirect effects. However, these conditions typically involve stringent no unmeasured confounding assumptions and that the mediator has been measured without error. These assumptions may fail to hold in practice where mediation methods are often applied. The goal of this paper is two-fold. First, we show that the natural indirect effect can in fact be identified in the presence of unmeasured exposure-outcome confounding provided there is no additive interaction between the mediator and unmeasured confounder(s). Second, we introduce a new estimator of the natural indirect effect that is robust to both classical measurement error of the mediator and unmeasured confounding of both exposure-outcome and mediator-outcome relations under certain no interaction assumptions. We provide formal proofs and a simulation study to demonstrate our results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/6W2X5L5K/Fulcher et al. - 2018 - Estimation of natural indirect effects robust to u.pdf}
}

@article{fulcher_robust_2020,
  title = {Robust Inference on Population Indirect Causal Effects: The Generalized Front Door Criterion},
  shorttitle = {Robust Inference on Population Indirect Causal Effects},
  author = {Fulcher, Isabel R. and Shpitser, Ilya and Marealle, Stella and Tchetgen Tchetgen, Eric J.},
  year = {2020},
  month = feb,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {82},
  number = {1},
  pages = {199--214},
  issn = {13697412},
  doi = {10.1111/rssb.12345},
  abstract = {Standard methods for inference about direct and indirect effects require stringent no-unmeasuredconfounding assumptions which often fail to hold in practice, particularly in observational studies. The goal of the paper is to introduce a new form of indirect effect, the population intervention indirect effect, that can be non-parametrically identified in the presence of an unmeasured common cause of exposure and outcome. This new type of indirect effect captures the extent to which the effect of exposure is mediated by an intermediate variable under an intervention that holds the component of exposure directly influencing the outcome at its observed value. The population intervention indirect effect is in fact the indirect component of the population intervention effect, introduced by Hubbard and Van der Laan. Interestingly, our identification criterion generalizes Judea Pearl's front door criterion as it does not require no direct effect of exposure not mediated by the intermediate variable. For inference, we develop both parametric and semiparametric methods, including a novel doubly robust semiparametric locally efficient estimator, that perform very well in simulation studies. Finally, the methods proposed are used to measure the effectiveness of monetary saving recommendations among women enrolled in a maternal health programme in Tanzania.},
  langid = {english},
  file = {/home/alex/Zotero/storage/FY5LBLD3/Fulcher et al. - 2020 - Robust inference on population indirect causal eff.pdf}
}

@article{fytas_what_nodate,
  title = {What {{Makes}} a {{Scientific Paper}} Be {{Accepted}} for {{Publication}}?},
  author = {Fytas, Panagiotis and Rizos, Georgios and Specia, Lucia},
  pages = {17},
  langid = {english},
  file = {/home/alex/Zotero/storage/6VC5RWLZ/Fytas et al. - What Makes a Scientific Paper be Accepted for Publ.pdf}
}

@article{gao_testing_2021,
  title = {Testing for {{Association}} in {{Multi-View Network Data}}},
  author = {Gao, Lucy L. and Witten, Daniela and Bien, Jacob},
  year = {2021},
  month = mar,
  journal = {arXiv:1909.11640 [stat]},
  eprint = {1909.11640},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {In this paper, we consider data consisting of multiple networks, each comprised of a different edge set on a common set of nodes. Many models have been proposed for the analysis of such multi-view network data under the assumption that the data views are closely related. In this paper, we provide tools for evaluating this assumption. In particular, we ask: given two networks that each follow a stochastic block model, is there an association between the latent community memberships of the nodes in the two networks? To answer this question, we extend the stochastic block model for a single network view to the two-view setting, and develop a new hypothesis test for the null hypothesis that the latent community memberships in the two data views are independent. We apply our test to protein-protein interaction data from the HINT database (Das and Yu, 2012b). We find evidence of a weak association between the latent community memberships of proteins defined with respect to binary interaction data and the latent community memberships of proteins defined with respect to cocomplex association data. We also extend this proposal to the setting of a network with node covariates. The proposed methods extend readily to three or more network/multivariate data views.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/QUSEF6Z9/Gao et al. - 2021 - Testing for Association in Multi-View Network Data.pdf}
}

@article{ghassami_proximal_2021,
  title = {Proximal {{Causal Inference}} with {{Hidden Mediators}}: {{Front-Door}} and {{Related Mediation Problems}}},
  shorttitle = {Proximal {{Causal Inference}} with {{Hidden Mediators}}},
  author = {Ghassami, AmirEmad and Shpitser, Ilya and Tchetgen, Eric Tchetgen},
  year = {2021},
  month = nov,
  journal = {arXiv:2111.02927 [math, stat]},
  eprint = {2111.02927},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {Proximal causal inference was recently proposed as a framework to identify causal effects from observational data in the presence of hidden confounders for which proxies are available. In this paper, we extend the proximal causal approach to settings where identification of causal effects hinges upon a set of mediators which unfortunately are not directly observed, however proxies of the hidden mediators are measured. Specifically, we establish (i) a new hidden front-door criterion which extends the classical front-door result to allow for hidden mediators for which proxies are available; (ii) We extend causal mediation analysis to identify direct and indirect causal effects under unconfoundedness conditions in a setting where the mediator in view is hidden, but error prone proxies of the latter are available. We view (i) and (ii) as important steps towards the practical application of front-door criteria and mediation analysis as mediators are almost always error prone and thus, the most one can hope for in practice is that our measurements are at best proxies of mediating mechanisms. Finally, we show that identification of certain causal effects remains possible even in settings where challenges in (i) and (ii) might co-exist.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/AJP4Q5YA/Ghassami et al. - 2021 - Proximal Causal Inference with Hidden Mediators F.pdf}
}

@article{ghassami_proximal_2021-1,
  title = {Proximal {{Causal Inference}} with {{Hidden Mediators}}: {{Front-Door}} and {{Related Mediation Problems}}},
  shorttitle = {Proximal {{Causal Inference}} with {{Hidden Mediators}}},
  author = {Ghassami, AmirEmad and Shpitser, Ilya and Tchetgen, Eric Tchetgen},
  year = {2021},
  month = nov,
  journal = {arXiv:2111.02927 [math, stat]},
  eprint = {2111.02927},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {Proximal causal inference was recently proposed as a framework to identify causal effects from observational data in the presence of hidden confounders for which proxies are available. In this paper, we extend the proximal causal approach to settings where identification of causal effects hinges upon a set of mediators which unfortunately are not directly observed, however proxies of the hidden mediators are measured. Specifically, we establish (i) a new hidden front-door criterion which extends the classical front-door result to allow for hidden mediators for which proxies are available; (ii) We extend causal mediation analysis to identify direct and indirect causal effects under unconfoundedness conditions in a setting where the mediator in view is hidden, but error prone proxies of the latter are available. We view (i) and (ii) as important steps towards the practical application of front-door criteria and mediation analysis as mediators are almost always error prone and thus, the most one can hope for in practice is that our measurements are at best proxies of mediating mechanisms. Finally, we show that identification of certain causal effects remains possible even in settings where challenges in (i) and (ii) might co-exist.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/X6BXN95R/Ghassami et al. - 2021 - Proximal Causal Inference with Hidden Mediators F.pdf}
}

@article{giffin_generalized_2020,
  title = {Generalized Propensity Score Approach to Causal Inference with Spatial Interference},
  author = {Giffin, Andrew and Reich, Brian and Yang, Shu and Rappold, Ana},
  year = {2020},
  month = jun,
  journal = {arXiv:2007.00106 [stat]},
  eprint = {2007.00106},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Many spatial phenomena exhibit treatment interference where treatments at one location may affect the response at other locations. Because interference violates the stable unit treatment value assumption, standard methods for causal inference do not apply. We propose a new causal framework to recover direct and spill-over effects in the presence of spatial interference, taking into account that treatments at nearby locations are more influential than treatments at locations further apart. Under the no unmeasured confounding assumption, we show that a generalized propensity score is sufficient to remove all measured confounding. To reduce dimensionality issues, we propose a Bayesian spline-based regression model accounting for a sufficient set of variables for the generalized propensity score. A simulation study demonstrates the accuracy and coverage properties. We apply the method to estimate the causal effect of wildland fires on air pollution in the Western United States over 2005\textendash 2018.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/EGT4MPM9/Giffin et al. - 2020 - Generalized propensity score approach to causal in.pdf}
}

@article{giffin_instrumental_2021,
  title = {Instrumental Variables, Spatial Confounding and Interference},
  author = {Giffin, Andrew and Reich, Brian J. and Yang, Shu and Rappold, Ana G.},
  year = {2021},
  month = feb,
  journal = {arXiv:2103.00304 [stat]},
  eprint = {2103.00304},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Unobserved spatial confounding variables are prevalent in environmental and ecological applications where the system under study is complex and the data are often observational. Instrumental variables (IVs) are a common way to address unobserved confounding; however, the efficacy of using IVs on spatial confounding is largely unknown. This paper explores the effectiveness of IVs in this situation \textendash{} with particular attention paid to the spatial scale of the instrument. We show that, in case of spatially-dependent treatments, IVs are most effective when they vary at a finer spatial resolution than the treatment. We investigate IV performance in extensive simulations and apply the model in the example of long term trends in the air pollution and cardiovascular mortality in the United States over 1990-2010. Finally, the IV approach is also extended to the spatial interference setting, in which treatments can affect nearby responses.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62-02,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/DWAWPJ8R/Giffin et al. - 2021 - Instrumental variables, spatial confounding and in.pdf}
}

@article{gilbert_approaches_2021,
  title = {Approaches to Spatial Confounding in Geostatistics},
  author = {Gilbert, Brian and Datta, Abhirup and Ogburn, Elizabeth},
  year = {2021},
  month = dec,
  journal = {arXiv:2112.14946 [stat]},
  eprint = {2112.14946},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Research in the past few decades has discussed the concept of ``spatial confounding'' but has provided conflicting definitions and proposed solutions, some of which do not address the issue of confounding as it is understood in the field of causal inference. We give a clear account of spatial confounding as the existence of an unmeasured confounding variable with a spatial structure. Under certain conditions, including the smoothness of the confounder as a function of space, we show that spatial covariates (e.g. latitude and longitude) can be handled as typical covariates by algorithms popular in causal inference. We focus on ``double machine learning'' (DML) by which flexible models are fit for both the exposure and outcome variables to arrive at a causal estimator with favorable convergence properties. These models avoid restrictive assumptions, such as linearity and heterogeneity, which are present in linear models typically employed in spatial statistics and which can lead to strong bias when violated. We demonstrate the advantages of the DML approach analytically and via extensive simulation studies.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/AZ9GTLUA/Gilbert et al. - 2021 - Approaches to spatial confounding in geostatistics.pdf}
}

@article{glenski_identifying_nodate,
  title = {Identifying {{Causal Influences}} on {{Publication Trends}} and {{Behavior}}: {{A Case Study}} of the {{Computational Linguistics Community}}},
  author = {Glenski, Maria and Volkova, Svitlana},
  pages = {12},
  langid = {english},
  file = {/home/alex/Zotero/storage/J2TZHP8Y/Glenski and Volkova - Identifying Causal Influences on Publication Trend.pdf}
}

@article{glymour_comment_1986,
  title = {Comment: {{Statistics}} and {{Metaphysics}}},
  shorttitle = {Comment},
  author = {Glymour, Clark},
  year = {1986},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {81},
  number = {396},
  pages = {964--966},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1986.10478357},
  langid = {english},
  file = {/home/alex/Zotero/storage/6NJ2VJNN/Glymour - 1986 - Comment Statistics and Metaphysics.pdf}
}

@article{glymour_commentary_2014,
  title = {Commentary: {{Race}} and {{Sex Are Causes}}},
  shorttitle = {Commentary},
  author = {Glymour, Clark and Glymour, Madelyn R.},
  year = {2014},
  month = jul,
  journal = {Epidemiology},
  volume = {25},
  number = {4},
  pages = {488--490},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000122},
  langid = {english},
  file = {/home/alex/Zotero/storage/N7XDKGSI/Glymour and Glymour - 2014 - Commentary Race and Sex Are Causes.pdf}
}

@article{guan_spectral_2020,
  title = {A Spectral Adjustment for Spatial Confounding},
  author = {Guan, Yawen and Page, Garritt L. and Reich, Brian J. and Ventrucci, Massimo and Yang, Shu},
  year = {2020},
  month = dec,
  journal = {arXiv:2012.11767 [stat]},
  eprint = {2012.11767},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Adjusting for an unmeasured confounder is generally an intractable problem, but in the spatial setting it may be possible under certain conditions. In this paper, we derive necessary conditions on the coherence between the treatment variable of interest and the unmeasured confounder that ensure the causal effect of the treatment is estimable. We specify our model and assumptions in the spectral domain to allow for different degrees of confounding at different spatial resolutions. The key assumption that ensures identifiability is that confounding present at global scales dissipates at local scales. We show that this assumption in the spectral domain is equivalent to adjusting for global-scale confounding in the spatial domain by adding a spatially smoothed version of the treatment variable to the mean of the response variable. Within this general framework, we propose a sequence of confounder adjustment methods that range from parametric adjustments based on the Mat\textasciiacute ern coherence function to more robust semiparametric methods that use smoothing splines. These ideas are applied to areal and geostatistical data for both simulated and real datasets.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/N76DVGB4/Guan et al. - 2020 - A spectral adjustment for spatial confounding.pdf}
}

@article{guha_bayesian_2020,
  title = {Bayesian {{Causal Inference}} with {{Bipartite Record Linkage}}},
  author = {Guha, Sharmistha and Reiter, Jerome P. and Mercatanti, Andrea},
  year = {2020},
  month = sep,
  journal = {arXiv:2002.09119 [stat]},
  eprint = {2002.09119},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {In many scenarios, the observational data needed for causal inferences are spread over two data files. In particular, we consider scenarios where one file includes covariates and the treatment measured on one set of individuals, and a second file includes responses measured on another, partially overlapping set of individuals. In the absence of error free direct identifiers like social security numbers, straightforward merging of separate files is not feasible, so that records must be linked using error-prone variables such as names, birth dates, and demographic characteristics. Typical practice in such situations generally follows a two-stage procedure: first link the two files using a probabilistic linkage technique, then make causal inferences with the linked dataset. This does not propagate uncertainty due to imperfect linkages to the causal inference, nor does it leverage relationships among the study variables to improve the quality of the linkages. We propose a hierarchical model for simultaneous Bayesian inference on probabilistic linkage and causal effects that addresses these deficiencies. Using simulation studies and theoretical arguments, we show the hierarchical model can improve the accuracy of estimated treatment effects, as well as the record linkages, compared to the two-stage modeling option. We illustrate the hierarchical model using a causal study of the effects of debit card possession on household spending.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/NJSDI5AF/Guha et al. - 2020 - Bayesian Causal Inference with Bipartite Record Li.pdf}
}

@article{guha_bayesian_2021,
  title = {Bayesian {{Regression With Undirected Network Predictors With}} an {{Application}} to {{Brain Connectome Data}}},
  author = {Guha, Sharmistha and Rodriguez, Abel},
  year = {2021},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {116},
  number = {534},
  pages = {581--593},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2020.1772079},
  abstract = {This article focuses on the relationship between a measure of creativity and the human brain network for subjects in a brain connectome dataset obtained using a diffusion weighted magnetic resonance imaging procedure. We identify brain regions and interconnections that have a significant effect on creativity. Brain networks are often expressed in terms of symmetric adjacency matrices, with row and column indices of the matrix representing the regions of interest (ROI), and a cell entry signifying the estimated number of fiber bundles connecting the corresponding row and column ROIs. Current statistical practices for regression analysis with the brain network as the predictor and the measure of creativity as the response typically vectorize the network predictor matrices prior to any analysis, thus failing to account for the important structural information in the network. This results in poor inferential and predictive performance in presence of small sample sizes. To answer the scientific questions discussed above, we develop a flexible Bayesian framework that avoids reshaping the network predictor matrix, draws inference on brain ROIs and interconnections significantly related to creativity, and enables accurate prediction of creativity from a brain network. A novel class of network shrinkage priors for the coefficient corresponding to the network predictor is proposed to achieve these goals simultaneously. The Bayesian framework allows characterization of uncertainty in the findings. Empirical results in simulation studies illustrate substantial inferential and predictive gains of the proposed framework in comparison with the ordinary high-dimensional Bayesian shrinkage priors and penalized optimization schemes. Our framework yields new insights into the relationship of brain regions with creativity, also providing the uncertainty associated with the scientific findings. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
  langid = {english},
  file = {/home/alex/Zotero/storage/SY4ZC3K5/Guha and Rodriguez - 2021 - Bayesian Regression With Undirected Network Predic.pdf}
}

@article{guha_high_2020,
  title = {High {{Dimensional Bayesian Network Classification}} with {{Network Global-Local Shrinkage Priors}}},
  author = {Guha, Sharmistha and Rodriguez, Abel},
  year = {2020},
  month = sep,
  journal = {arXiv:2009.11401 [stat]},
  eprint = {2009.11401},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {This article proposes a novel Bayesian classification framework for networks with labeled nodes. While literature on statistical modeling of network data typically involves analysis of a single network, the recent emergence of complex data in several biological applications, including brain imaging studies, presents a need to devise a network classifier for subjects. This article considers an application from a brain connectome study, where the overarching goal is to classify subjects into two separate groups based on their brain network data, along with identifying influential regions of interest (ROIs) (referred to as nodes). Existing approaches either treat all edge weights as a long vector or summarize the network information with a few summary measures. Both these approaches ignore the full network structure, may lead to less desirable inference in small samples and are not designed to identify significant network nodes. We propose a novel binary logistic regression framework with the network as the predictor and a binary response, the network predictor coefficient being modeled using a novel class global-local shrinkage priors. The framework is able to accurately detect nodes and edges in the network influencing the classification. Our framework is implemented using an efficient Markov Chain Monte Carlo algorithm. Theoretically, we show asymptotically optimal classification for the proposed framework when the number of network edges grows faster than the sample size. The framework is empirically validated by extensive simulation studies and analysis of a brain connectome data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/9KXFN2SQ/Guha and Rodriguez - 2020 - High Dimensional Bayesian Network Classification w.pdf}
}

@article{guo_counterfactual_2019,
  title = {Counterfactual {{Evaluation}} of {{Treatment Assignment Functions}} with {{Networked Observational Data}}},
  author = {Guo, Ruocheng and Li, Jundong and Liu, Huan},
  year = {2019},
  month = dec,
  journal = {arXiv:1912.10536 [cs, stat]},
  eprint = {1912.10536},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Counterfactual evaluation of novel treatment assignment functions (e.g., advertising algorithms and recommender systems) is one of the most crucial causal inference problems for practitioners. Traditionally, randomized controlled trials (A/B tests) are performed to evaluate treatment assignment functions. However, such trials can be time-consuming, expensive, and even unethical in some cases. Therefore, offline counterfactual evaluation of treatment assignment functions becomes a pressing issue because a massive amount of observational data is available in today's big data era. Counterfactual evaluation requires handling the hidden confounders \textendash{} the unmeasured features which causally influence both the treatment assignment and the outcome. To deal with the hidden confounders, most of the existing methods rely on the assumption of no hidden confounders. However, this assumption can be untenable in the context of massive observational data. When such data comes with network information, the later can be potentially useful to correct hidden confounding bias. As such, we first formulate a novel problem, counterfactual evaluation of treatment assignment functions with networked observational data. Then, we investigate the following research questions: How can we utilize network information in counterfactual evaluation? Can network information improve the estimates in counterfactual evaluation? Toward answering these questions, first, we propose a novel framework, Counterfactual Network Evaluator (CONE), which (1) learns partial representations of latent confounders under the supervision of observed treatments and outcomes; and (2) combines them for counterfactual evaluation. Then through extensive experiments, we corroborate the effectiveness of CONE. The results imply that incorporating network information mitigates hidden confounding bias in counterfactual evaluation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/QVREUHXI/Guo et al. - 2019 - Counterfactual Evaluation of Treatment Assignment .pdf}
}

@inproceedings{guo_ignite_2020,
  title = {{{IGNITE}}: {{A Minimax Game Toward Learning Individual Treatment Effects}} from {{Networked Observational Data}}},
  shorttitle = {{{IGNITE}}},
  booktitle = {Proceedings of the {{Twenty-Ninth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Guo, Ruocheng and Li, Jundong and Li, Yichuan and Candan, K. Sel{\c c}uk and Raglin, Adrienne and Liu, Huan},
  year = {2020},
  month = jul,
  pages = {4534--4540},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Yokohama, Japan}},
  doi = {10.24963/ijcai.2020/625},
  abstract = {Networked observational data presents new opportunities for learning individual causal effects, which plays an indispensable role in decision making. Such data poses the challenge of confounding bias. Previous work presents two desiderata to handle confounding bias. On the treatment group level, we aim to balance the distributions of confounder representations. On the individual level, it is desirable to capture patterns of hidden confounders that predict treatment assignments. Existing methods show the potential of utilizing network information to handle confounding bias, but they only tries to satisfy one of the two desiderata. This is because the two desiderata seem to contradict each other. When the two distributions of confounder representations are highly overlapped, then we confront the undiscriminating problem between the treated and the controlled. In this work, we formulate the two desiderata as a minimax game. We propose IGNITE, a novel framework to learn representations of confounders from networked observational data, which is trained by a minimax game to achieve the two desiderata. Experiments verify the efficacy of IGNITE on two datasets under various settings.},
  isbn = {978-0-9992411-6-5},
  langid = {english},
  file = {/home/alex/Zotero/storage/FMV388LA/Guo et al. - 2020 - IGNITE A Minimax Game Toward Learning Individual .pdf}
}

@book{hayashi_econometrics_2000-1,
  title = {Econometrics},
  author = {Hayashi, Fumio},
  year = {2000},
  publisher = {{Princeton University Press}},
  address = {{Princeton}},
  isbn = {978-0-691-01018-2},
  lccn = {HB139 .H39 2000},
  keywords = {Econometrics},
  file = {/home/alex/Zotero/storage/IG43XVLK/Hayashi - 2000 - Econometrics.pdf}
}

@article{hodges_adding_2010,
  title = {Adding {{Spatially-Correlated Errors Can Mess Up}} the {{Fixed Effect You Love}}},
  author = {Hodges, James S. and Reich, Brian J.},
  year = {2010},
  month = nov,
  journal = {The American Statistician},
  volume = {64},
  number = {4},
  pages = {325--334},
  issn = {0003-1305, 1537-2731},
  doi = {10.1198/tast.2010.10052},
  langid = {english},
  file = {/home/alex/Zotero/storage/8WD9S7P3/Hodges and Reich - 2010 - Adding Spatially-Correlated Errors Can Mess Up the.pdf}
}

@article{hoff_bilinear_2005,
  title = {Bilinear {{Mixed-Effects Models}} for {{Dyadic Data}}},
  author = {Hoff, Peter D},
  year = {2005},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {100},
  number = {469},
  pages = {286--295},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214504000001015},
  langid = {english},
  file = {/home/alex/Zotero/storage/26QJ5K3E/Hoff - 2005 - Bilinear Mixed-Effects Models for Dyadic Data.pdf}
}

@article{hoff_latent_2002,
  title = {Latent {{Space Approaches}} to {{Social Network Analysis}}},
  author = {Hoff, Peter D and Raftery, Adrian E and Handcock, Mark S},
  year = {2002},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {97},
  number = {460},
  pages = {1090--1098},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214502388618906},
  langid = {english},
  file = {/home/alex/Zotero/storage/CRNWNHRN/Hoff et al. - 2002 - Latent Space Approaches to Social Network Analysis.pdf}
}

@article{hoteliinig_generalization_2022,
  title = {The {{Generalization}} of {{Student}}'s {{Ratio}}},
  author = {Hoteliinig, Harold},
  year = {2022},
  pages = {20},
  langid = {english},
  file = {/home/alex/Zotero/storage/P88BSC6F/Hoteliinig - 2022 - The Generalization of Student's Ratio.pdf}
}

@article{hsu_spatial_2015,
  title = {Spatial Mediation and Moderated Effect on {{FDI}} Performance: {{Empirical}} Study of {{Taiwanese}} Firms in {{China}} (1999\textendash 2008)},
  shorttitle = {Spatial Mediation and Moderated Effect on {{FDI}} Performance},
  author = {Hsu, Hsu-Wei and Jaw, Yi-Long},
  year = {2015},
  month = dec,
  journal = {Asia Pacific Management Review},
  volume = {20},
  number = {4},
  pages = {252--264},
  issn = {10293132},
  doi = {10.1016/j.apmrv.2015.03.002},
  abstract = {Taiwanese businesses exhibit a specific pattern when they enter into an uncertain territory, and tend to start off with a small amount of investments and explore markets by improvising strategies and tactics. This paper integrates theories concerning transaction costs and systems, and develops antecedent causes, and intervening and interference factors, by referring to the perspectives of economic geography. It is found that when faced with high uncertainties in emerging markets, multi-national corporations are highly concerned about institutional environments. Labor cost of different regions is an implicit indicator of the average wages that local companies are willing to pay. Companies that are willing to pay a high labor cost are less likely to face labor shortage, thus ensuring normal operation and better performance. \textcopyright{} 2015 College of Management, National Cheng Kung University. Production and hosting by Elsevier Taiwan LLC. All rights reserved.},
  langid = {english},
  file = {/home/alex/Zotero/storage/VBLBG9GN/Hsu and Jaw - 2015 - Spatial mediation and moderated effect on FDI perf.pdf}
}

@book{hu_econometrics_2022,
  title = {The {{Econometrics}} of {{Unobservables}}: {{Latent Variable}} and {{Measurement Error Models}} and {{Their Applications}} in {{Empirical Industrial Organization}} and {{Labor Economics}}},
  author = {Hu, Yingyao},
  year = {2022},
  langid = {english},
  file = {/home/alex/Zotero/storage/3QC24NG2/Hu - The Econometrics of Unobservables.pdf}
}

@misc{hu_race_2021,
  type = {Text},
  title = {Race, {{Policing}}, and the {{Limits}} of {{Social Science}}},
  author = {Hu, Lily},
  year = {2021},
  month = may,
  journal = {Boston Review},
  abstract = {Studying the social world requires more than deference to data. In some cases, it may even require that we reject findings\textemdash no matter the prestige or sophistication of the technical apparatus on which they are built.},
  howpublished = {https://bostonreview.net/science-nature-race/lily-hu-race-policing-and-limits-social-science},
  langid = {english},
  file = {/home/alex/Zotero/storage/DCDVTSVQ/lily-hu-race-policing-and-limits-social-science.html}
}

@article{hu_supervised_2022,
  title = {Supervised Tensor Decomposition with Features on Multiple Modes},
  author = {Hu, Jiaxin and Lee, Chanwoo and Wang, Miaoyan},
  year = {2022},
  month = jan,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {31},
  number = {1},
  eprint = {1910.09499},
  eprinttype = {arxiv},
  pages = {204--218},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2021.1978471},
  abstract = {Higher-order tensors have received increased attention across science and engineering. While most tensor decomposition methods are developed for a single tensor observation, scientific studies often collect side information, in the form of node features and interactions thereof, together with the tensor data. Such data problems are common in neuroimaging, network analysis, and spatial-temporal modeling. Identifying the relationship between a high-dimensional tensor and side information is important yet challenging. Here, we develop a tensor decomposition method that incorporates multiple feature matrices as side information. Unlike unsupervised tensor decomposition, our supervised decomposition captures the effective dimension reduction of the data tensor confined to feature space of interest. An efficient alternating optimization algorithm with provable spectral initialization is further developed. Our proposal handles a broad range of data types, including continuous, count, and binary observations. We apply the method to diffusion tensor imaging data from human connectome project and multi-relational political network data. We identify the key global connectivity pattern and pinpoint the local regions that are associated with available features. Our simulation code, R-package tensorregress, and datasets used in the paper are available at https://CRAN.R-project.org/package=tensorregress.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62H25; 62H12,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/J3DLTXT2/Hu et al. - 2022 - Supervised tensor decomposition with features on m.pdf}
}

@article{hu_whats_2020,
  title = {What's {{Sex Got}} to {{Do With Fair Machine Learning}}?},
  author = {Hu, Lily and {Kohler-Hausmann}, Issa},
  year = {2020},
  pages = {11},
  abstract = {The debate about fairness in machine learning has largely centered around competing substantive definitions of what fairness or nondiscrimination between groups requires. However, very little attention has been paid to what precisely a group is. Many recent approaches have abandoned observational, or purely statistical, definitions of fairness in favor of definitions that require one to specify a causal model of the data generating process. The implicit ontological assumption of these exercises is that a racial or sex group is a collection of individuals who share a trait or attribute, for example: the group ``female'' simply consists in grouping individuals who share female-coded sex features. We show this by exploring the formal assumption of modularity in causal models, which holds that the dependencies captured by one causal pathway are invariant to interventions on any other causal pathways. Modeling sex, for example, in a causal model proposes two substantive claims: 1) There exists a feature, sex-on-its-own, that is an inherent trait of an individual that then (causally) brings about social phenomena external to it in the world; and 2) the relations between sex and its downstream effects can be modified in whichever ways and the former feature would still retain the meaning that sex has in our world. We argue that these ontological assumptions about social groups like sex are conceptual errors. Many of the ``effects'' that sex purportedly ``causes'' are in fact constitutive features of sex as a social status. Together, they give the social meaning of sex features, and these social meanings are precisely what make sex discrimination a distinctively morally problematic type of act that differs from mere irrationality or meanness on the basis of a physical feature. Correcting this conceptual error has a number of important implications for how analytic models can be used to detect discrimination. If what makes something discrimination on the basis of a particular social grouping is that the practice acts on what it means to be in that group in a way that we deem wrongful, then what we need from analytic diagrams is a model of what constitutes the social grouping. Only then can we have a normative debate about what is fair or nondiscriminatory vis-\`a-vis that group. We suggest that formal diagrams of constitutive relations would present an entirely different path toward reasoning about discrimination (and relatedly, counterfactuals) because they proffer a model of how the meaning of a social group emerges from its constitutive features. Whereas the value of causal diagrams is to guide the construction and testing of sophisticated modular counterfactuals, the value of constitutive diagrams would be to identify a different kind of counterfactual as central to an inquiry on discrimination: one that asks how the social meaning of a group would be changed if its non-modular features were altered.},
  langid = {english},
  file = {/home/alex/Zotero/storage/WS2PXUSD/Hu and Kohler-Hausmann - 2020 - What’s Sex Got to Do With Fair Machine Learning.pdf}
}

@article{huang_hypothesis_2016,
  title = {Hypothesis Test of Mediation Effect in Causal Mediation Model with High-Dimensional Continuous Mediators: {{Hypothesis Test}} of {{Mediation Effect}} in {{Causal Mediation Model}} with {{High-Dimensional Continuous Mediators}}},
  shorttitle = {Hypothesis Test of Mediation Effect in Causal Mediation Model with High-Dimensional Continuous Mediators},
  author = {Huang, Yen-Tsung and Pan, Wen-Chi},
  year = {2016},
  month = jun,
  journal = {Biometrics},
  volume = {72},
  number = {2},
  pages = {402--413},
  issn = {0006341X},
  doi = {10.1111/biom.12421},
  abstract = {Causal mediation modeling has become a popular approach for studying the effect of an exposure on an outcome through a mediator. However, current methods are not applicable to the setting with a large number of mediators. We propose a testing procedure for mediation effects of high-dimensional continuous mediators. We characterize the marginal mediation effect, the multivariate component-wise mediation effects, and the L2 norm of the component-wise effects, and develop a MonteCarlo procedure for evaluating their statistical significance. To accommodate the setting with a large number of mediators and a small sample size, we further propose a transformation model using the spectral decomposition. Under the transformation model, mediation effects can be estimated using a series of regression models with a univariate transformed mediator, and examined by our proposed testing procedure. Extensive simulation studies are conducted to assess the performance of our methods for continuous and dichotomous outcomes. We apply the methods to analyze genomic data investigating the effect of microRNA miR-223 on a dichotomous survival status of patients with glioblastoma multiforme (GBM). We identify nine gene ontology sets with expression values that significantly mediate the effect of miR-223 on GBM survival.},
  langid = {english},
  file = {/home/alex/Zotero/storage/8UWVWPKQ/Huang and Pan - 2016 - Hypothesis test of mediation effect in causal medi.pdf}
}

@article{huberman_estimating_2020,
  title = {Estimating the Drivers of Species Distributions with Opportunistic Data Using Mediation Analysis},
  author = {Huberman, David B. and Reich, Brian J. and Pacifici, Krishna and Collazo, Jaime A.},
  year = {2020},
  month = jun,
  journal = {Ecosphere},
  volume = {11},
  number = {6},
  issn = {2150-8925, 2150-8925},
  doi = {10.1002/ecs2.3165},
  abstract = {Ecological occupancy modeling has historically relied on high-quality, low-quantity designedsurvey data for estimation and prediction. In recent years, there has been a large increase in the amount of high-quantity, unknown-quality opportunistic data. This has motivated research on how best to combine these two data sources in order to optimize inference. Existing methods can be infeasible for large datasets or require opportunistic data to be located where designed-survey data exist. These methods map species occupancies, motivating a need to properly evaluate covariate effects (e.g., land cover proportion) on their distributions. We describe a spatial estimation method for supplementarily including additional opportunistic data using mediation analysis concepts. The opportunistic data mediate the effect of the covariate on the designed-survey data response, decomposing it into a direct and indirect effect. A component of the indirect effect can then be quickly estimated via regressing the mediator on the covariate, while the other components are estimated through a spatial occupancy model. The regression step allows for use of large quantities of opportunistic data that can be collected in locations with no designed-survey data available. Simulation results suggest that the mediated method produces an improvement in relative MSE when the data are of reasonable quality. However, when the simulated opportunistic data are poorly correlated with the true spatial process, the standard, unmediated method is still preferable. A spatiotemporal extension of the method is also developed for analyzing the effect of deciduous forest land cover on red-eyed vireo distribution in the southeastern United States and find that including the opportunistic data do not lead to a substantial improvement. Opportunistic data quality remains an important consideration when employing this method, as with other data integration methods.},
  langid = {english},
  file = {/home/alex/Zotero/storage/N52LERDF/Huberman et al. - 2020 - Estimating the drivers of species distributions wi.pdf}
}

@article{hughes_dimension_2013,
  title = {Dimension Reduction and Alleviation of Confounding for Spatial Generalized Linear Mixed Models},
  shorttitle = {Dimension Reduction and Alleviation of Confounding for Spatial Generalized Linear Mixed Models},
  author = {Hughes, John and Haran, Murali},
  year = {2013},
  month = jan,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {75},
  number = {1},
  pages = {139--159},
  issn = {13697412},
  doi = {10.1111/j.1467-9868.2012.01041.x},
  abstract = {Non-Gaussian spatial data are very common in many disciplines. For instance, count data are common in disease mapping, and binary data are common in ecology.When fitting spatial regressions for such data, one needs to account for dependence to ensure reliable inference for the regression coefficients. The spatial generalized linear mixed model offers a very popular and flexible approach to modelling such data, but this model suffers from two major shortcomings: variance inflation due to spatial confounding and high dimensional spatial random effects that make fully Bayesian inference for such models computationally challenging. We propose a new parameterization of the spatial generalized linear mixed model that alleviates spatial confounding and speeds computation by greatly reducing the dimension of the spatial random effects. We illustrate the application of our approach to simulated binary, count and Gaussian spatial data sets, and to a large infant mortality data set.},
  langid = {english},
  file = {/home/alex/Zotero/storage/XSDATHRI/Hughes and Haran - 2013 - Dimension reduction and alleviation of confounding.pdf}
}

@article{iacobucci_mediation_2012,
  title = {Mediation Analysis and Categorical Variables: {{The}} Final Frontier},
  shorttitle = {Mediation Analysis and Categorical Variables},
  author = {Iacobucci, Dawn},
  year = {2012},
  month = oct,
  journal = {Journal of Consumer Psychology},
  volume = {22},
  number = {4},
  pages = {582--594},
  issn = {10577408},
  doi = {10.1016/j.jcps.2012.03.006},
  abstract = {Many scholars are interested in understanding the process by which an independent variable affects a dependent variable, perhaps in part directly and perhaps in part indirectly, occurring through the activation of a mediator. Researchers are facile at testing for mediation when all the variables are continuous, but a definitive answer had been lacking heretofore as to how to analyze the data when the mediator or dependent variable is categorical. This paper describes the problems that arise as well as the potential solutions. In the end, a solution is recommended that is both optimal in its statistical qualities as well as practical and easily implemented: compute zMediation.},
  langid = {english},
  file = {/home/alex/Zotero/storage/N7IM6H9B/Iacobucci - 2012 - Mediation analysis and categorical variables The .pdf}
}

@article{imai_general_2010,
  title = {A General Approach to Causal Mediation Analysis.},
  author = {Imai, Kosuke and Keele, Luke and Tingley, Dustin},
  year = {2010},
  journal = {Psychological Methods},
  volume = {15},
  number = {4},
  pages = {309--334},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0020761},
  abstract = {Traditionally in the social sciences, causal mediation analysis has been formulated, understood, and implemented within the framework of linear structural equation models. We argue and demonstrate that this is problematic for 3 reasons: the lack of a general definition of causal mediation effects independent of a particular statistical model, the inability to specify the key identification assumption, and the difficulty of extending the framework to nonlinear models. In this article, we propose an alternative approach that overcomes these limitations. Our approach is general because it offers the definition, identification, estimation, and sensitivity analysis of causal mediation effects without reference to any specific statistical model. Further, our approach explicitly links these 4 elements closely together within a single framework. As a result, the proposed framework can accommodate linear and nonlinear relationships, parametric and nonparametric models, continuous and discrete mediators, and various types of outcome variables. The general definition and identification result also allow us to develop sensitivity analysis in the context of commonly used models, which enables applied researchers to formally assess the robustness of their empirical conclusions to violations of the key assumption. We illustrate our approach by applying it to the Job Search Intervention Study. We also offer easy-to-use software that implements all our proposed methods.},
  langid = {english},
  file = {/home/alex/Zotero/storage/2T6ZS7FX/Imai et al. - 2010 - A general approach to causal mediation analysis..pdf}
}

@article{imai_identification_2010,
  title = {Identification, {{Inference}} and {{Sensitivity Analysis}} for {{Causal Mediation Effects}}},
  author = {Imai, Kosuke and Keele, Luke and Yamamoto, Teppei},
  year = {2010},
  month = feb,
  journal = {Statistical Science},
  volume = {25},
  number = {1},
  issn = {0883-4237},
  doi = {10.1214/10-STS321},
  abstract = {Causal mediation analysis is routinely conducted by applied researchers in a variety of disciplines. The goal of such an analysis is to investigate alternative causal mechanisms by examining the roles of intermediate variables that lie in the causal paths between the treatment and outcome variables. In this paper we first prove that under a particular version of sequential ignorability assumption, the average causal mediation effect (ACME) is nonparametrically identified. We compare our identification assumption with those proposed in the literature. Some practical implications of our identification result are also discussed. In particular, the popular estimator based on the linear structural equation model (LSEM) can be interpreted as an ACME estimator once additional parametric assumptions are made. We show that these assumptions can easily be relaxed within and outside of the LSEM framework and propose simple nonparametric estimation strategies. Second, and perhaps most importantly, we propose a new sensitivity analysis that can be easily implemented by applied researchers within the LSEM framework. Like the existing identifying assumptions, the proposed sequential ignorability assumption may be too strong in many applied settings. Thus, sensitivity analysis is essential in order to examine the robustness of empirical findings to the possible existence of an unmeasured confounder. Finally, we apply the proposed methods to a randomized experiment from political psychology. We also make easy-to-use software available to implement the proposed methods.},
  langid = {english},
  file = {/home/alex/Zotero/storage/66TCZ6S4/Imai et al. - 2010 - Identification, Inference and Sensitivity Analysis.pdf}
}

@article{imai_unpacking_2011,
  title = {Unpacking the {{Black Box}} of {{Causality}}: {{Learning}} about {{Causal Mechanisms}} from {{Experimental}} and {{Observational Studies}}},
  shorttitle = {Unpacking the {{Black Box}} of {{Causality}}},
  author = {Imai, Kosuke and Keele, Luke and Tingley, Dustin and Yamamoto, Teppei},
  year = {2011},
  month = nov,
  journal = {American Political Science Review},
  volume = {105},
  number = {4},
  pages = {765--789},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055411000414},
  abstract = {Identifying causal mechanisms is a fundamental goal of social science. Researchers seek to study not only whether one variable affects another but also how such a causal relationship arises. Yet commonly used statistical methods for identifying causal mechanisms rely upon untestable assumptions and are often inappropriate even under those assumptions. Randomizing treatment and intermediate variables is also insufficient. Despite these difficulties, the study of causal mechanisms is too important to abandon. We make three contributions to improve research on causal mechanisms. First, we present a minimum set of assumptions required under standard designs of experimental and observational studies and develop a general algorithm for estimating causal mediation effects. Second, we provide a method for assessing the sensitivity of conclusions to potential violations of a key assumption. Third, we offer alternative research designs for identifying causal mechanisms under weaker assumptions. The proposed approach is illustrated using media framing experiments and incumbency advantage studies.},
  langid = {english},
  file = {/home/alex/Zotero/storage/TTLGKFT5/Imai et al. - 2011 - Unpacking the Black Box of Causality Learning abo.pdf}
}

@article{jackson_decomposition_2018,
  title = {Decomposition {{Analysis}} to {{Identify Intervention Targets}} for {{Reducing Disparities}}},
  author = {Jackson, John W. and VanderWeele, Tyler J.},
  year = {2018},
  month = nov,
  journal = {Epidemiology},
  volume = {29},
  number = {6},
  pages = {825--835},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000901},
  abstract = {There has been considerable interest in using decomposition methods in epidemiology (mediation analysis) and economics (Oaxaca\textendash Blinder decomposition) to understand how health disparities arise and how they might change upon intervention. It has not been clear when estimates from the Oaxaca\textendash Blinder decomposition can be interpreted causally because its implementation does not explicitly address potential confounding of target variables. While mediation analysis does explicitly adjust for confounders of target variables, it typically does so in a way that effectively entails equalizing confounders across racial groups, which may not reflect the intended intervention. Revisiting prior analyses in the National Longitudinal Survey of Youth on disparities in wages, unemployment, incarceration, and overall health with test scores, taken as a proxy for educational attainment, as a target intervention, we propose and demonstrate a novel decomposition that controls for confounders of test scores (e.g., measures of childhood socioeconomic status [SES]) while leaving their association with race intact. We compare this decomposition with others that use standardization (to equalize childhood SES [the confounders] alone), mediation analysis (to equalize test scores within levels of childhood SES), and one that equalizes both childhood SES and test scores. We also show how these decompositions, including our novel proposals, are equivalent to implementations of the Oaxaca\textendash Blinder decomposition but provide a more formal causal interpretation for these decompositions.},
  langid = {english},
  file = {/home/alex/Zotero/storage/4ZRX278A/Jackson and VanderWeele - 2018 - Decomposition Analysis to Identify Intervention Ta.pdf}
}

@article{jin_how_2021,
  title = {How Social Network Influences Human Behavior: {{An}} Integrated Latent Space Approach},
  shorttitle = {How Social Network Influences Human Behavior},
  author = {Jin, Ick Hoon and Park, Jina and Jeon, Minjeong},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.05200 [cs, stat]},
  eprint = {2109.05200},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {How human behavior is influenced by a social network that they belong has been an interested topic in applied research. Existing methods often utilized scale-level behavioral data to estimate the influence of a social network on human behavior. This study proposes a novel approach to studying social influence by using item-level behavioral measures. Under the latent space modeling framework, we integrate the two latent spaces for respondents' social network data and item-level behavior measures. We then measure social influence as the impact of the latent space configuration contributed by the social network data on the behavior data. The performance and properties of the proposed approach are evaluated via simulation studies. We apply the proposed model to an empirical dataset to explain how students' friendship network influences their participation in school activities.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks,Statistics - Applications},
  file = {/home/alex/Zotero/storage/SVMP9P22/Jin et al. - 2021 - How social network influences human behavior An i.pdf}
}

@article{karrer_stochastic_2011,
  title = {Stochastic Blockmodels and Community Structure in Networks},
  author = {Karrer, Brian and Newman, M. E. J.},
  year = {2011},
  month = jan,
  journal = {Physical Review E},
  volume = {83},
  number = {1},
  eprint = {1008.3926},
  eprinttype = {arxiv},
  pages = {016107},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.83.016107},
  abstract = {Stochastic blockmodels have been proposed as a tool for detecting community structure in networks as well as for generating synthetic networks for use as benchmarks. Most blockmodels, however, ignore variation in vertex degree, making them unsuitable for applications to real-world networks, which typically display broad degree distributions that can significantly distort the results. Here we demonstrate how the generalization of blockmodels to incorporate this missing element leads to an improved objective function for community detection in complex networks. We also propose a heuristic algorithm for community detection using this objective function or its non-degree-corrected counterpart and show that the degree-corrected version dramatically outperforms the uncorrected one in both real-world and synthetic networks.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {/home/alex/Zotero/storage/6NLCQCJZ/Karrer and Newman - 2011 - Stochastic blockmodels and community structure in .pdf}
}

@article{kaufman_commentary_2014,
  title = {Commentary: {{Race}}},
  shorttitle = {Commentary},
  author = {Kaufman, Jay S.},
  year = {2014},
  month = jul,
  journal = {Epidemiology},
  volume = {25},
  number = {4},
  pages = {485--487},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000117},
  langid = {english},
  file = {/home/alex/Zotero/storage/ZFXVLC7N/Kaufman - 2014 - Commentary Race.pdf}
}

@inproceedings{keith_text_2020,
  title = {Text and {{Causal Inference}}: {{A Review}} of {{Using Text}} to {{Remove Confounding}} from {{Causal Estimates}}},
  shorttitle = {Text and {{Causal Inference}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Keith, Katherine and Jensen, David and O'Connor, Brendan},
  year = {2020},
  pages = {5332--5344},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2020.acl-main.474},
  abstract = {Many applications of computational social science aim to infer causal conclusions from nonexperimental data. Such observational data often contains confounders, variables that influence both potential causes and potential effects. Unmeasured or latent confounders can bias causal estimates, and this has motivated interest in measuring potential confounders from observed text. For example, an individual's entire history of social media posts or the content of a news article could provide a rich measurement of multiple confounders. Yet, methods and applications for this problem are scattered across different communities and evaluation practices are inconsistent. This review is the first to gather and categorize these examples and provide a guide to dataprocessing and evaluation decisions. Despite increased attention on adjusting for confounding using text, there are still many open problems, which we highlight in this paper.},
  langid = {english},
  file = {/home/alex/Zotero/storage/LJHLSTPW/Keith et al. - 2020 - Text and Causal Inference A Review of Using Text .pdf}
}

@inproceedings{keith_text_2021,
  title = {Text as {{Causal Mediators}}: {{Research Design}} for {{Causal Estimates}} of {{Differential Treatment}} of {{Social Groups}} via {{Language Aspects}}},
  booktitle = {Proceedings of {{CI}}+{{NLP}}: {{First Workshop}} on {{Causal Inference}} and {{NLP}}},
  author = {Keith, Katherine and Rice, Douglas and O'Connor, Brendan},
  year = {2021},
  month = nov,
  pages = {21--32},
  langid = {english},
  file = {/home/alex/Zotero/storage/M36QLPYV/Keith et al. - Text as Causal Mediators Research Design for Caus.pdf}
}

@article{kim_networkbased_2013,
  title = {Network-{{Based Penalized Regression With Application}} to {{Genomic Data}}},
  author = {Kim, Sunkyung and Pan, Wei and Shen, Xiaotong},
  year = {2013},
  month = sep,
  journal = {Biometrics},
  volume = {69},
  number = {3},
  pages = {582--593},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/biom.12035},
  abstract = {Penalized regression approaches are attractive in dealing with high-dimensional data such as arising in high-throughput genomic studies. New methods have been introduced to utilize the network structure of predictors, e.g. gene networks, to improve parameter estimation and variable selection. All the existing network-based penalized methods are based on an assumption that parameters, e.g. regression coefficients, of neighboring nodes in a network are close in magnitude, which however may not hold. Here we propose a novel penalized regression method based on a weaker prior assumption that the parameters of neighboring nodes in a network are likely to be zero (or non-zero) at the same time, regardless of their specific magnitudes. We propose a novel non-convex penalty function to incorporate this prior, and an algorithm based on difference convex programming. We use simulated data and two breast cancer gene expression datasets to demonstrate the advantages of the proposed method over some existing methods. Our proposed methods can be applied to more general problems for group variable selection.},
  langid = {english},
  file = {/home/alex/Zotero/storage/6GUTSSBD/Kim et al. - 2013 - Network‐Based Penalized Regression With Applicatio.pdf}
}

@techreport{koch_deep_2021,
  type = {Preprint},
  title = {Deep {{Learning}} of {{Potential Outcomes}}},
  author = {Koch, Bernard and Sainburg, Tim and Geraldo, Pablo and Jiang, Song and Sun, Yizhou and Foster, Jacob G.},
  year = {2021},
  month = oct,
  institution = {{SocArXiv}},
  doi = {10.31235/osf.io/aeszf},
  abstract = {This review systematizes the emerging literature for causal inference using deep neural networks under the potential outcomes framework. It provides an intuitive introduction on how deep learning can be used to estimate/predict heterogeneous treatment effects and extend causal inference to settings where confounding is non-linear, time varying, or encoded in text, networks, and images. To maximize accessibility, we also introduce prerequisite concepts from causal inference and deep learning. The survey differs from other treatments of deep learning and causal inference in its sharp focus on observational causal estimation, its extended exposition of key algorithms, and its detailed tutorials for implementing, training, and selecting among deep estimators in Tensorflow 2 available at github.com/kochbj/Deep-Learning-for-Causal-Inference.},
  langid = {english},
  keywords = {research},
  file = {/home/alex/Zotero/storage/2INLX679/Koch et al. - 2021 - Deep Learning of Potential Outcomes.pdf}
}

@article{kov2017a,
  title = {Digit Ratio (2d:4d) and Social Integration: {{An}} Effect of Prenatal Sex Hormones},
  author = {Kov{\`a}{\u r}{\'{\i}}k, Jarom{\'{\i}}r and Garza, Pablo Bra{\~n}as and Davidson, Michael W. and Haim, Dotan A. and Carcelli, Shannon and Fowler, James H.},
  year = {2017},
  journal = {Network Science},
  volume = {5},
  number = {4},
  doi = {10.1017/nws.2017.4.},
  langid = {english},
  file = {/home/alex/Zotero/storage/826XXNU6/Kovàr̆ı́k et al. - 2017 - Digit ratio (2d4d) and social integration An eff.pdf}
}

@article{land_large-sample_1992,
  title = {On the {{Large-Sample Estimation}} of {{Regression Models}} with {{Spatial- Or Network-Effects Terms}}: {{A Two-Stage Least Squares Approach}}},
  shorttitle = {On the {{Large-Sample Estimation}} of {{Regression Models}} with {{Spatial- Or Network-Effects Terms}}},
  author = {Land, Kenneth C. and Deane, Glenn},
  year = {1992},
  journal = {Sociological Methodology},
  volume = {22},
  pages = {221},
  issn = {00811750},
  doi = {10.2307/270997},
  langid = {english},
  file = {/home/alex/Zotero/storage/HI7CPE2W/Land and Deane - 1992 - On the Large-Sample Estimation of Regression Model.pdf}
}

@article{larsen_spatial_2020,
  title = {A Spatial Causal Analysis of Wildland Fire-Contributed {{PM2}}.5 Using Numerical Model Output},
  author = {Larsen, Alexandra and Yang, Shu and Reich, Brian J. and Rappold, Ana G.},
  year = {2020},
  month = mar,
  journal = {arXiv:2003.06037 [stat]},
  eprint = {2003.06037},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Wildland fire smoke contains hazardous levels of fine particulate matter (PM2.5), a pollutant shown to adversely effect health. Estimating fire attributable PM2.5 concentrations is key to quantifying the impact on air quality and subsequent health burden. This is a challenging problem since only total PM2.5 is measured at monitoring stations and both fire-attributable PM2.5 and PM2.5 from all other sources are correlated in space and time. We propose a framework for estimating fire-contributed PM2.5 and PM2.5 from all other sources using a novel causal inference framework and bias-adjusted chemical model representations of PM2.5 under counterfactual scenarios. The chemical model representation of PM2.5 for this analysis is simulated using Community Multi-Scale Air Quality Modeling System (CMAQ), run with and without fire emissions across the contiguous U.S. for the 2008-2012 wildfire seasons. The CMAQ output is calibrated with observations from monitoring sites for the same spatial domain and time period. We use a Bayesian model that accounts for spatial variation to estimate the effect of wildland fires on PM2.5 and state assumptions under which the estimate has a valid causal interpretation. Our results include estimates of absolute, relative and cumulative contributions of wildfire smoke to PM2.5 for the contiguous U.S. Additionally, we compute the health burden associated with the PM2.5 attributable to wildfire smoke.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/LMQWEK53/Larsen et al. - 2020 - A spatial causal analysis of wildland fire-contrib.pdf}
}

@article{latouche_overlapping_2011,
  title = {Overlapping Stochastic Block Models with Application to the {{French}} Political Blogosphere},
  author = {Latouche, Pierre and Birmel{\'e}, Etienne and Ambroise, Christophe},
  year = {2011},
  month = mar,
  journal = {The Annals of Applied Statistics},
  volume = {5},
  number = {1},
  eprint = {0910.2098},
  eprinttype = {arxiv},
  pages = {309--336},
  issn = {1932-6157},
  doi = {10.1214/10-AOAS382},
  abstract = {Complex systems in nature and in society are often represented as networks, describing the rich set of interactions between objects of interest. Many deterministic and probabilistic clustering methods have been developed to analyze such structures. Given a network, almost all of them partition the vertices into disjoint clusters, according to their connection profile. However, recent studies have shown that these techniques were too restrictive and that most of the existing networks contained overlapping clusters. To tackle this issue, we present in this paper the Overlapping Stochastic Block Model. Our approach allows the vertices to belong to multiple clusters, and, to some extent, generalizes the well-known Stochastic Block Model [Nowicki and Snijders (2001)]. We show that the model is generically identifiable within classes of equivalence and we propose an approximate inference procedure, based on global and local variational techniques. Using toy data sets as well as the French Political Blogosphere network and the transcriptional network of Saccharomyces cerevisiae, we compare our work with other approaches.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {/home/alex/Zotero/storage/K3DPEYC8/Latouche et al. - 2011 - Overlapping stochastic block models with applicati.pdf}
}

@book{lazega_collegial_2001,
  title = {The Collegial Phenomenon: The Social Mechanisms of Cooperation among Peers in a Corporate Law Partnership},
  shorttitle = {The Collegial Phenomenon},
  author = {Lazega, Emmanuel},
  year = {2001},
  publisher = {{Oxford University Press}},
  address = {{Oxford ; New York}},
  isbn = {978-0-19-924272-6},
  lccn = {KF300 .L34 2001},
  keywords = {Law firms,Lawyers,Organizational behavior,Social aspects,Social networks,United States},
  annotation = {OCLC: ocm46846863}
}

@article{le_linear_2021,
  title = {Linear Regression and Its Inference on Noisy Network-Linked Data},
  author = {Le, Can M. and Li, Tianxi},
  year = {2021},
  journal = {arXiv:2007.00803 [stat]},
  eprint = {2007.00803},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Linear regression on a set of observations linked by a network has been an essential tool in modeling the relationship between response and covariates with additional network data. Despite its wide range of applications in many areas, such as in social sciences and healthrelated research, the problem has not been well-studied in statistics so far. Previous methods either lack inference tools or rely on restrictive assumptions on social effects and usually assume that networks are observed without errors, which is unrealistic in many problems. This paper proposes a linear regression model with nonparametric network effects. The model does not assume that the relational data or network structure is exactly observed; thus, the method can be provably robust to a certain network perturbation level. A set of asymptotic inference results is established under a general requirement of the network observational errors, and the robustness of this method is studied in the specific setting when the errors come from random network models. We discover a phase-transition phenomenon of the inference validity concerning the network density when no prior knowledge of the network model is available while also showing a significant improvement achieved by knowing the network model. As a by-product of this analysis, we derive a rate-optimal concentration bound for random subspace projection that may be of independent interest. Extensive simulation studies are conducted to verify these theoretical results and demonstrate the advantage of the proposed method over existing work in terms of accuracy and computational efficiency under different data-generating models. The method is then applied to adolescent network data to study the gender and racial difference in social activities.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/IY8FP8WT/Le and Li - 2021 - Linear regression and its inference on noisy netwo.pdf}
}

@article{lee_identification_2007,
  title = {Identification and Estimation of Econometric Models with Group Interactions, Contextual Factors and Fixed Effects},
  author = {Lee, Lung-fei},
  year = {2007},
  month = oct,
  journal = {Journal of Econometrics},
  volume = {140},
  number = {2},
  pages = {333--374},
  issn = {03044076},
  doi = {10.1016/j.jeconom.2006.07.001},
  abstract = {This paper considers identification and estimation of structural interaction effects in a social interaction model. The model allows unobservables in the group structure, which may be correlated with included regressors. We show that both the endogenous and exogenous interaction effects can be identified if there are sufficient variations in group sizes. We consider the estimation of the model by the conditional maximum likelihood and instrumental variables methods. For the case with large group sizes, the possible identification can be weak in the sense that the estimates converge in distribution at low rates.},
  langid = {english},
  file = {/home/alex/Zotero/storage/K59GZVW8/Lee - 2007 - Identification and estimation of econometric model.pdf}
}

@article{lee_network_2019,
  title = {Network Dependence Testing via Diffusion Maps and Distance-Based Correlations},
  author = {Lee, Youjin and Shen, Cencheng and Priebe, Carey E and Vogelstein, Joshua T},
  year = {2019},
  month = dec,
  journal = {Biometrika},
  volume = {106},
  number = {4},
  pages = {857--873},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asz045},
  abstract = {Deciphering the associations between network connectivity and nodal attributes is one of the core problems in network science. The dependency structure and high dimensionality of networks pose unique challenges to traditional dependency tests in terms of theoretical guarantees and empirical performance. We propose an approach to test network dependence via diffusion maps and distance-based correlations. We prove that the new method yields a consistent test statistic under mild distributional assumptions on the graph structure, and demonstrate that it is able to efficiently identify the most informative graph embedding with respect to the diffusion time. The methodology is illustrated on both simulated and real data.},
  langid = {english},
  file = {/home/alex/Zotero/storage/XV7GW7V9/Lee et al. - 2019 - Network dependence testing via diffusion maps and .pdf}
}

@article{lee_network_2020,
  title = {Network {{Dependence Can Lead}} to {{Spurious Associations}} and {{Invalid Inference}}},
  author = {Lee, Youjin and Ogburn, Elizabeth L.},
  year = {2020},
  month = feb,
  journal = {arXiv:1908.00520 [stat]},
  eprint = {1908.00520},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Researchers across the health and social sciences generally assume that observations are independent, even while relying on convenience samples that draw subjects from one or a small number of communities, schools, hospitals, etc. A paradigmatic example of this is the Framingham Heart Study (FHS). Many of the limitations of such samples are well-known, but the issue of statistical dependence due to social network ties has not previously been addressed. We show that, along with anticonservative variance estimation, this can result in spurious associations due to network dependence. Using a statistical test that we adapted from one developed for spatial autocorrelation, we test for network dependence in several of the thousands of influential papers that have been published using FHS data. Results suggest that some of the many decades of research on coronary heart disease, other health outcomes, and peer influence using FHS data may suffer from spurious associations, error-prone point estimates, and anticonservative inference due to unacknowledged network dependence. These issues are not unique to the FHS; as researchers in psychology, medicine, and beyond grapple with replication failures, this unacknowledged source of invalid statistical inference should be part of the conversation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {to-read},
  file = {/home/alex/Zotero/storage/8WNVXKAD/Lee and Ogburn - 2020 - Network Dependence Can Lead to Spurious Associatio.pdf}
}

@article{lee_specification_nodate,
  title = {Specification and {{Estimation}} of {{Social Interaction Models}} with {{Network Structure}}, {{Contextual Factors}}, {{Correlation}} and {{Fixed E}}\textcurrency ects},
  author = {Lee, Lung-fei and Liu, Xiaodong},
  pages = {47},
  abstract = {This paper considers the speci\ldots cation and estimation of social interaction models with network structures and the presence of endogenous and contextural e\textcurrency ects. With macro group settings, group \ldots xed e\textcurrency ects are also incorporated. Networks provide information on the identi\ldots cation of endogenous, exogenous and unobserved interactions among speci\ldots c peers. We consider the identi\ldots cation and estimation of such a model. Empirical applications are provided to illustrate the usefulness of such a model. In addition to asymptotic properties of estimators, Monte Carlo studies provide evidence on \ldots nite sample performance of the estimation methods.},
  langid = {english},
  file = {/home/alex/Zotero/storage/VMC4CENQ/Lee and Liu - Speci…cation and Estimation of Social Interaction .pdf}
}

@article{leenders_modeling_2002,
  title = {Modeling Social Influence through Network Autocorrelation: Constructing the Weight Matrix},
  shorttitle = {Modeling Social Influence through Network Autocorrelation},
  author = {Leenders, Roger Th.A.J.},
  year = {2002},
  month = jan,
  journal = {Social Networks},
  volume = {24},
  number = {1},
  pages = {21--47},
  issn = {03788733},
  doi = {10.1016/S0378-8733(01)00049-1},
  abstract = {Many physical and social phenomena are embedded within networks of interdependencies, the so-called `context' of these phenomena. In network analysis, this type of process is typically modeled as a network autocorrelation model. Parameter estimates and inferences based on autocorrelation models, hinge upon the chosen specification of weight matrix W, the elements of which represent the influence pattern present in the network. In this paper I discuss how social influence processes can be incorporated in the specification of W. Theories of social influence center around `communication' and `comparison'; it is discussed how these can be operationalized in a network analysis context. Starting from that, a series of operationalizations of W is discussed. Finally, statistical tests are presented that allow an analyst to test various specifications against one another or pick the best fitting model from a set of models. \textcopyright{} 2002 Elsevier Science B.V. All rights reserved.},
  langid = {english},
  file = {/home/alex/Zotero/storage/DZ7H8HVV/That's a lot to process! Draft.pdf;/home/alex/Zotero/storage/X3KPY9VY/Leenders - 2002 - Modeling social influence through network autocorr.pdf}
}

@article{leung_causal_2019,
  title = {Causal {{Inference Under Approximate Neighborhood Interference}}},
  author = {Leung, Michael},
  year = {2019},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3479902},
  abstract = {This paper studies causal inference in randomized experiments under network interference. Commonly used models of interference posit that treatments assigned to alters beyond a certain network distance from the ego have no effect on the ego's response. However, this assumption is violated in common models of social interactions. We propose a substantially weaker model of ``approximate neighborhood interference'' (ANI) under which treatments assigned to alters further from the ego have smaller, but potentially nonzero, effects on the ego's response. We formally verify that ANI holds for well-known models of social interactions. Under ANI, restrictions on the network topology, and asymptotics under which the network size increases, we prove that standard inverse-probability weighting estimators consistently estimate useful exposure effects and are approximately normal. For inference, we consider a network HAC variance estimator. Under a finite population model, we show that the estimator is biased but that the bias can be interpreted as the variance of unit-level exposure effects. This generalizes Neyman's well-known result on conservative variance estimation to settings with interference.},
  langid = {english},
  file = {/home/alex/Zotero/storage/3DZKR843/Leung - 2019 - Causal Inference Under Approximate Neighborhood In.pdf}
}

@article{levin_central_2019,
  title = {A Central Limit Theorem for an Omnibus Embedding of Multiple Random Graphs and Implications for Multiscale Network Inference},
  author = {Levin, Keith and Athreya, Avanti and Tang, Minh and Lyzinski, Vince and Park, Youngser and Priebe, Carey E.},
  year = {2019},
  month = jun,
  journal = {arXiv:1705.09355 [stat]},
  eprint = {1705.09355},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Performing statistical analyses on collections of graphs is of import to many disciplines, but principled, scalable methods for multi-sample graph inference are few. Here we describe an "omnibus" embedding in which multiple graphs on the same vertex set are jointly embedded into a single space with a distinct representation for each graph. We prove a central limit theorem for this embedding and demonstrate how it streamlines graph comparison, obviating the need for pairwise subspace alignments. The omnibus embedding achieves near-optimal inference accuracy when graphs arise from a common distribution and yet retains discriminatory power as a test procedure for the comparison of different graphs. Moreover, this joint embedding and the accompanying central limit theorem are important for answering multiscale graph inference questions, such as the identification of specific subgraphs or vertices responsible for similarity or difference across networks. We illustrate this with a pair of analyses of connectome data derived from dMRI and fMRI scans of human subjects. In particular, we show that this embedding allows the identification of specific brain regions associated with population-level differences. Finally, we sketch how the omnibus embedding can be used to address pressing open problems, both theoretical and practical, in multisample graph inference.},
  archiveprefix = {arXiv},
  keywords = {to-read},
  file = {/home/alex/Zotero/storage/V5LNPHKU/Levin et al. - 2019 - A central limit theorem for an omnibus embedding o.pdf;/home/alex/Zotero/storage/4I34P4QB/1705.html}
}

@article{levin_integrating_nodate,
  title = {Integrating {{Low-Dimensional Network Models}} in {{Ordinary Least Squares Regression}}},
  author = {Levin, Keith and Fredrickson, Mark M},
  pages = {19},
  langid = {english},
  file = {/home/alex/Zotero/storage/TV89RSWZ/Levin and Fredrickson - Integrating Low-Dimensional Network Models in Ordi.pdf}
}

@article{levin_recovering_2022,
  title = {Recovering Shared Structure from Multiple Networks with Unknown Edge Distributions},
  author = {Levin, Keith and Lodhia, Asad and Levina, Elizaveta},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  pages = {1--48},
  abstract = {In increasingly many settings, data sets consist of multiple samples from a population of networks, with vertices aligned across networks; for example, brain connectivity networks in neuroscience. We consider the setting where the observed networks have a shared expectation, but may differ in the noise structure on their edges. Our approach exploits the shared mean structure to denoise edge-level measurements of the observed networks and estimate the underlying population-level parameters. We also explore the extent to which edge-level errors influence estimation and downstream inference. In the process, we establish a finite-sample concentration inequality for the low-rank eigenvalue truncation of a random weighted adjacency matrix, which may be of independent interest. The proposed approach is illustrated on synthetic networks and on data from an fMRI study of schizophrenia.},
  langid = {english},
  file = {/home/alex/Zotero/storage/C6S2VXEX/Levin et al. - Recovering shared structure from multiple networks.pdf}
}

@article{li_causal_2021,
  title = {Causal {{Inference}} under {{Network Interference}} with {{Noise}}},
  author = {Li, Wenrui and Sussman, Daniel L. and Kolaczyk, Eric D.},
  year = {2021},
  month = may,
  journal = {arXiv:2105.04518 [stat]},
  eprint = {2105.04518},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Increasingly, there is a marked interest in estimating causal effects under network interference due to the fact that interference manifests naturally in networked experiments. However, network information generally is available only up to some level of error. We study the propagation of such errors to estimators of average causal effects under network interference. Specifically, assuming a four-level exposure model and Bernoulli random assignment of treatment, we characterize the impact of network noise on the bias and variance of standard estimators in homogeneous and inhomogeneous networks. In addition, we propose method-of-moments estimators for bias reduction. We illustrate the practical performance of our estimators through simulation studies in British secondary school contact networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/8HHRPKDJ/Li et al. - 2021 - Causal Inference under Network Interference with N.pdf}
}

@article{li_connected_2022,
  title = {A Connected Network-Regularized Logistic Regression Model for Feature Selection},
  author = {Li, Lingyu and Liu, Zhi-Ping},
  year = {2022},
  month = jan,
  journal = {Applied Intelligence},
  issn = {0924-669X, 1573-7497},
  doi = {10.1007/s10489-021-02877-3},
  abstract = {Feature selection on a network structure can not only discover interesting variables but also mine out their intricate interactions. Regularization is often employed to ensure the sparsity and smoothness of the coefficients in logistic regression. However, currently available methods fail to embed the network connectivity in regularized penalty functions. In this paper, a connected network-regularized logistic regression (CNet-RLR) model for feature selection considering the structural connectivity in a network was proposed. Mathematically, it was a convex optimization problem constrained by inequalities reflecting network connectivity. Considering the non-differentiability of Lasso penalty, we constructed an equivalent formulation of CNet-RLR by employing auxiliary variables. An interior-point algorithm was designed to efficiently achieve the solutions. Theoretically, we proved their grouping effect and oracle property and guaranteed algorithmic convergence. In both synthetic simulation data and real-world uterine corpus endometrial carcinoma (UCEC) cancer genomics data, we validated the CNet-RLR model is efficient to identify the connected-network-structured features that can serve as diagnostic biomarkers. In the comparison study, we also proved the proposed CNet-RLR model results in better classification performance and feature interpretability than the other regularized logistic regression (RLR) alternatives and another graph embedded feature selection model.},
  langid = {english},
  file = {/home/alex/Zotero/storage/JWIB9J73/Li and Liu - 2022 - A connected network-regularized logistic regressio.pdf}
}

@article{li_double_2022,
  title = {Double {{Negative Control Inference}} in {{Test-Negative Design Studies}} of {{Vaccine Effectiveness}}},
  author = {Li, Kendrick Qijun and Shi, Xu and Miao, Wang and Tchetgen, Eric Tchetgen},
  year = {2022},
  month = mar,
  journal = {arXiv:2203.12509 [stat]},
  eprint = {2203.12509},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The test-negative design (TND) has become a standard approach to evaluate vaccine effectiveness against the risk of acquiring infectious diseases in real-world settings, such as Influenza, Rotavirus, Dengue fever, and more recently COVID-19. In a TND study, individuals who experience symptoms and seek care are recruited and tested for the infectious disease which defines cases and controls. Despite TND's potential to reduce unobserved differences in healthcare seeking behavior (HSB) between vaccinated and unvaccinated subjects, it remains subject to various potential biases. First, residual confounding bias may remain due to unobserved HSB, occupation as healthcare worker, or previous infection history. Second, because selection into the TND sample is a common consequence of infection and HSB, collider stratification bias may exist when conditioning the analysis on testing, which further induces confounding by latent HSB. In this paper, we present a novel approach to identify and estimate vaccine effectiveness in the target population by carefully leveraging a pair of negative control exposure and outcome variables to account for potential hidden bias in TND studies. We illustrate our proposed method with extensive simulation and an application to study COVID-19 vaccine effectiveness using data from the University of Michigan Health System.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/CEE5XYFT/Li et al. - 2022 - Double Negative Control Inference in Test-Negative.pdf}
}

@article{li_prediction_2019,
  title = {Prediction Models for Network-Linked Data},
  author = {Li, Tianxi and Levina, Elizaveta and Zhu, Ji},
  year = {2019},
  month = mar,
  journal = {The Annals of Applied Statistics},
  volume = {13},
  number = {1},
  pages = {132--164},
  issn = {1932-6157},
  doi = {10.1214/18-AOAS1205},
  langid = {english},
  keywords = {done},
  file = {/home/alex/Zotero/storage/NTHMK8Y7/Li et al. - 2019 - Prediction models for network-linked data.pdf}
}

@article{lin_identifying_2010,
  title = {Identifying {{Peer Effects}} in {{Student Academic Achievement}} by {{Spatial Autoregressive Models}} with {{Group Unobservables}}},
  author = {Lin, Xu},
  year = {2010},
  month = oct,
  journal = {Journal of Labor Economics},
  volume = {28},
  number = {4},
  pages = {825--860},
  issn = {0734-306X, 1537-5307},
  doi = {10.1086/653506},
  langid = {english},
  file = {/home/alex/Zotero/storage/ZZMMN2RC/Lin - 2010 - Identifying Peer Effects in Student Academic Achie.pdf}
}

@article{listgarten_correction_2010,
  title = {Correction for Hidden Confounders in the Genetic Analysis of Gene Expression},
  author = {Listgarten, Jennifer and Kadie, Carl and Schadt, Eric E. and Heckerman, David},
  year = {2010},
  month = sep,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {107},
  number = {38},
  pages = {16465--16470},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1002425107},
  abstract = {Understanding the genetic underpinnings of disease is important for screening, treatment, drug development, and basic biological insight. One way of getting at such an understanding is to find out which parts of our DNA, such as single-nucleotide polymorphisms, affect particular intermediary processes such as gene expression. Naively, such associations can be identified using a simple statistical test on all paired combinations of genetic variants and gene transcripts. However, a wide variety of confounders lie hidden in the data, leading to both spurious associations and missed associations if not properly addressed. We present a statistical model that jointly corrects for two particular kinds of hidden structure\textemdash population structure (e.g., race, family-relatedness), and microarray expression artifacts (e.g., batch effects), when these confounders are unknown. Applying our method to both real and synthetic, human and mouse data, we demonstrate the need for such a joint correction of confounders, and also the disadvantages of other possible approaches based on those in the current literature. In particular, we show that our class of models has maximum power to detect eQTL on synthetic data, and has the best performance on a bronze standard applied to real data. Lastly, our software and the associations we found with it are available at               http://www.microsoft.com/science               .},
  langid = {english},
  file = {/home/alex/Zotero/storage/T7EMB93S/Listgarten et al. - 2010 - Correction for hidden confounders in the genetic a.pdf}
}

@article{liu_doubly_2018,
  title = {Doubly {{Robust Estimation}} in {{Observational Studies}} with {{Partial Interference}}},
  author = {Liu, Lan and Hudgens, Michael G. and Saul, Bradley and Clemens, John D. and Ali, Mohammad and Emch, Michael E.},
  year = {2018},
  month = jun,
  journal = {arXiv:1806.07422 [stat]},
  eprint = {1806.07422},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Interference occurs when the treatment (or exposure) of one individual affects the outcomes of others. In some settings it may be reasonable to assume individuals can be partitioned into clusters such that there is no interference between individuals in different clusters, i.e., there is partial interference. In observational studies with partial interference, inverse probability weighted (IPW) estimators have been proposed of different possible treatment effects. However, the validity of IPW estimators depends on the propensity score being known or correctly modeled. Alternatively, one can estimate the treatment effect using an outcome regression model. In this paper, we propose doubly robust (DR) estimators which utilize both models and are consistent and asymptotically normal if either model, but not necessarily both, is correctly specified. Empirical results are presented to demonstrate the DR property of the proposed estimators, as well as the efficiency gain of DR over IPW estimators when both models are correctly specified. The different estimators are illustrated using data from a study examining the effects of cholera vaccination in Bangladesh.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/VYK6QTY8/Liu et al. - 2018 - Doubly Robust Estimation in Observational Studies .pdf}
}

@article{liu_regression-based_2020,
  title = {Regression-Based {{Negative Control}} of {{Homophily}} in {{Dyadic Peer Effect Analysis}}},
  author = {Liu, Lan and Tchetgen, Eric Tchetgen},
  year = {2020},
  month = feb,
  journal = {arXiv:2002.06521 [stat]},
  eprint = {2002.06521},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {A prominent threat to causal inference about peer effects over social networks is the presence of homophily bias, that is, social influence between friends and families is entangled with common characteristics or underlying similarities that form close connections. Analysis of social network data has suggested that certain health conditions such as obesity and psychological states including happiness and loneliness can spread over a network. However, such analyses of peer effects or contagion effects have come under criticism because homophily bias may compromise the causal statement. We develop a regressionbased approach which leverages a negative control exposure for identification and estimation of contagion effects on additive or multiplicative scales, in the presence of homophily bias. We apply our methods to evaluate the peer effect of obesity in Framingham Offspring Study.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/D6LDH7RH/Liu and Tchetgen - 2020 - Regression-based Negative Control of Homophily in .pdf}
}

@article{liu_social_2021,
  title = {Social {{Network Mediation Analysis}}: {{A Latent Space Approach}}},
  shorttitle = {Social {{Network Mediation Analysis}}},
  author = {Liu, Haiyan and Jin, Ick Hoon and Zhang, Zhiyong and Yuan, Ying},
  year = {2021},
  month = mar,
  journal = {Psychometrika},
  volume = {86},
  number = {1},
  pages = {272--298},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-020-09736-z},
  abstract = {A social network comprises both actors and the social connections among them. Such connections reflect the dependence among social actors, which is essential for individuals' mental health and social development. In this article, we propose a mediation model with a social network as a mediator to investigate the potential mediation role of a social network. In the model, the dependence among actors is accounted for by a few mutually orthogonal latent dimensions which form a social space. The individuals' positions in such a latent social space are directly involved in the mediation process between an independent and dependent variable. After showing that all the latent dimensions are equivalent in terms of their relationship to the social network and the meaning of each dimension is arbitrary, we propose to measure the whole mediation effect of a network. Although individuals' positions in the latent space are not unique, we rigorously articulate that the proposed network mediation effect is still well defined. We use a Bayesian estimation method to estimate the model and evaluate its performance through an extensive simulation study under representative conditions. The usefulness of the network mediation model is demonstrated through an application to a college friendship network.},
  langid = {english},
  file = {/home/alex/Zotero/storage/WMTYIK6H/Liu et al. - 2021 - Social Network Mediation Analysis A Latent Space .pdf}
}

@inproceedings{louizos_causal_2017,
  title = {Causal {{Effect Inference}} with {{Deep Latent-Variable Models}}},
  booktitle = {31st {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Louizos, Christos and Shalit, Uri and Mooij, Joris M and Sontag, David and Zemel, Richard and Welling, Max},
  year = {2017},
  pages = {11},
  address = {{Long Beach, CA, USA.}},
  abstract = {Learning individual-level causal effects from observational data, such as inferring the most effective medication for a specific patient, is a problem of growing importance for policy makers. The most important aspect of inferring causal effects from observational data is the handling of confounders, factors that affect both an intervention and its outcome. A carefully designed observational study attempts to measure all important confounders. However, even if one does not have direct access to all confounders, there may exist noisy and uncertain measurement of proxies for confounders. We build on recent advances in latent variable modeling to simultaneously estimate the unknown latent space summarizing the confounders and the causal effect. Our method is based on Variational Autoencoders (VAE) which follow the causal structure of inference with proxies. We show our method is significantly more robust than existing methods, and matches the state-of-the-art on previous benchmarks focused on individual treatment effects.},
  langid = {english},
  file = {/home/alex/Zotero/storage/AULBLRUU/Louizos et al. - Causal Effect Inference with Deep Latent-Variable .pdf}
}

@article{lovell_seasonal_1963,
  title = {Seasonal {{Adjustment}} of {{Economic Time Series}} and {{Multiple Regression Analysis}}},
  author = {Lovell, Michael C},
  year = {1963},
  journal = {Journal of the American Statistical Association},
  volume = {58},
  number = {304},
  pages = {993--1010},
  langid = {english},
  file = {/home/alex/Zotero/storage/W6WUPD25/Lovell - 2022 - Seasonal Adjustment of Economic Time Series and Mu.pdf}
}

@article{lovell_simple_2008,
  title = {A {{Simple Proof}} of the {{FWL Theorem}}},
  author = {Lovell, Michael C.},
  year = 2008,
  journal = {Journal of Economic Education},
  volume = {39},
  number = {1},
  pages = {88--91},
  publisher = {{Taylor \& Francis Ltd}},
  issn = {00220485},
  doi = {10.3200/JECE.39.1.88-91},
  abstract = {The author presents a simple proof of a property of the method of least squares variously known as the FWL, the Frisch-Waugh-Lovell, the Frisch-Waugh, or the decomposition theorem.},
  keywords = {Correlation (Statistics),decomposition theorem,Frisch-Waugh theorem,Frisch-Waugh-Lovell theorem,FWL theorem,Geodesy,Graphic methods,Least squares,Mathematical statistics,Mathematics}
}

@article{low_its_nodate,
  title = {It's Quality and Quantity: The Effect of the Amount of Comments on Online Suicidal Posts},
  author = {Low, Daniel and Zuromski, Kelly and Kessler, Daniel and Ghosh, Satrajit S and Nock, Matthew K and Dempsey, Walter},
  pages = {9},
  langid = {english},
  file = {/home/alex/Zotero/storage/SB54YIP8/Low et al. - It's quality and quantity the effect of the amoun.pdf}
}

@article{lu_weak_2015,
  title = {Weak Laws of Large Numbers for Sequences or Arrays of Correlated Random Variables},
  author = {Lu, Yuting},
  year = {2015},
  journal = {International Mathematical Forum},
  volume = {10},
  pages = {165--173},
  issn = {13147536},
  doi = {10.12988/imf.2015.5111},
  abstract = {In this paper we establish several weak laws of large numbers for sequences or arrays of correlated random variables based on estimates on variances of weighted sums.},
  langid = {english},
  file = {/home/alex/Zotero/storage/UQMSSVY2/Lu - 2015 - Weak laws of large numbers for sequences or arrays.pdf}
}

@article{lyzinski_community_2017,
  title = {Community {{Detection}} and {{Classification}} in {{Hierarchical Stochastic Blockmodels}}},
  author = {Lyzinski, Vince and Tang, Minh and Athreya, Avanti and Park, Youngser and Priebe, Carey E.},
  year = {2017},
  month = jan,
  journal = {IEEE Transactions on Network Science and Engineering},
  volume = {4},
  number = {1},
  pages = {13--26},
  issn = {2327-4697},
  doi = {10.1109/TNSE.2016.2634322},
  file = {/home/alex/Zotero/storage/DYRW8XH6/Lyzinski et al. - 2017 - Community Detection and Classification in Hierarch.pdf}
}

@article{lyzinski_perfect_2015,
  title = {Perfect {{Clustering}} for {{Stochastic Blockmodel Graphs}} via {{Adjacency Spectral Embedding}}},
  author = {Lyzinski, Vince and Sussman, Daniel and Tang, Minh and Athreya, Avanti and Priebe, Carey},
  year = {2015},
  month = jan,
  journal = {arXiv:1310.0532 [stat]},
  eprint = {1310.0532},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Vertex clustering in a stochastic blockmodel graph has wide applicability and has been the subject of extensive research. In this paper, we provide a short proof that the adjacency spectral embedding can be used to obtain perfect clustering for the stochastic blockmodel and the degree-corrected stochastic blockmodel. We also show an analogous result for the more general random dot product graph model.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/LHMTT3D9/Lyzinski et al. - 2015 - Perfect Clustering for Stochastic Blockmodel Graph.pdf}
}

@article{ma_apoe_2022,
  title = {{{APOE}} {$E$}4 and Late-Life Cognition: Mediation by Structural Brain Imaging Markers},
  shorttitle = {{{APOE}} {$E$}4 and Late-Life Cognition},
  author = {Ma, Yuan and Sajeev, Gautam and VanderWeele, Tyler J. and Viswanathan, Anand and Sigurdsson, Sigurdur and Eiriksdottir, Gudny and Aspelund, Thor and Betensky, Rebecca A. and Grodstein, Francine and Hofman, Albert and Gudnason, Vilmundur and Launer, Lenore and Blacker, Deborah},
  year = {2022},
  month = apr,
  journal = {European Journal of Epidemiology},
  issn = {0393-2990, 1573-7284},
  doi = {10.1007/s10654-022-00864-7},
  abstract = {The apolipoprotein E allele 4 (APOE-{$\epsilon$}4) is established as a major genetic risk factor for cognitive decline and late-onset Alzheimer's disease. Accumulating evidence has linked {$\epsilon$}4 carriership to abnormal structural brain changes across the adult lifespan. To better understand the underlying causal mechanisms, we investigated the extent to which the effect of the {$\epsilon$}4 allele on cognition is mediated by structural brain imaging markers in the population-based Age, Gene/Environment Susceptibility\textendash Reykjavik Study (AGES-Reykjavik). This study included 4527 participants (aged 76.3\,{$\pm$}\,5.4 at baseline) who underwent the brain magnetic resonance imaging assessment (of brain tissue volumes, white matter lesion volume, subcortical and cortical infarcts, and cerebral microbleeds) and a battery of neuropsychological tests at baseline. Causal mediation analysis was used to quantify the mediation of the {$\epsilon$}4 effect on cognition by these MRI markers, both individually and jointly. We observed that about 9\% of the total effect of {$\epsilon$}4 carriership on cognition was mediated by white matter lesion volume. This proportion increased to 25\% when total brain tissue volume was jointly considered with white matter lesion volume. In analyses separating {$\epsilon$}4 homozygotes from {$\epsilon$}4 heterozygotes, the effect on global cognition of specifically {$\epsilon$}4 homozygosity appeared to be partially mediated by cerebral microbleeds, particularly lobar microbleeds. There was no evidence of mediation of the {$\epsilon$}4 effect by cortical or subcortical infarcts. This study shows that the {$\epsilon$}4 effect on cognition is partly mediated by white matter lesion volume and total brain tissue volume. These findings suggest the joint role of cerebral small vessel disease and neurodegeneration in the {$\epsilon$}4-cognition relationship.},
  langid = {english},
  file = {/home/alex/Zotero/storage/I2S6QX4S/Ma et al. - 2022 - APOE ε4 and late-life cognition mediation by stru.pdf}
}

@article{ma_causal_nodate,
  title = {Causal {{Inference}} under {{Networked Interference}} and {{Intervention Policy Enhancement}}},
  author = {Ma, Yunpu and Tresp, Volker},
  pages = {11},
  abstract = {Estimating individual treatment effects from data of randomized experiments is a critical task in causal inference. The Stable Unit Treatment Value Assumption (SUTVA) is usually made in causal inference. However, interference can introduce bias when the assigned treatment on one unit affects the potential outcomes of the neighboring units. This interference phenomenon is known as spillover effect in economics or peer effect in social science. Usually, in randomized experiments, or observational studies with interconnected units, one can only observe treatment responses under interference. Hence, the issue of how to estimate the superimposed causal effect and recover the individual treatment effect in the presence of interference becomes a challenging task. In this work, we study causal effect estimation under general network interference using Graph Neural Networks, which are powerful tools for capturing node and link dependencies in graphs. After deriving causal effect estimators, we further study intervention policy improvement on the graph under capacity constraint. We give policy regret bounds under network interference and treatment capacity constraint.},
  langid = {english},
  file = {/home/alex/Zotero/storage/LQT3E9WM/Ma and Tresp - Causal Inference under Networked Interference and .pdf}
}

@article{mackinnon_estimating_1993,
  title = {Estimating {{Mediated Effects}} in {{Prevention Studies}}},
  author = {Mackinnon, David P. and Dwyer, James H.},
  year = {1993},
  month = apr,
  journal = {Evaluation Review},
  volume = {17},
  number = {2},
  pages = {144--158},
  issn = {0193-841X, 1552-3926},
  doi = {10.1177/0193841X9301700202},
  abstract = {The purpose of this article is to describe statistical procedures to assess how prevention and intervention programs achieve their effects. The analyses require the measurement of intervening or mediating variables hypothesized to represent the causal mechanism by which the prevention program achieves its effects. Methods to estimate mediation are illustrated in the evaluation of a health promotion program designed to reduce dietary cholesterol and a school-based drug prevention program. The methods are relatively easy to apply and the information gained from such analyses should add to our understanding of prevention.},
  langid = {english},
  file = {/home/alex/Zotero/storage/K5CGR6L4/Mackinnon and Dwyer - 1993 - Estimating Mediated Effects in Prevention Studies.pdf}
}

@article{manski_identification_1993,
  title = {Identification of {{Endogenous Social Effects}}: {{The Reflection Problem}}},
  shorttitle = {Identification of {{Endogenous Social Effects}}},
  author = {Manski, Charles F.},
  year = {1993},
  month = jul,
  journal = {The Review of Economic Studies},
  volume = {60},
  number = {3},
  pages = {531},
  issn = {00346527},
  doi = {10.2307/2298123},
  langid = {english},
  file = {/home/alex/Zotero/storage/KRCMHCKT/Manski - 1993 - Identification of Endogenous Social Effects The R.pdf}
}

@article{manski_identification_2013,
  title = {Identification of Treatment Response with Social Interactions},
  author = {Manski, Charles F},
  year = {2013},
  pages = {24},
  abstract = {This paper studies identification of potential outcome distributions when treatme response may have social interactions. Defining a person's treatment response to be a functio of the entire vector of treatments received by the population, I study identification when no parametric shape restrictions and distributional assumptions are placed on response function An early key result is that the traditional assumption of individualistic treatment response a polar case within the broad class of constant treatment response (CTR) assumptions, th other pole being unrestricted interactions. Important non-polar cases are interactions with reference groups and anonymous interactions. I first study identification under Assumptio CTR alone. I then strengthen this Assumption to semi-monotone response. I next discus derivation of these assumptions from models of endogenous interactions. Finally, I combin Assumption CTR with statistical independence of potential outcomes from realized effectiv treatments. The findings both extend and delimit the classical analysis of randomiz experiments.},
  langid = {english},
  file = {/home/alex/Zotero/storage/WKBEIYB8/Manski - 2022 - Identification of treatment response with social i.pdf}
}

@article{matous_external_2019-1,
  title = {External Exposure, Boundary-Spanning, and Opinion Leadership in Remote Communities: {{A}} Network Experiment},
  shorttitle = {External Exposure, Boundary-Spanning, and Opinion Leadership in Remote Communities},
  author = {Matous, Petr and Wang, Peng},
  year = {2019},
  month = jan,
  journal = {Social Networks},
  volume = {56},
  pages = {10--22},
  issn = {03788733},
  doi = {10.1016/j.socnet.2018.08.002},
  abstract = {Are boundary spanners opinion leaders in ethnically segregated remote low-income communities or are they shunned? Can external exposure create opinion leaders in such peripheral communities? To answer these questions, we invited randomly selected farmers from 16 randomly selected communities in Sumatra to threeday networking and training events outside of their villages. The substantive purpose of these events was for the farmers to learn new practices from their peers in the visited locations. Eighteen months later, we conducted a sociocentric survey of information-sharing networks in the 16 communities. These 16 networks included 380 members, of which 117 participated in our randomized intervention and 263 were in the control group. We found that participants of our randomized intervention had an average indegree that was double that of the control group (2.8 vs 1.4). We applied Exponential Random Graph Models to the 16 networks to account for endogenous network tendencies. We treated participation in the intervention and the number of boundaryspanning links of each actor as node covariates. Results from our models show that actors who participated in the intervention had higher levels of influence in their communities than the control group, and actors with more boundary spanning links were more popular sources of advice. The results suggest that network interventions do not always need to rely on opinion leaders. Under certain conditions, interventions can create opinion leaders by changing local social networks. We conclude with methodological implications for using interventions in social network research.},
  langid = {english},
  file = {/home/alex/Zotero/storage/P26Y5FFV/Matous and Wang - 2019 - External exposure, boundary-spanning, and opinion .pdf}
}

@article{mayer_missdeepcausal_2020,
  title = {{{MissDeepCausal}}: {{Causal Inference}} from {{Incomplete Data Using Deep Latent Variable Models}}},
  shorttitle = {{{MissDeepCausal}}},
  author = {Mayer, Imke and Josse, Julie and Raimundo, F{\'e}lix and Vert, Jean-Philippe},
  year = {2020},
  month = feb,
  journal = {arXiv:2002.10837 [cs, stat]},
  eprint = {2002.10837},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Inferring causal effects of a treatment, intervention or policy from observational data is central to many applications. However, state-of-the-art methods for causal inference seldom consider the possibility that covariates have missing values, which is ubiquitous in many real-world analyses. Missing data greatly complicate causal inference procedures as they require an adapted unconfoundedness hypothesis which can be difficult to justify in practice. We circumvent this issue by considering latent confounders whose distribution is learned through variational autoencoders adapted to missing values. They can be used either as a pre-processing step prior to causal inference but we also suggest to embed them in a multiple imputation strategy to take into account the variability due to missing values. Numerical experiments demonstrate the effectiveness of the proposed methodology especially for non-linear models compared to competitors.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/4WREZFDA/Mayer et al. - 2020 - MissDeepCausal Causal Inference from Incomplete D.pdf}
}

@article{mcfowland_iii_estimating_2021,
  title = {Estimating {{Causal Peer Influence}} in {{Homophilous Social Networks}} by {{Inferring Latent Locations}}},
  author = {McFowland III, Edward and Shalizi, Cosma Rohilla},
  year = {2021},
  month = jun,
  journal = {arXiv:1607.06565 [physics, stat]},
  eprint = {1607.06565},
  eprinttype = {arxiv},
  primaryclass = {physics, stat},
  abstract = {Social influence cannot be identified from purely observational data on social networks, because such influence is generically confounded with latent homophily, i.e., with a node's network partners being informative about the node's attributes and therefore its behavior. If the network grows according to either a latent community (stochastic block) model, or a continuous latent space model, then latent homophilous attributes can be consistently estimated from the global pattern of social ties. We show that, for common versions of those two network models, these estimates are so informative that controlling for estimated attributes allows for asymptotically unbiased and consistent estimation of social-influence effects in linear models. In particular, the bias shrinks at a rate which directly reflects how much information the network provides about the latent attributes. These are the first results on the consistent non-experimental estimation of social-influence effects in the presence of latent homophily, and we discuss the prospects for generalizing them.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/H2MWIZA2/McFowland III and Shalizi - 2021 - Estimating Causal Peer Influence in Homophilous So.pdf}
}

@article{meng_linear_2016,
  title = {Linear Regression with an Estimated Regressor: Applications to Aggregate Indicators of Economic Development},
  shorttitle = {Linear Regression with an Estimated Regressor},
  author = {Meng, Lingsheng and Wu, Binzhen and Zhan, Zhaoguo},
  year = {2016},
  month = mar,
  journal = {Empirical Economics},
  volume = {50},
  number = {2},
  pages = {299--316},
  issn = {0377-7332, 1435-8921},
  doi = {10.1007/s00181-015-0941-z},
  abstract = {This study examines the consequences of using an estimated aggregate measure as an explanatory variable in linear regression. We show that neglecting the seemingly small sampling error in the estimated regressor could severely contaminate the estimates. We propose a simple statistical framework to account for the error. In particular, we apply our analysis to two aggregate indicators of economic development, the Gini coefficient and sex ratio. Our findings suggest that the impact of the estimated regressor could be substantially underestimated, when the sampling error is not accounted for.},
  langid = {english},
  file = {/home/alex/Zotero/storage/JBPYDW3T/Meng et al. - 2016 - Linear regression with an estimated regressor app.pdf}
}

@article{miles_semiparametric_2019,
  title = {On Semiparametric Estimation of a Path-Specific Effect in the Presence of Mediator-Outcome Confounding},
  author = {Miles, C H and Shpitser, I and Kanki, P and Meloni, S and Tchetgen Tchetgen, E J},
  year = {2019},
  month = nov,
  journal = {Biometrika},
  pages = {asz063},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asz063},
  abstract = {Summary             Path-specific effects constitute a broad class of mediated effects from an exposure to an outcome via one or more causal pathways along a set of intermediate variables. Most of the literature concerning estimation of mediated effects has focused on parametric models, with stringent assumptions regarding unmeasured confounding. We consider semiparametric inference of a path-specific effect when these assumptions are relaxed. In particular, we develop a suite of semiparametric estimators for the effect along a pathway through a mediator, but not through an exposure-induced confounder of that mediator. These estimators have different robustness properties, as each depends on different parts of the likelihood of the observed data. One estimator is locally semiparametric efficient and multiply robust. The latter property implies that machine learning can be used to estimate nuisance functions. We demonstrate these properties, as well as finite-sample properties of all the estimators, in a simulation study. We apply our method to an HIV study, in which we estimate the effect comparing two drug treatments on a patient's average log CD4 count mediated by the patient's level of adherence, but not by previous experience of toxicity, which is clearly affected by which treatment the patient is assigned to and may confound the effect of the patient's level of adherence on their virologic outcome.},
  langid = {english},
  file = {/home/alex/Zotero/storage/Q48ZI9SW/Miles et al. - 2019 - On semiparametric estimation of a path-specific ef.pdf}
}

@book{moraga_geospatial_2019,
  title = {Geospatial {{Health Data}}: {{Modeling}} and {{Visualization}} with {{R-INLA}} and {{Shiny}}},
  shorttitle = {Geospatial {{Health Data}}},
  author = {Moraga, Paula},
  year = {2019},
  month = nov,
  edition = {First},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/9780429341823},
  isbn = {978-0-429-34182-3},
  langid = {english},
  file = {/home/alex/Zotero/storage/QW5VF3IQ/Moraga - 2019 - Geospatial Health Data Modeling and Visualization.pdf}
}

@incollection{morgan_social_2013,
  title = {Social {{Networks}} and {{Causal Inference}}},
  booktitle = {Handbook of {{Causal Analysis}} for {{Social Research}}},
  author = {VanderWeele, Tyler J. and An, Weihua},
  editor = {Morgan, Stephen L.},
  year = {2013},
  pages = {353--374},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-007-6094-3_17},
  abstract = {This chapter reviews theoretical developments and empirical studies related to causal inference on social networks from both experimental and observational studies. Discussion is given to the effect of experimental interventions on outcomes and behaviors and how these effects relate to the presence of social ties, the position of individuals within the network, and the underlying structure and properties of the network. The effects of such experimental interventions on changing the network structure itself and potential feedback between behaviors and network changes are also discussed. With observational data, correlations in behavior or outcomes between individuals with network ties may be due to social influence, homophily, or environmental confounding. With cross-sectional data these three sources of correlation cannot be distinguished. Methods employing longitudinal observational data that can help distinguish between social influence, homophily, and environmental confounding are described, along with their limitations. Proposals are made regarding future research directions and methodological developments that would help put causal inference on social networks on a firmer theoretical footing.},
  isbn = {978-94-007-6093-6 978-94-007-6094-3},
  langid = {english},
  file = {/home/alex/Zotero/storage/I97GSN9Q/VanderWeele and An - 2013 - Social Networks and Causal Inference.pdf}
}

@article{mouw_estimating_2006-1,
  title = {Estimating the {{Causal Effect}} of {{Social Capital}}: {{A Review}} of {{Recent Research}}},
  shorttitle = {Estimating the {{Causal Effect}} of {{Social Capital}}},
  author = {Mouw, Ted},
  year = {2006},
  month = aug,
  journal = {Annual Review of Sociology},
  volume = {32},
  number = {1},
  pages = {79--102},
  issn = {0360-0572, 1545-2115},
  doi = {10.1146/annurev.soc.32.061604.123150},
  abstract = {Although there is a large literature on social capital, empirical estimates of the effect of social capital may be biased because of social homophily, the tendency of similar people to become friends with each other. Despite the methodological difficulties, a recent literature has emerged across several different disciplines that tries to estimate the causal effect of social capital. This paper reviews this recent empirical literature on social capital, paying close attention to the statistical and theoretical assumptions involved. Overall, there is evidence that genuine progress has been made in estimating the effect of social capital. The reviewed articles should provide useful examples for future research.},
  langid = {english},
  file = {/home/alex/Zotero/storage/UKEU2EHH/Mouw - 2006 - Estimating the Causal Effect of Social Capital A .pdf}
}

@article{murphy_estimation_2002,
  title = {Estimation and {{Inference}} in {{Two-Step Econometric Models}}},
  author = {Murphy, Kevin M and Topel, Robert H},
  year = {2002},
  month = jan,
  journal = {Journal of Business \& Economic Statistics},
  volume = {20},
  number = {1},
  pages = {88--97},
  issn = {0735-0015, 1537-2707},
  doi = {10.1198/073500102753410417},
  langid = {english},
  file = {/home/alex/Zotero/storage/QBJ768FF/Murphy and Topel - 2002 - Estimation and Inference in Two-Step Econometric M.pdf}
}

@article{nguyen_causal_2021,
  title = {Causal Mediation Analysis: {{From}} Simple to More Robust Strategies for Estimation of Marginal Natural (in)Direct Effects},
  shorttitle = {Causal Mediation Analysis},
  author = {Nguyen, Trang Quynh and Ogburn, Elizabeth L. and Sarker, Elizabeth B. and Greifer, Noah and Schmid, Ian and Koning, Ina M. and Stuart, Elizabeth A.},
  year = {2021},
  month = may,
  journal = {arXiv:2102.06048 [stat]},
  eprint = {2102.06048},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {This paper aims to provide practitioners of causal mediation analysis with a better understanding of estimation options. We take as inputs two familiar strategies (weighting and model-based prediction) and a simple way of combining them (weighted models), and show how we can generate a range of estimators with different modeling requirements and robustness properties. The primary goal is to help build intuitive appreciation for robust estimation that is conducive to sound practice. A second goal is to provide a ``menu'' of estimators that practitioners can choose from for the estimation of marginal natural (in)direct effects. The estimators generated from this exercise include some that coincide or are similar to existing estimators and others that have not previously appeared in the literature. We note several different ways to estimate the weights for cross-world weighting based on three expressions of the weighting function, including one that is novel; and show how to check the resulting covariate and mediator balance. We use a random continuous weights bootstrap to obtain confidence intervals, and also derive general asymptotic (sandwich) variance formulas for the estimators. The estimators are illustrated using data from an adolescent alcohol use prevention study.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/Y838U4CN/Nguyen et al. - 2021 - Causal mediation analysis From simple to more rob.pdf}
}

@article{nikitin_non-separable_2022,
  title = {Non-Separable {{Spatio-temporal Graph Kernels}} via {{SPDEs}}},
  author = {Nikitin, Alexander and John, S. T. and Solin, Arno and Kaski, Samuel},
  year = {2022},
  month = mar,
  journal = {arXiv:2111.08524 [cs, stat]},
  eprint = {2111.08524},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Gaussian processes (GPs) provide a principled and direct approach for inference and learning on graphs. However, the lack of justified graph kernels for spatio-temporal modelling has held back their use in graph problems. We leverage an explicit link between stochastic partial differential equations (SPDEs) and GPs on graphs, introduce a framework for deriving graph kernels via SPDEs, and derive non-separable spatio-temporal graph kernels that capture interaction across space and time. We formulate the graph kernels for the stochastic heat equation and wave equation. We show that by providing novel tools for spatio-temporal GP modelling on graphs, we outperform pre-existing graph kernels in realworld applications that feature diffusion, oscillation, and other complicated interactions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/PUZ5XWAP/Nikitin et al. - 2022 - Non-separable Spatio-temporal Graph Kernels via SP.pdf}
}

@article{ogburn_bias_2013,
  title = {Bias Attenuation Results for Nondifferentially Mismeasured Ordinal and Coarsened Confounders},
  author = {Ogburn, E. L. and Vanderweele, T. J.},
  year = {2013},
  month = mar,
  journal = {Biometrika},
  volume = {100},
  number = {1},
  pages = {241--248},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/ass054},
  abstract = {Suppose we are interested in the effect of a binary treatment on an outcome where that relationship is confounded by an ordinal confounder. We assume that the true confounder is not observed, rather we observe a nondifferentially mismeasured version of it. We show that under certain monotonicity assumptions about its effect on the treatment and on the outcome, an effect measure controlling for the mismeasured confounder will fall between its corresponding crude and the true effect measures. We present results for coarsened, and, under further assumptions, for multiple misclassified confounders.},
  langid = {english},
  file = {/home/alex/Zotero/storage/3PKPXMB9/Ogburn and Vanderweele - 2013 - Bias attenuation results for nondifferentially mis.pdf}
}

@article{ogburn_causal_2014,
  title = {Causal {{Diagrams}} for {{Interference}}},
  author = {Ogburn, Elizabeth L. and VanderWeele, Tyler J.},
  year = {2014},
  month = nov,
  journal = {Statistical Science},
  volume = {29},
  number = {4},
  pages = {559--578},
  issn = {0883-4237},
  doi = {10.1214/14-STS501},
  abstract = {The term ``interference'' has been used to describe any setting in which one subject's exposure may affect another subject's outcome. We use causal diagrams to distinguish among three causal mechanisms that give rise to interference. The first causal mechanism by which interference can operate is a direct causal effect of one individual's treatment on another individual's outcome; we call this direct interference. Interference by contagion is present when one individual's outcome may affect the outcomes of other individuals with whom he comes into contact. Then giving treatment to the first individual could have an indirect effect on others through the treated individual's outcome. The third pathway by which interference may operate is allocational interference. Treatment in this case allocates individuals to groups; through interactions within a group, individuals may affect one another's outcomes in any number of ways. In many settings, more than one type of interference will be present simultaneously. The causal effects of interest differ according to which types of interference are present, as do the conditions under which causal effects are identifiable. Using causal diagrams for interference, we describe these differences, give criteria for the identification of important causal effects, and discuss applications to infectious diseases.},
  langid = {english},
  file = {/home/alex/Zotero/storage/GZYLPVE7/Ogburn and VanderWeele - 2014 - Causal Diagrams for Interference.pdf}
}

@article{ogburn_causal_2020-1,
  title = {Causal Inference for Social Network Data},
  author = {Ogburn, Elizabeth L. and Sofrygin, Oleg and Diaz, Ivan and {van der Laan}, Mark J.},
  year = {2020},
  month = feb,
  journal = {arXiv:1705.08527 [math, stat]},
  eprint = {1705.08527},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {We describe semiparametric estimation and inference for causal effects using observational data from a single social network. Our asymptotic result is the first to allow for dependence of each observation on a growing number of other units as sample size increases. While previous methods have generally implicitly focused on one of two possible sources of dependence among social network observations, we allow for both dependence due to transmission of information across network ties, and for dependence due to latent similarities among nodes sharing ties. We describe estimation and inference for new causal effects that are specifically of interest in social network settings, such as interventions on network ties and network structure. Using our methods to reanalyze the Framingham Heart Study data used in one of the most influential and controversial causal analyses of social network data, we find that after accounting for network structure there is no evidence for the causal effects claimed in the original paper.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/DCXQSVTN/Ogburn et al. - 2020 - Causal inference for social network data.pdf}
}

@article{ogburn_causal_2020-2,
  title = {Causal Inference, Social Networks and Chain Graphs},
  author = {Ogburn, Elizabeth L. and Shpitser, Ilya and Lee, Youjin},
  year = {2020},
  month = oct,
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume = {183},
  number = {4},
  pages = {1659--1676},
  issn = {0964-1998, 1467-985X},
  doi = {10.1111/rssa.12594},
  abstract = {Traditionally, statistical inference and causal inference on human subjects rely on the assumption that individuals are independently affected by treatments or exposures. However, recently there has been increasing interest in settings, such as social networks, where individuals may interact with one another such that treatments may spill over from the treated individual to their social contacts and outcomes may be contagious. Existing models proposed for causal inference using observational data from networks of interacting individuals have two major shortcomings. First, they often require a level of granularity in the data that is infeasible in practice to collect in most settings and, second, the models are high dimensional and often too big to fit to the available data. We illustrate and justify a parsimonious parameterization for network data with interference and contagion. Our parameterization corresponds to a particular family of graphical models known as chain graphs. We argue that, in some settings, chain graph models approximate the marginal distribution of a snapshot of a longitudinal data-generating process on interacting units. We illustrate the use of chain graphs for causal inference about collective decision making in social networks by using data from US Supreme Court decisions between 1994 and 2004 and in simulations.},
  langid = {english},
  file = {/home/alex/Zotero/storage/WUXUFCR2/Ogburn et al. - 2020 - Causal inference, social networks and chain graphs.pdf}
}

@article{omalley_estimating_2014,
  title = {Estimating Peer Effects in Longitudinal Dyadic Data Using Instrumental Variables},
  author = {O'Malley, A. James and Elwert, Felix and Rosenquist, J. Niels and Zaslavsky, Alan M. and Christakis, Nicholas A.},
  year = {2014},
  journal = {Biometrics},
  volume = {70},
  number = {3},
  pages = {506--515},
  issn = {1541-0420},
  doi = {10.1111/biom.12172},
  abstract = {The identification of causal peer effects (also known as social contagion or induction) from observational data in social networks is challenged by two distinct sources of bias: latent homophily and unobserved confounding. In this paper, we investigate how causal peer effects of traits and behaviors can be identified using genes (or other structurally isomorphic variables) as instrumental variables (IV) in a large set of data generating models with homophily and confounding. We use directed acyclic graphs to represent these models and employ multiple IV strategies and report three main identification results. First, using a single fixed gene (or allele) as an IV will generally fail to identify peer effects if the gene affects past values of the treatment. Second, multiple fixed genes/alleles, or, more promisingly, time-varying gene expression, can identify peer effects if we instrument exclusion violations as well as the focal treatment. Third, we show that IV identification of peer effects remains possible even under multiple complications often regarded as lethal for IV identification of intra-individual effects, such as pleiotropy on observables and unobservables, homophily on past phenotype, past and ongoing homophily on genotype, inter-phenotype peer effects, population stratification, gene expression that is endogenous to past phenotype and past gene expression, and others. We apply our identification results to estimating peer effects of body mass index (BMI) among friends and spouses in the Framingham Heart Study. Results suggest a positive causal peer effect of BMI between friends.},
  langid = {english},
  keywords = {Body-mass index,Causality,Directed acyclic graphs,Dyad,Genes,Homophily,Instrumental variable,Longitudinal,Mendelian randomization,Peer effect,Social network,Two-stage least squares},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12172},
  file = {/home/alex/Zotero/storage/YMUFRJ3F/O'Malley et al. - 2014 - Estimating peer effects in longitudinal dyadic dat.pdf;/home/alex/Zotero/storage/GILKGUW7/biom.html}
}

@article{ord_estimation_1975,
  title = {Estimation {{Methods}} for {{Models}} of {{Spatial Interaction}}},
  author = {Ord, Keith},
  year = {1975},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {70},
  number = {349},
  pages = {120--126},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1975.10480272},
  langid = {english},
  file = {/home/alex/Zotero/storage/TM6P7EC7/Ord - 1975 - Estimation Methods for Models of Spatial Interacti.pdf}
}

@article{orourke_random_2013,
  title = {Random Perturbation of Low Rank Matrices: {{Improving}} Classical Bounds},
  shorttitle = {Random Perturbation of Low Rank Matrices},
  author = {O'Rourke, Sean and Vu, Van and Wang, Ke},
  year = {2013},
  month = nov,
  journal = {arXiv:1311.2657 [math, stat]},
  eprint = {1311.2657},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {Matrix perturbation inequalities, such as Weyl's theorem (concerning the singular values) and the Davis-Kahan theorem (concerning the singular vectors), play essential roles in quantitative science; in particular, these bounds have found application in data analysis as well as related areas of engineering and computer science.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {/home/alex/Zotero/storage/IFY2F9JU/O'Rourke et al. - 2013 - Random perturbation of low rank matrices Improvin.pdf}
}

@article{pagan_econometric_1984,
  title = {Econometric {{Issues}} in the {{Analysis}} of {{Regressions}} with {{Generated Regressors}}},
  author = {Pagan, Adrian},
  year = {1984},
  month = feb,
  journal = {International Economic Review},
  volume = {25},
  number = {1},
  pages = {221},
  issn = {00206598},
  doi = {10.2307/2648877},
  langid = {english},
  file = {/home/alex/Zotero/storage/FLN4JEWV/Pagan - 1984 - Econometric Issues in the Analysis of Regressions .pdf}
}

@article{pan_inference_2021,
  title = {Inference for {{Network Regression Models}} with {{Community Structure}}},
  author = {Pan, Mengjie and McCormick, Tyler H. and Fosdick, Bailey K.},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.04271 [cs, stat]},
  eprint = {2106.04271},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Network regression models, where the outcome comprises the valued edge in a network and the predictors are actor or dyad-level covariates, are used extensively in the social and biological sciences. Valid inference relies on accurately modeling the residual dependencies among the relations. Frequently homogeneity assumptions are placed on the errors which are commonly incorrect and ignore critical, natural clustering of the actors. In this work, we present a novel regression modeling framework that models the errors as resulting from a community-based dependence structure and exploits the subsequent exchangeability properties of the error distribution to obtain parsimonious standard errors for regression parameters.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/JP6PEIHV/Pan et al. - 2021 - Inference for Network Regression Models with Commu.pdf}
}

@article{papadogeorgou_causal_2021,
  title = {Causal {{Inference}} with {{Spatio-temporal Data}}: {{Estimating}} the {{Effects}} of {{Airstrikes}} on {{Insurgent Violence}} in {{Iraq}}},
  shorttitle = {Causal {{Inference}} with {{Spatio-temporal Data}}},
  author = {Papadogeorgou, Georgia and Imai, Kosuke and Lyall, Jason and Li, Fan},
  year = {2021},
  month = jul,
  journal = {arXiv:2003.13555 [stat]},
  eprint = {2003.13555},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Many causal processes have spatial and temporal dimensions. Yet the classic causal inference framework is not directly applicable when the treatment and outcome variables are generated by spatio-temporal processes with an infinite number of possible event locations. We extend the potential outcomes framework to these settings by formulating the treatment point process as a stochastic intervention. Our causal estimands include the expected number of outcome events in a specified area under a particular stochastic treatment assignment strategy. We develop methodology that allows for arbitrary patterns of spatial spillover and temporal carryover effects. Using martingale theory, we show that the proposed estimator is consistent and asymptotically normal as the number of time periods increases, even when the propensity score is estimated. We propose a sensitivity analysis for the possible existence of unmeasured confounders, and extend it to the Ha\textasciiacute jek estimator. Simulation studies are conducted to examine the estimators' finite sample performance. Finally, we use the proposed methods to estimate the effects of American airstrikes on insurgent violence in Iraq from February 2007 to July 2008. We find that increasing the average number of daily airstrikes for up to one month results in more insurgent attacks across Iraq and within Baghdad. We also find evidence that airstrikes can displace attacks from Baghdad to new locations up to 400 kilometers away.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/GJ255C67/Papadogeorgou et al. - 2021 - Causal Inference with Spatio-temporal Data Estima.pdf}
}

@article{paul_causal_2022,
  title = {Causal {{Network Influence}} with {{Latent Homophily}} and {{Measurement Error}}: {{An Application}} to {{Therapeutic Community}}},
  shorttitle = {Causal {{Network Influence}} with {{Latent Homophily}} and {{Measurement Error}}},
  author = {Paul, Subhadeep and Nath, Shanjukta and Warren, Keith},
  year = {2022},
  month = mar,
  journal = {arXiv:2203.14223 [stat]},
  eprint = {2203.14223},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The Spatial or Network Autoregressive model (SAR, NAM) is popular for modeling the influence network connected neighbors exert on the outcome of individuals. However, many authors have noted that the causal network influence or contagion cannot be identified from observational data due to the presence of homophily. We propose a latent homophily-adjusted spatial autoregressive model for networked responses to identify the causal contagion and contextual effects. The latent homophily is estimated from the spectral embedding of the network's adjacency matrix. Separately, we develop maximum likelihood estimators for the parameters of the SAR model correcting for measurement error when covariates are measured with error. We show that the bias corrected MLE are consistent and derive its asymptotic limiting distribution. We propose to estimate network influence using the bias corrected MLE in a SAR model with the estimated latent homophily added as a covariate. Our simulations show that the methods perform well in finite sample. We apply our methodology to a data-set of female criminal offenders in a therapeutic community (TC) for substance abuse and criminal behavior. We provide causal estimates of network influence on graduation from TC and re-incarceration after accounting for latent homophily.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/85ZIG7YL/Paul et al. - 2022 - Causal Network Influence with Latent Homophily and.pdf}
}

@book{pearl_causality:_2009,
  title = {Causality: {{Models}}, {{Reasoning}} and {{Inference}}},
  author = {Pearl, Judea},
  year = {2009},
  publisher = {{Cambridge University Press}},
  file = {/home/alex/Zotero/storage/C4YFXGJ9/Pearl - 2009 - Causality Models, Reasoning and Inference.pdf}
}

@inproceedings{pryzant_causal_2021,
  title = {Causal {{Effects}} of {{Linguistic Properties}}},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Pryzant, Reid and Card, Dallas and Jurafsky, Dan and Veitch, Victor and Sridhar, Dhanya},
  year = {2021},
  pages = {4095--4109},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.naacl-main.323},
  langid = {english},
  file = {/home/alex/Zotero/storage/GV3UTVF7/Pryzant et al. - 2021 - Causal Effects of Linguistic Properties.pdf}
}

@article{qu_efficient_2021,
  title = {Efficient {{Treatment Effect Estimation}} in {{Observational Studies}} under {{Heterogeneous Partial Interference}}},
  author = {Qu, Zhaonan and Xiong, Ruoxuan and Liu, Jizhou and Imbens, Guido},
  year = {2021},
  month = jul,
  journal = {arXiv:2107.12420 [econ, math, stat]},
  eprint = {2107.12420},
  eprinttype = {arxiv},
  primaryclass = {econ, math, stat},
  abstract = {In many observational studies in social science and medical applications, subjects or individuals are connected, and one unit's treatment and attributes may affect another unit's treatment and outcome, violating the stable unit treatment value assumption (SUTVA) and resulting in interference. To enable feasible inference, many previous works assume the ``exchangeability'' of interfering units, under which the effect of interference is captured by the number or ratio of treated neighbors. However, in many applications with distinctive units, interference is heterogeneous. In this paper, we focus on the partial interference setting, and restrict units to be exchangeable conditional on observable characteristics. Under this framework, we propose generalized augmented inverse propensity weighted (AIPW) estimators for general causal estimands that include direct treatment effects and spillover effects. We show that they are consistent, asymptotically normal, semiparametric efficient, and robust to heterogeneous interference as well as model misspecifications. We also apply our method to the Add Health dataset and find that smoking behavior exhibits interference on academic outcomes.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Economics - Econometrics,Mathematics - Statistics Theory,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/4VM5USFP/Qu et al. - 2021 - Efficient Treatment Effect Estimation in Observati.pdf}
}

@inproceedings{ravfogel_counterfactual_2021,
  title = {Counterfactual {{Interventions Reveal}} the {{Causal Effect}} of {{Relative Clause Representations}} on {{Agreement Prediction}}},
  booktitle = {Proceedings of the 25th {{Conference}} on {{Computational Natural Language Learning}}},
  author = {Ravfogel, Shauli and Prasad, Grusha and Linzen, Tal and Goldberg, Yoav},
  year = {2021},
  pages = {194--209},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.conll-1.15},
  langid = {english},
  file = {/home/alex/Zotero/storage/AKQZVETJ/Ravfogel et al. - 2021 - Counterfactual Interventions Reveal the Causal Eff.pdf}
}

@article{reich_review_2020,
  title = {A Review of Spatial Causal Inference Methods for Environmental and Epidemiological Applications},
  author = {Reich, Brian J. and Yang, Shu and Guan, Yawen and Giffin, Andrew B. and Miller, Matthew J. and Rappold, Ana G.},
  year = {2020},
  month = jul,
  journal = {arXiv:2007.02714 [stat]},
  eprint = {2007.02714},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {The scientific rigor and computational methods of causal inference have had great impacts on many disciplines, but have only recently begun to take hold in spatial applications. Spatial casual inference poses analytic challenges due to complex correlation structures and interference between the treatment at one location and the outcomes at others. In this paper, we review the current literature on spatial causal inference and identify areas of future work. We first discuss methods that exploit spatial structure to account for unmeasured confounding variables. We then discuss causal analysis in the presence of spatial interference including several common assumptions used to reduce the complexity of the interference patterns under consideration. These methods are extended to the spatiotemporal case where we compare and contrast the potential outcomes framework with Granger causality, and to geostatistical analyses involving spatial random fields of treatments and responses. The methods are introduced in the context of observational environmental and epidemiological studies, and are compared using both a simulation study and analysis of the effect of ambient air pollution on COVID-19 mortality rate. Code to implement many of the methods using the popular Bayesian software OpenBUGS is provided.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/JX7RA9F3/Reich et al. - 2020 - A review of spatial causal inference methods for e.pdf}
}

@article{rissanen_critical_2021,
  title = {A {{Critical Look}} at the {{Consistency}} of {{Causal Estimation With Deep Latent Variable Models}}},
  author = {Rissanen, Severi and Marttinen, Pekka},
  year = {2021},
  month = may,
  journal = {arXiv:2102.06648 [cs]},
  eprint = {2102.06648},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Using deep latent variable models in causal inference has attracted considerable interest recently, but an essential open question is their ability to yield consistent causal estimates. While they have demonstrated promising results and theory exists on some simple model formulations, we also know that causal effects are not even identifiable in general with latent variables. We investigate this gap between theory and empirical results with analytical considerations and extensive experiments under multiple synthetic and real-world data sets, using the causal effect variational autoencoder (CEVAE) as a case study. While CEVAE seems to work reliably under some simple scenarios, it does not estimate the causal effect correctly with a misspecified latent variable or a complex data distribution, as opposed to its original motivation. Hence, our results show that more attention should be paid to ensuring the correctness of causal estimates with deep latent variable models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/home/alex/Zotero/storage/QR39MIB2/Rissanen and Marttinen - 2021 - A Critical Look at the Consistency of Causal Estim.pdf}
}

@article{robinson_teaching_2019,
  title = {Teaching Yourself about Structural Racism Will Improve Your Machine Learning},
  author = {Robinson, Whitney R and Renson, Audrey and Naimi, Ashley I},
  year = {2019},
  month = nov,
  journal = {Biostatistics},
  pages = {kxz040},
  issn = {1465-4644, 1468-4357},
  doi = {10.1093/biostatistics/kxz040},
  abstract = {In this commentary, we put forth the following argument: Anyone conducting machine learning in a health-related domain should educate themselves about structural racism. We argue that structural racism is a critical body of knowledge needed for generalizability in almost all domains of health research.},
  langid = {english},
  file = {/home/alex/Zotero/storage/A8Q6YLIS/Robinson et al. - 2019 - Teaching yourself about structural racism will imp.pdf}
}

@article{rohe_vintage_2022,
  title = {Vintage {{Factor Analysis}} with {{Varimax Performs Statistical Inference}}},
  author = {Rohe, Karl and Zeng, Muzhe},
  year = {2022+},
  journal = {arXiv:2004.05387 [math, stat]},
  eprint = {2004.05387},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {Psychologists developed Multiple Factor Analysis to decompose multivariate data into a small number of interpretable factors without any a priori knowledge about those factors [Thurstone, 1935]. In this form of factor analysis, the Varimax ``factor rotation'' is a key step to make the factors interpretable [Kaiser, 1958]. Charles Spearman and many others objected to factor rotations because the factors seem to be rotationally invariant [Thurstone, 1947, Anderson and Rubin, 1956]. These objections are still reported in all contemporary multivariate statistics textbooks. This is an engima because this vintage form of factor analysis has survived and is widely popular because, empirically, the factor rotation often makes the factors easier to interpret. We argue that the rotation makes the factors easier to interpret because, in fact, the Varimax factor rotation performs statistical inference. We show that Principal Components Analysis (PCA) with the Varimax rotation provides a unified spectral estimation strategy for a broad class of modern factor models, including the Stochastic Blockmodel and a natural variation of Latent Dirichlet Allocation (i.e., ``topic modeling''). In addition, we show that Thurstone's widely employed sparsity diagnostics implicitly assess a key ``leptokurtic'' condition that makes the rotation statistically identifiable in these models. Taken together, this shows that the know-how of Vintage Factor Analysis performs statistical inference, reversing nearly a century of statistical thinking on the topic. With a sparse eigensolver, PCA with Varimax is both fast and stable. Combined with Thurstone's straightforward diagnostics, this vintage approach is suitable for a wide array of modern applications.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {/home/alex/Zotero/storage/BZB352YZ/Rohe and Zeng - 2020 - Vintage Factor Analysis with Varimax Performs Stat.pdf}
}

@article{rubin-delanchy_statistical_2021,
  title = {A Statistical Interpretation of Spectral Embedding: The Generalised Random Dot Product Graph},
  shorttitle = {A Statistical Interpretation of Spectral Embedding},
  author = {{Rubin-Delanchy}, Patrick and Cape, Joshua and Tang, Minh and Priebe, Carey E.},
  year = {2021},
  month = nov,
  journal = {arXiv:1709.05506 [cs, stat]},
  eprint = {1709.05506},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Spectral embedding is a procedure which can be used to obtain vector representations of the nodes of a graph. This paper proposes a generalisation of the latent position network model known as the random dot product graph, to allow interpretation of those vector representations as latent position estimates. The generalisation is needed to model heterophilic connectivity (e.g., `opposites attract') and to cope with negative eigenvalues more generally. We show that, whether the adjacency or normalised Laplacian matrix is used, spectral embedding produces uniformly consistent latent position estimates with asymptotically Gaussian error (up to identifiability). The standard and mixed membership stochastic block models are special cases in which the latent positions take only K distinct vector values, representing communities, or live in the (K - 1)-simplex with those vertices, respectively. Under the stochastic block model, our theory suggests spectral clustering using a Gaussian mixture model (rather than K-means) and, under mixed membership, fitting the minimum volume enclosing simplex, existing recommendations previously only supported under non-negative-definite assumptions. Empirical improvements in link prediction (over the random dot product graph), and the potential to uncover richer latent structure (than posited under the standard or mixed membership stochastic block models) are demonstrated in a cyber-security example.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {62H30; 62H12; 62E20;,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/XZ3AWKYB/Rubin-Delanchy et al. - 2021 - A statistical interpretation of spectral embedding.pdf}
}

@misc{rudolph_efficient_2022,
  title = {Efficient and Flexible Estimation of Natural Mediation Effects under Intermediate Confounding and Monotonicity Constraints},
  author = {Rudolph, Kara E. and Diaz, Ivan},
  year = {2022},
  month = may,
  number = {arXiv:2205.04408},
  eprint = {2205.04408},
  eprinttype = {arxiv},
  primaryclass = {stat},
  institution = {{arXiv}},
  abstract = {Natural direct and indirect effects are mediational estimands that decompose the average treatment effect and describe how outcomes would be affected by contrasting levels of a treatment through changes induced in mediator values (in the case of the indirect effect) or not through induced changes in the mediator values (in the case of the direct effect). Natural direct and indirect effects are not generally point-identifiable in the presence of a treatment-induced confounder, however they may still be identified if one is willing to assume monotonicity between a treatment and the treatment-induced confounder. We argue that this assumption may be reasonable in the relatively common encouragement-design trial setting where intervention is randomized treatment assignment and the treatment-induced confounder is whether or not treatment was actually taken/adhered to. We develop efficiency theory for the natural direct and indirect effects under this monotonicity assumption, and use it to propose a nonparametric, multiply robust estimator. We demonstrate the finite sample properties of this estimator using a simulation study, and apply it to data from the Moving to Opportunity Study to estimate the natural direct and indirect effects of being randomly assigned to receive a Section 8 housing voucher\textemdash the most common form of federal housing assistance\textemdash on risk developing any mood or externalizing disorder among adolescent boys\textemdash -possibly operating through various school and community characteristics.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/home/alex/Zotero/storage/EL4E86NR/Rudolph and Diaz - 2022 - Efficient and flexible estimation of natural media.pdf}
}

@article{savje_average_2019,
  title = {Average Treatment Effects in the Presence of Unknown Interference},
  author = {S{\"a}vje, Fredrik and Aronow, Peter M. and Hudgens, Michael G.},
  year = {2019},
  month = oct,
  journal = {arXiv:1711.06399 [math, stat]},
  eprint = {1711.06399},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {We investigate large-sample properties of treatment effect estimators under unknown interference in randomized experiments. The inferential target is a generalization of the average treatment effect estimand that marginalizes over potential spillover effects. We show that estimators commonly used to estimate treatment effects under no interference are consistent for the generalized estimand for several common experimental designs under limited but otherwise arbitrary and unknown interference. The rates of convergence depend on the rate at which the amount of interference grows and the degree to which it aligns with dependencies in treatment assignment. Importantly for practitioners, the results imply that if one erroneously assumes that units do not interfere in a setting with limited, or even moderate, interference, standard estimators are nevertheless likely to be close to an average treatment effect if the sample is sufficiently large. Conventional confidence statements may, however, not be accurate.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory},
  file = {/home/alex/Zotero/storage/8RZGFMQY/Sävje et al. - 2019 - Average treatment effects in the presence of unkno.pdf}
}

@article{seneta_tricentenary_2013,
  title = {A {{Tricentenary}} History of the {{Law}} of {{Large Numbers}}},
  author = {Seneta, Eugene},
  year = {2013},
  month = sep,
  journal = {Bernoulli},
  volume = {19},
  number = {4},
  eprint = {1309.6488},
  eprinttype = {arxiv},
  issn = {1350-7265},
  doi = {10.3150/12-BEJSP12},
  abstract = {The Weak Law of Large Numbers is traced chronologically from its inception as Jacob Bernoulli's Theorem in 1713, through De Moivre's Theorem, to ultimate forms due to Uspensky and Khinchin in the 1930s, and beyond. Both aspects of Jacob Bernoulli's Theorem: 1. As limit theorem (sample size \$n\textbackslash to\textbackslash infty\$), and: 2. Determining sufficiently large sample size for specified precision, for known and also unknown p (the inversion problem), are studied, in frequentist and Bayesian settings. The Bienaym\textbackslash '\{e\}-Chebyshev Inequality is shown to be a meeting point of the French and Russian directions in the history. Particular emphasis is given to less well-known aspects especially of the Russian direction, with the work of Chebyshev, Markov (the organizer of Bicentennial celebrations), and S.N. Bernstein as focal points.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - History and Overview,Mathematics - Statistics Theory},
  file = {/home/alex/Zotero/storage/A4VFDQEH/Seneta - 2013 - A Tricentenary history of the Law of Large Numbers.pdf}
}

@article{shalizi_comment_2012,
  title = {Comment on "{{Why}} and {{When}} '{{Flawed}}' {{Social Network Analyses Still Yield Valid Tests}} of No {{Contagion}}"},
  author = {Shalizi, Cosma Rohilla},
  year = {2012},
  month = jan,
  journal = {Statistics, Politics, and Policy},
  volume = {3},
  number = {1},
  issn = {2151-7509},
  doi = {10.1515/2151-7509.1053},
  abstract = {VanderWeele et al.'s paper is a useful contribution to the on-going scientific conversation about the detection of contagion from purely observational data. It is especially helpful as a corrective to some of the more extreme statements of Lyons (2011). Unfortunately, this paper, too, goes too far in some places, and so needs some correction itself.},
  langid = {english},
  file = {/home/alex/Zotero/storage/M36IJMNH/Shalizi - 2012 - Comment on Why and When 'Flawed' Social Network A.pdf}
}

@article{sims_consistency_nodate,
  title = {{{CONSISTENCY OF OLS}}, {{PROPERTIES OF CONVERGENCE}}},
  author = {Sims, C},
  pages = {2},
  langid = {english},
  file = {/home/alex/Zotero/storage/PI5PNYCF/Sims - CONSISTENCY OF OLS, PROPERTIES OF CONVERGENCE.pdf}
}

@article{snijders_new_2006,
  title = {New {{Specifications}} for {{Exponential Random Graph Models}}},
  author = {Snijders, Tom A. B. and Pattison, Philippa E. and Robins, Garry L. and Handcock, Mark S.},
  year = {2006},
  month = aug,
  journal = {Sociological Methodology},
  volume = {36},
  number = {1},
  pages = {99--153},
  issn = {0081-1750, 1467-9531},
  doi = {10.1111/j.1467-9531.2006.00176.x},
  abstract = {The most promising class of statistical models for expressing structural properties of social networks observed at one moment in time is the class of exponential random graph models (ERGMs), also known as p* models. The strong point of these models is that they can represent a variety of structural tendencies, such as transitivity, that define complicated dependence patterns not easily modeled by more basic probability models. Recently, Markov chain Monte Carlo (MCMC) algorithms have been developed that produce approximate maximum likelihood estimators. Applying these models in their traditional specification to observed network data often has led to problems, however, which can be traced back to the fact that important parts of the parameter space correspond to nearly degenerate distributions, which may lead to convergence problems of estimation algorithms, and a poor fit to empirical data.             This paper proposes new specifications of exponential random graph models. These specifications represent structural properties such as transitivity and heterogeneity of degrees by more complicated graph statistics than the traditional star and triangle counts. Three kinds of statistics are proposed: geometrically weighted degree distributions, alternating k-triangles, and alternating independent two-paths. Examples are presented both of modeling graphs and digraphs, in which the new specifications lead to much better results than the earlier existing specifications of the ERGM. It is concluded that the new specifications increase the range and applicability of the ERGM as a tool for the statistical analysis of social networks.},
  langid = {english},
  file = {/home/alex/Zotero/storage/4NMUBGRF/Snijders et al. - 2006 - New Specifications for Exponential Random Graph Mo.pdf}
}

@article{sobel_asymptotic_1982,
  title = {Asymptotic {{Confidence Intervals}} for {{Indirect Effects}} in {{Structural Equation Models}}},
  author = {Sobel, Michael E.},
  year = {1982},
  journal = {Sociological Methodology},
  volume = {13},
  pages = {290},
  issn = {00811750},
  doi = {10.2307/270723},
  langid = {english},
  file = {/home/alex/Zotero/storage/4BT6J8DU/Sobel - 1982 - Asymptotic Confidence Intervals for Indirect Effec.pdf}
}

@article{sobel_new_1986,
  title = {Some {{New Results}} on {{Indirect Effects}} and {{Their Standard Errors}} in {{Covariance Structure Models}}},
  author = {Sobel, Michael E.},
  year = {1986},
  journal = {Sociological Methodology},
  volume = {16},
  pages = {159},
  issn = {00811750},
  doi = {10.2307/270922},
  langid = {english},
  file = {/home/alex/Zotero/storage/FD7BCD48/Sobel - 1986 - Some New Results on Indirect Effects and Their Sta.pdf}
}

@article{song_bayesian_2020,
  title = {Bayesian {{Hierarchical Models}} for {{High-Dimensional Mediation Analysis}} with {{Coordinated Selection}} of {{Correlated Mediators}}},
  author = {Song, Yanyi and Zhou, Xiang and Kang, Jian and Aung, Max T. and Zhang, Min and Zhao, Wei and Needham, Belinda L. and Kardia, Sharon L. R. and Liu, Yongmei and Meeker, John D. and Smith, Jennifer A. and Mukherjee, Bhramar},
  year = {2020},
  month = sep,
  journal = {arXiv:2009.11409 [stat]},
  eprint = {2009.11409},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {We consider Bayesian high-dimensional mediation analysis to identify among a large set of correlated potential mediators the active ones that mediate the effect from an exposure variable to an outcome of interest. Correlations among mediators are commonly observed in modern data analysis; examples include the activated voxels within connected regions in brain image data, regulatory signals driven by gene networks in genome data and correlated exposure data from the same source. When correlations are present among active mediators, mediation analysis that fails to account for such correlation can be sub-optimal and may lead to a loss of power in identifying active mediators. Building upon a recent high-dimensional mediation analysis framework, we propose two Bayesian hierarchical models, one with a Gaussian mixture prior that enables correlated mediator selection and the other with a Potts mixture prior that accounts for the correlation among active mediators in mediation analysis. We develop efficient sampling algorithms for both methods. Various simulations demonstrate that our methods enable effective identification of correlated active mediators, which could be missed by using existing methods that assume prior independence among active mediators. The proposed methods are applied to the LIFECODES birth cohort and the Multi-Ethnic Study of Atherosclerosis (MESA) and identified new active mediators with important biological implications.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications},
  file = {/home/alex/Zotero/storage/N9R2V6Z7/Song et al. - 2020 - Bayesian Hierarchical Models for High-Dimensional .pdf}
}

@misc{sridhar_using_nodate,
  title = {Using {{Text Embeddings}} for {{Causal Inference}}},
  author = {Sridhar, Dhanya},
  langid = {english},
  file = {/home/alex/Zotero/storage/PFHL4SAX/Sridhar - Using Text Embeddings for Causal Inference.pdf}
}

@article{steen_graphical_2018,
  title = {Graphical Models for Mediation Analysis},
  author = {Steen, Johan and Vansteelandt, Stijn},
  year = {2018},
  month = nov,
  journal = {arXiv:1801.06069 [math, stat]},
  eprint = {1801.06069},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  pages = {405--438},
  doi = {10.1201/9780429463976-17},
  abstract = {Mediation analysis seeks to infer how much of the effect of an exposure on an outcome can be attributed to specific pathways via intermediate variables or mediators. This requires identification of so-called path-specific effects. These express how a change in exposure affects those intermediate variables (along certain pathways), and how the resulting changes in those variables in turn affect the outcome (along subsequent pathways). However, unlike identification of total effects, adjustment for confounding is insufficient for identification of path-specific effects because their magnitude is also determined by the extent to which individuals who experience large exposure effects on the mediator, tend to experience relatively small or large mediator effects on the outcome. This chapter therefore provides an accessible review of identification strategies under general nonparametric structural equation models (with possibly unmeasured variables), which rule out certain such dependencies. In particular, it is shown which path-specific effects can be identified under such models, and how this can be done.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology}
}

@article{su_testing_2020,
  title = {Testing and {{Estimation}} of {{Social Network Dependence With Time}} to {{Event Data}}},
  author = {Su, Lin and Lu, Wenbin and Song, Rui and Huang, Danyang},
  year = {2020},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {115},
  number = {530},
  pages = {570--582},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2019.1617153},
  abstract = {Nowadays, events are spread rapidly along social networks. We are interested in whether people's responses to an event are affected by their friends' characteristics. For example, how soon will a person start playing a game given that his/her friends like it? Studying social network dependence is an emerging research area. In this work, we propose a novel latent spatial autocorrelation Cox model to study social network dependence with time-to-event data. The proposed model introduces a latent indicator to characterize whether a person's survival time might be affected by his or her friends' features. We first propose a score-type test for detecting the existence of social network dependence. If it exists, we further develop an EM-type algorithm to estimate the model parameters. The performance of the proposed test and estimators are illustrated by simulation studies and an application to a time-to-event dataset about playing a popular mobile game from one of the largest online social network platforms. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
  langid = {english},
  file = {/home/alex/Zotero/storage/SMT3P7CQ/Su et al. - 2020 - Testing and Estimation of Social Network Dependenc.pdf}
}

@article{sweet_estimating_2018,
  title = {Estimating the Effects of Network Covariates on Subgroup Insularity with a Hierarchical Mixed Membership Stochastic Blockmodel},
  author = {Sweet, Tracy M. and Zheng, Qiwen},
  year = {2018},
  month = jan,
  journal = {Social Networks},
  volume = {52},
  pages = {100--114},
  issn = {03788733},
  doi = {10.1016/j.socnet.2017.05.008},
  langid = {english},
  file = {/home/alex/Zotero/storage/5NRPISSM/Sweet and Zheng - 2018 - Estimating the effects of network covariates on su.pdf}
}

@article{sweet_hierarchical_2022,
  title = {A Hierarchical Latent Space Network Model for Mediation},
  author = {Sweet, Tracy M. and Adhikari, Samrachana},
  year = {2022},
  month = may,
  journal = {Network Science},
  pages = {1--18},
  issn = {2050-1242, 2050-1250},
  doi = {10.1017/nws.2022.12},
  abstract = {For interventions that affect how individuals interact, social network data may aid in understanding the mechanisms through which an intervention is effective. Social networks may even be an intermediate outcome observed prior to end of the study. In fact, social networks may also mediate the effects of the intervention on the outcome of interest, and Sweet (2019) introduced a statistical model for social networks as mediators in network-level interventions. We build on their approach and introduce a new model in which the network is a mediator using a latent space approach. We investigate our model through a simulation study and a real-world analysis of teacher advice-seeking networks.},
  langid = {english},
  file = {/home/alex/Zotero/storage/YQ3L8R76/Sweet and Adhikari - 2022 - A hierarchical latent space network model for medi.pdf}
}

@article{sweet_modeling_2019,
  title = {Modeling {{Social Networks}} as {{Mediators}}: {{A Mixed Membership Stochastic Blockmodel}} for {{Mediation}}},
  shorttitle = {Modeling {{Social Networks}} as {{Mediators}}},
  author = {Sweet, Tracy M.},
  year = {2019},
  month = apr,
  journal = {Journal of Educational and Behavioral Statistics},
  volume = {44},
  number = {2},
  pages = {210--240},
  issn = {1076-9986, 1935-1054},
  doi = {10.3102/1076998618814255},
  abstract = {There are some educational interventions aimed at changing the ways in which individuals interact, and social networks are particularly useful for quantifying these changes. For many of these interventions, the ultimate goal is to change some outcome of interest such as teacher quality or student achievement, and social networks act as a natural mediator; the intervention changes the social networks of the teachers in schools, and teachers with certain types of social networks tend to use better teaching practices, for example. Due to lack of methodology, however, social networks have not been modeled as mediators. We present a new framework for modeling social networks as mediators in which a social network model is embedded into a mediation model and both models are estimated simultaneously. As a proof of concept, we introduce a new network model for mediation, applicable for interventions that affect subgroup structure. We provide a small simulation study to demonstrate the feasibility of this model and explore some potential operating characteristics. Finally, we apply our model to examine the effects of instructional coaches on teacher advice-seeking networks and subsequent changes in beliefs about mathematics.},
  langid = {english},
  file = {/home/alex/Zotero/storage/GQC4PH8B/Sweet - 2019 - Modeling Social Networks as Mediators A Mixed Mem.pdf}
}

@article{szekely_measuring_2007-1,
  title = {Measuring and Testing Dependence by Correlation of Distances},
  author = {Sz{\'e}kely, G{\'a}bor J. and Rizzo, Maria L. and Bakirov, Nail K.},
  year = {2007},
  month = dec,
  journal = {The Annals of Statistics},
  volume = {35},
  number = {6},
  issn = {0090-5364},
  doi = {10.1214/009053607000000505},
  langid = {english},
  file = {/home/alex/Zotero/storage/34SSGAHF/Székely et al. - 2007 - Measuring and testing dependence by correlation of.pdf}
}

@article{tchetgen_supplemental_2012,
  title = {Supplemental {{Appendix}} to {{Semiparametric Theory}} for {{Causal Mediation Analysis}}: Efficiency Bounds, Multiple Robustness, and Sensitivity Analysis},
  author = {Tchetgen, Eric J Tchetgen and Shpitser, Ilya},
  year = {2012},
  pages = {9},
  langid = {english},
  file = {/home/alex/Zotero/storage/9QRVURGH/Tchetgen and Shpitser - Supplemental Appendix to Semiparametric Theory for.pdf}
}

@article{tchetgen_tchetgen_semiparametric_2012,
  title = {Semiparametric Theory for Causal Mediation Analysis: {{Efficiency}} Bounds, Multiple Robustness and Sensitivity Analysis},
  shorttitle = {Semiparametric Theory for Causal Mediation Analysis},
  author = {Tchetgen Tchetgen, Eric J. and Shpitser, Ilya},
  year = {2012},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {40},
  number = {3},
  issn = {0090-5364},
  doi = {10.1214/12-AOS990},
  langid = {english},
  file = {/home/alex/Zotero/storage/LEBCNHXI/Tchetgen Tchetgen and Shpitser - 2012 - Semiparametric theory for causal mediation analysi.pdf}
}

@article{tierney_sensitivity_nodate,
  title = {Sensitivity {{Analysis}} for {{Causal Mediation}} through {{Text}}: An {{Application}} to {{Political Polarization}}},
  author = {Tierney, Graham and Volfovsky, Alexander},
  pages = {13},
  langid = {english},
  file = {/home/alex/Zotero/storage/V3KVB2K4/Tierney and Volfovsky - Sensitivity Analysis for Causal Mediation through .pdf}
}

@article{upton_bayesian_2017,
  title = {Bayesian {{Network Regularized Regression}} for {{Modeling Urban Crime Occurrences}}},
  author = {Upton, Elizabeth and Carvalho, Luis},
  year = {2017},
  month = aug,
  journal = {arXiv:1708.05047 [stat]},
  eprint = {1708.05047},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {This paper considers the problem of statistical inference and prediction for processes defined on networks. We assume that the network is known and measures similarity, and our goal is to learn about an attribute associated with its vertices. Classical regression methods are not immediately applicable to this setting, as we would like our model to incorporate information from both network structure and pertinent covariates. Our proposed model consists of a generalized linear model with vertex indexed predictors and a basis expansion of their coefficients, allowing the coefficients to vary over the network. We employ a regularization procedure, cast as a prior distribution on the regression coefficients under a Bayesian setup, so that the predicted responses vary smoothly according to the topology of the network. We motivate the need for this model by examining occurrences of residential burglary in Boston, Massachusetts. Noting that crime rates are not spatially homogeneous, and that the rates appear to vary sharply across regions in the city, we construct a hierarchical model that addresses these issues and gives insight into spatial patterns of crime occurrences. Furthermore, we examine efficient expectation-maximization fitting algorithms and provide computationally-friendly methods for eliciting hyperprior parameters.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications},
  file = {/home/alex/Zotero/storage/3KJNP6XV/Upton and Carvalho - 2017 - Bayesian Network Regularized Regression for Modeli.pdf}
}

@book{van_der_vaart_weak_1996,
  title = {Weak {{Convergence}} and {{Empirical Processes}}},
  author = {{van der Vaart}, Aad W. and Wellner, Jon A.},
  year = {1996},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4757-2545-2},
  isbn = {978-1-4757-2547-6 978-1-4757-2545-2},
  langid = {english},
  file = {/home/alex/Zotero/storage/IXEQL64X/van der Vaart and Wellner - 1996 - Weak Convergence and Empirical Processes.pdf}
}

@article{vanderweele_causal_2014,
  title = {On Causal Interpretation of Race in Regressions Adjusting for Confounding and Mediating Variables},
  author = {VanderWeele, Tyler J. and Robinson, Whitney R.},
  year = {2014},
  month = jul,
  journal = {Epidemiology (Cambridge, Mass.)},
  volume = {25},
  number = {4},
  pages = {473--484},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000105},
  abstract = {We consider several possible interpretations of the ``effect of race'' when regressions are run with race as an exposure variable, controlling also for various confounding and mediating variables. When adjustment is made for socioeconomic status early in a person's life, we discuss under what contexts the regression coefficients for race can be interpreted as corresponding to the extent to which a racial inequality would remain if various socioeconomic distributions early in life across racial groups could be equalized. When adjustment is also made for adult socioeconomic status, we note how the overall racial inequality can be decomposed into the portion that would be eliminated by equalizing adult socioeconomic status across racial groups and the portion of the inequality that would remain even if adult socioeconomic status across racial groups were equalized. We also discuss a stronger interpretation of the ``effect of race'' (stronger in terms of assumptions) involving the joint effects of race-associated physical phenotype (e.g. skin color), parental physical phenotype, genetic background and cultural context when such variables are thought to be hypothetically manipulable and if adequate control for confounding were possible. We discuss some of the challenges with such an interpretation. Further discussion is given as to how the use of selected populations in examining racial disparities can additionally complicate the interpretation of the effects.},
  pmcid = {PMC4125322},
  pmid = {24887159},
  file = {/home/alex/Zotero/storage/95QEUFNH/VanderWeele and Robinson - 2014 - On causal interpretation of race in regressions ad.pdf}
}

@article{vanderweele_conceptual_2009,
  title = {Conceptual Issues Concerning Mediation, Interventions and Composition},
  author = {Vanderweele, Tyler J. and Vansteelandt, Stijn},
  year = {2009},
  journal = {Statistics and Its Interface},
  volume = {2},
  number = {4},
  pages = {457--468},
  issn = {19387989, 19387997},
  doi = {10.4310/SII.2009.v2.n4.a7},
  abstract = {Concepts concerning mediation in the causal inference literature are reviewed. Notions of direct and indirect effects from a counterfactual approach to mediation are compared with those arising from the standard regression approach to mediation of Baron and Kenny (1986), commonly utilized in the social science literature. It is shown that concepts of direct and indirect effect from causal inference generalize those described by Baron and Kenny and that under appropriate identification assumptions these more general direct and indirect effects from causal inference can be estimated using regression even when there are interactions between the primary exposure of interest and the mediator. A number of conceptual issues are discussed concerning the interpretation of identification conditions for mediation, the notion of counterfactuals based on hypothetical interventions and the so called consistency and composition assumptions.},
  langid = {english},
  file = {/home/alex/Zotero/storage/67HF4MU2/Vanderweele and Vansteelandt - 2009 - Conceptual issues concerning mediation, interventi.pdf}
}

@article{vanderweele_controlled_2011,
  title = {Controlled Direct and Mediated Effects: Definition, Identification and Bounds},
  shorttitle = {Controlled Direct and Mediated Effects},
  author = {VanderWeele, Tyler J.},
  year = {2011},
  month = sep,
  journal = {Scandinavian journal of statistics, theory and applications},
  volume = {38},
  number = {3},
  pages = {551--563},
  issn = {0303-6898},
  doi = {10.1111/j.1467-9469.2010.00722.x},
  abstract = {Results are given which provide bounds for controlled direct effects when the no-unmeasured-confounding assumptions required for the identification of these effects do not hold. Previous results concerning bounds for controlled direct effects rely on monotonicity relationships between the treatment, mediator and the outcome themselves; the results presented in this paper instead assume that monotonicity relationships hold between the unmeasured confounding variable or variables and the treatment, mediator and outcome. Whereas prior results give bounds that contain the null hypothesis of no direct effect, the results presented here will in many instances yield bounds that do not contain the null hypothesis of no direct effect. For contexts in which a set of variables intercepts all paths between a treatment and an outcome, it is possible to provide a definition for a controlled mediated effect. We discuss the identification of these controlled mediated effects; the bounds for controlled direct effects are applicable also to controlled mediated effects. An example is given to illustrate how the results in the paper can be used to draw inferences about direct and mediated effects in the presence of unmeasured confounding variables.},
  pmcid = {PMC4193506},
  pmid = {25309023},
  keywords = {research},
  file = {/home/alex/Zotero/storage/GH7Q4SGY/VanderWeele - 2011 - Controlled direct and mediated effects definition.pdf}
}

@book{vanderweele_explanation_2015,
  title = {Explanation in {{Causal Inference}}: {{Methods}} for {{Mediation}} and {{Interaction}}},
  author = {VanderWeele, Tyler},
  year = {2015},
  abstract = {A comprehensive book on methods for mediation and interaction. The only book to approach this topic from the perspective of causal inference. Numerous software tools provided. Easy-to-read and accessible. Examples drawn from diverse fields. An essential reference for anyone conducting empirical research in the biomedical or social sciences''\textendash{} Provided by publisher. ISBN 978-0-19-932587-0 (hardback) 1. Social sciences \textendash{} Research. 2. Social sciences \textendash{} Methodology. 3. Causation. H62.V3238 2015 001.4 22 \textendash{} dc23 2014029661 I. Title.},
  langid = {english},
  file = {/home/alex/Zotero/storage/5WE8A27C/VanderWeele - Explanation in Causal Inference Methods for Media.pdf}
}

@article{vanderweele_mediation_2014,
  title = {Mediation {{Analysis}} with {{Multiple Mediators}}},
  author = {VanderWeele, T.J. and Vansteelandt, S.},
  year = {2014},
  month = jan,
  journal = {Epidemiologic methods},
  volume = {2},
  number = {1},
  pages = {95--115},
  issn = {2194-9263},
  doi = {10.1515/em-2012-0010},
  abstract = {Recent advances in the causal inference literature on mediation have extended traditional approaches to direct and indirect effects to settings that allow for interactions and non-linearities. In this paper, these approaches from causal inference are further extended to settings in which multiple mediators may be of interest. Two analytic approaches, one based on regression and one based on weighting are proposed to estimate the effect mediated through multiple mediators and the effects through other pathways. The approaches proposed here accommodate exposure-mediator interactions and, to a certain extent, mediator-mediator interactions as well. The methods handle binary or continuous mediators and binary, continuous or count outcomes. When the mediators affect one another, the strategy of trying to assess direct and indirect effects one mediator at a time will in general fail; the approach given in this paper can still be used. A characterization is moreover given as to when the sum of the mediated effects for multiple mediators considered separately will be equal to the mediated effect of all of the mediators considered jointly. The approach proposed in this paper is robust to unmeasured common causes of two or more mediators.},
  pmcid = {PMC4287269},
  pmid = {25580377},
  file = {/home/alex/Zotero/storage/4QMWLSR2/VanderWeele and Vansteelandt - 2014 - Mediation Analysis with Multiple Mediators.pdf}
}

@article{vanderweele_mediation_2016,
  title = {Mediation {{Analysis}}: {{A Practitioner}}'s {{Guide}}},
  shorttitle = {Mediation {{Analysis}}},
  author = {VanderWeele, Tyler J.},
  year = {2016},
  month = mar,
  journal = {Annual Review of Public Health},
  volume = {37},
  number = {1},
  pages = {17--32},
  issn = {0163-7525, 1545-2093},
  doi = {10.1146/annurev-publhealth-032315-021402},
  abstract = {This article provides an overview of recent developments in mediation analysis, that is, analyses used to assess the relative magnitude of different pathways and mechanisms by which an exposure may affect an outcome. Traditional approaches to mediation in the biomedical and social sciences are described. Attention is given to the confounding assumptions required for a causal interpretation of direct and indirect effect estimates. Methods from the causal inference literature to conduct mediation in the presence of exposuremediator interactions, binary outcomes, binary mediators, and case-control study designs are presented. Sensitivity analysis techniques for unmeasured confounding and measurement error are introduced. Discussion is given to extensions to time-to-event outcomes and multiple mediators. Further flexible modeling strategies arising from the precise counterfactual definitions of direct and indirect effects are also described. The focus throughout is on methodology that is easily implementable in practice across a broad range of potential applications.},
  langid = {english},
  file = {/home/alex/Zotero/storage/RMPPMN8D/VanderWeele - 2016 - Mediation Analysis A Practitioner's Guide.pdf}
}

@article{vanderweele_rejoinder_2014,
  title = {Rejoinder: {{How}} to {{Reduce Racial Disparities}}?},
  shorttitle = {Rejoinder},
  author = {VanderWeele, Tyler J. and Robinson, Whitney R.},
  year = {2014},
  month = jul,
  journal = {Epidemiology},
  volume = {25},
  number = {4},
  pages = {491--493},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000124},
  langid = {english},
  file = {/home/alex/Zotero/storage/GEPWM3AX/VanderWeele and Robinson - 2014 - Rejoinder How to Reduce Racial Disparities.pdf}
}

@article{vanderweele_statistical_nodate,
  title = {A Statistical Test to Reject the Structural Interpretation of a Latent Factor Model},
  author = {Vanderweele, Tyler J and Vansteelandt, Stijn},
  pages = {18},
  abstract = {Factor analysis is often used to assess whether a single univariate latent variable is sufficient to explain most of the covariance among a set of indicators for some underlying construct. When evidence suggests that a single factor is adequate, research often proceeds by using a univariate summary of the indicators in subsequent research. Implicit in such practices is the assumption that it is the underlying latent, rather than the indicators, that is causally efficacious. The assumption that the indicators do not have effects on anything subsequent, and that they are themselves only affected by antecedents through the underlying latent is a strong assumption, effectively imposing a structural interpretation on the latent factor model. In this paper, we show that this structural assumption has empirically testable implications, even though the latent is unobserved. We develop a statistical test to potentially reject the structural interpretation of a latent factor model. We apply this test to data concerning associations between the Satisfactionwith-Life-Scale and subsequent all-cause mortality, which provides strong evidence against a structural interpretation for a univariate latent underlying the scale. Discussion is given to the implications of this result for the development, evaluation, and use of measures related to latent factor models.},
  langid = {english},
  file = {/home/alex/Zotero/storage/LLYJIQZW/Vanderweele and Vansteelandt - A statistical test to reject the structural interp.pdf}
}

@article{vansteelandt_imputation_2012,
  title = {Imputation {{Strategies}} for the {{Estimation}} of {{Natural Direct}} and {{Indirect Effects}}},
  author = {Vansteelandt, Stijn and Bekaert, Maarten and Lange, Theis},
  year = {2012},
  month = jan,
  journal = {Epidemiologic Methods},
  volume = {1},
  number = {1},
  issn = {2161-962X},
  doi = {10.1515/2161-962X.1014},
  abstract = {Mediation analysis is widely adopted to infer causal mechanism by disentangling indirect or mediated effects of an exposure on an outcome through given intermediaries, from the remaining direct effect. Traditional approaches build on standard regression models for the outcome and mediator, but easily result in difficult-to-interpret or difficult-to-report results when some of these models involve non-linearities. In this article, we overcome this via a general class of so-called natural effect models, which directly parameterize the (natural) direct and indirect effects of interest. We propose flexible estimation strategies for the direct and indirect effect parameters indexing these models, that are easy to perform with standard statistical software: one based on regression mean imputation and one based on doubly robust imputation. We give a theoretical discussion of the properties of these estimation strategies. We moreover assess their finite-sample performance through a simulation study, and through the analysis of the WHO-LARES study on the association between residence in a damp and moldy dwelling and the risk of depression.},
  langid = {english},
  file = {/home/alex/Zotero/storage/HWQ3XZLZ/Vansteelandt et al. - 2012 - Imputation Strategies for the Estimation of Natura.pdf}
}

@article{vansteelandt_interventional_2017,
  title = {Interventional {{Effects}} for {{Mediation Analysis}} with {{Multiple Mediators}}:},
  shorttitle = {Interventional {{Effects}} for {{Mediation Analysis}} with {{Multiple Mediators}}},
  author = {Vansteelandt, Stijn and Daniel, Rhian M.},
  year = {2017},
  month = mar,
  journal = {Epidemiology},
  volume = {28},
  number = {2},
  pages = {258--265},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000596},
  abstract = {The mediation formula for the identification of natural (in)direct effects has facilitated mediation analyses that better respect the nature of the data, with greater consideration of the need for confounding control. The default assumptions on which it relies are strong, however. In particular, they are known to be violated when confounders of the mediator\textendash outcome association are affected by the exposure. This complicates extensions of counterfactual-based mediation analysis to settings that involve repeatedly measured mediators, or multiple correlated mediators.},
  langid = {english},
  file = {/home/alex/Zotero/storage/7Z5G5XB7/Vansteelandt and Daniel - 2017 - Interventional Effects for Mediation Analysis with.pdf}
}

@article{vansteelandt_natural_2012,
  title = {Natural {{Direct}} and {{Indirect Effects}} on the {{Exposed}}: {{Effect Decomposition}} under {{Weaker Assumptions}}},
  shorttitle = {Natural {{Direct}} and {{Indirect Effects}} on the {{Exposed}}},
  author = {Vansteelandt, Stijn and VanderWeele, Tyler J.},
  year = {2012},
  month = dec,
  journal = {Biometrics},
  volume = {68},
  number = {4},
  pages = {1019--1027},
  issn = {0006341X},
  doi = {10.1111/j.1541-0420.2012.01777.x},
  abstract = {We define natural direct and indirect effects on the exposed. We show that these allow for effect decomposition under weaker identification conditions than population natural direct and indirect effects. When no confounders of the mediator-outcome association are affected by the exposure, identification is possible under essentially the same conditions as for controlled direct effects. Otherwise, identification is still possible with additional knowledge on a non-identifiable selection-bias function which measures the dependence of the mediator effect on the observed exposure within confounder levels, and which evaluates to zero in a large class of realistic datagenerating mechanisms.},
  langid = {english},
  file = {/home/alex/Zotero/storage/G73N3VMR/Vansteelandt and VanderWeele - 2012 - Natural Direct and Indirect Effects on the Exposed.pdf}
}

@inproceedings{veitch_adapting_2020,
  title = {Adapting {{Text Embeddings}} for {{Causal Inference}}},
  booktitle = {Proceedings of the 36 Th {{Conference}} on {{Uncertainty}} in {{Artificial Intelligence}} ({{UAI}})},
  author = {Veitch, Victor and Sridhar, Dhanya and Blei, David M},
  year = {2020},
  volume = {124},
  pages = {10},
  langid = {english},
  file = {/home/alex/Zotero/storage/HYSGJS8L/Veitch et al. - Adapting Text Embeddings for Causal Inference.pdf}
}

@inproceedings{veitch_using_2019,
  title = {Using {{Embeddings}} to {{Correct}} for {{Unobserved Confounding}} in {{Networks}}},
  booktitle = {33rd {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Veitch, Victor and Wang, Yixin and Blei, David},
  year = {2019},
  pages = {11},
  address = {{Vancouver, Canada}},
  abstract = {We consider causal inference in the presence of unobserved confounding. We study the case where a proxy is available for the unobserved confounding in the form of a network connecting the units. For example, the link structure of a social network carries information about its members. We show how to effectively use the proxy to do causal inference. The main idea is to reduce the causal estimation problem to a semi-supervised prediction of both the treatments and outcomes. Networks admit high-quality embedding models that can be used for this semisupervised prediction. We show that the method yields valid inferences under suitable (weak) conditions on the quality of the predictive model. We validate the method with experiments on a semi-synthetic social network dataset. Code at github.com/vveitch/causal-network-embeddings.},
  langid = {english},
  file = {/home/alex/Zotero/storage/ZVZVJ6RL/Veitch et al. - Using Embeddings to Correct for Unobserved Confoun.pdf}
}

@article{verbitsky-savitz_causal_2012,
  title = {Causal {{Inference Under Interference}} in {{Spatial Settings}}: {{A Case Study Evaluating Community Policing Program}} in {{Chicago}}},
  shorttitle = {Causal {{Inference Under Interference}} in {{Spatial Settings}}},
  author = {{Verbitsky-Savitz}, Natalya and Raudenbush, Stephen W.},
  year = {2012},
  month = jan,
  journal = {Epidemiologic Methods},
  volume = {1},
  number = {1},
  issn = {2161-962X},
  doi = {10.1515/2161-962X.1020},
  abstract = {For decades, social scientists have been trying to answer causal questions about the effectiveness of certain programs or policies. The conventional methodology for answering such causal questions relies on the ``no interference between different units'' assumption; that is, a unit's outcome depends solely on the treatment that the unit is assigned to (or exposed to) and does not depend on the treatment assignment (or exposure) of other units in the population. However, this assumption is likely to be violated in spatial settings because of various spillover, diffusion, and displacement effects. In this paper, we present a case study evaluating the causal effects of Chicago's community policing program (a community-wide intervention) on neighborhoods' crime rates. We use semiannual crime data from Chicago to evaluate (1) whether community policing is more effective at decreasing rates of reported personal crime when implemented everywhere versus nowhere in a city; (2) whether community policing is effective if implemented in a single local area, holding constant policing in adjacent areas; (3) whether implementing community policing in surrounding areas affects crime in a focal area; and (4) whether community policing's impact on crime in surrounding areas depends on whether community policing is also implemented in the focal area. To answer these questions, we relax the no-interference assumption. Our approach allows the potential outcomes in any local area to depend on a function of the treatment assignments in all other units. We define causal effects and evaluate assumptions that make the framework tractable within the framework of a generalized linear model with spatially auto-correlated random effects.},
  langid = {english},
  file = {/home/alex/Zotero/storage/VTLRXSHR/Verbitsky-Savitz and Raudenbush - 2012 - Causal Inference Under Interference in Spatial Set.pdf}
}

@book{vershynin_high-dimensional_2020,
  title = {High-{{Dimensional Probability}}: {{An Introduction}} with {{Applications}} in {{Data Science}}},
  shorttitle = {High-{{Dimensional Probability}}},
  author = {Vershynin, Roman},
  year = {2020},
  month = jun,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108231596},
  isbn = {978-1-108-23159-6 978-1-108-41519-4},
  langid = {english},
  file = {/home/alex/Zotero/storage/4TJ9JKGD/Vershynin - 2018 - High-Dimensional Probability An Introduction with.pdf}
}

@incollection{vershynin_introduction_2011,
  title = {Introduction to the Non-Asymptotic Analysis of Random Matrices},
  booktitle = {{{arXiv}}:1011.3027 [Cs, Math]},
  author = {Vershynin, Roman},
  year = {2011},
  month = nov,
  eprint = {1011.3027},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  abstract = {This is a tutorial on some basic non-asymptotic methods and concepts in random matrix theory. The reader will learn several tools for the analysis of the extreme singular values of random matrices with independent rows or columns. Many of these methods sprung off from the development of geometric functional analysis since the 1970's. They have applications in several fields, most notably in theoretical computer science, statistics and signal processing. A few basic applications are covered in this text, particularly for the problem of estimating covariance matrices in statistics and for validating probabilistic constructions of measurement matrices in compressed sensing. These notes are written particularly for graduate students and beginning researchers in different areas, including functional analysts, probabilists, theoretical statisticians, electrical engineers, and theoretical computer scientists.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {60B20; 46B09,Mathematics - Functional Analysis,Mathematics - Numerical Analysis,Mathematics - Probability},
  file = {/home/alex/Zotero/storage/UPC5WUKV/Vershynin - 2011 - Introduction to the non-asymptotic analysis of ran.pdf}
}

@inproceedings{vig_investigating_2020,
  title = {Investigating {{Gender Bias}} in {{Language Models Using Causal Mediation Analysis}}},
  booktitle = {34th {{Conference}} on {{Neural Information Processing Systems}} ({{NeurIPS}} 2020), {{Vancouver}}, {{Canada}}.},
  author = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
  year = {2020},
  pages = {14},
  abstract = {Many interpretation methods for neural models in natural language processing investigate how information is encoded inside hidden representations. However, these methods can only measure whether the information exists, not whether it is actually used by the model. We propose a methodology grounded in the theory of causal mediation analysis for interpreting which parts of a model are causally implicated in its behavior. The approach enables us to analyze the mechanisms that facilitate the flow of information from input to output through various model components, known as mediators. As a case study, we apply this methodology to analyzing gender bias in pre-trained Transformer language models. We study the role of individual neurons and attention heads in mediating gender bias across three datasets designed to gauge a model's sensitivity to gender bias. Our mediation analysis reveals that gender bias effects are concentrated in specific components of the model that may exhibit highly specialized behavior.},
  langid = {english},
  file = {/home/alex/Zotero/storage/E669Z7I3/Vig et al. - Investigating Gender Bias in Language Models Using.pdf}
}

@article{volfovsky_causal_2015,
  title = {Causal Inference for Ordinal Outcomes},
  author = {Volfovsky, Alexander and Airoldi, Edoardo M. and Rubin, Donald B.},
  year = {2015},
  month = jan,
  journal = {arXiv:1501.01234 [stat]},
  eprint = {1501.01234},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Many outcomes of interest in the social and health sciences, as well as in modern applications in computational social science and experimentation on social media platforms, are ordinal and do not have a meaningful scale. Causal analyses that leverage this type of data, termed ordinal non-numeric, require careful treatment, as much of the classical potential outcomes literature is concerned with estimation and hypothesis testing for outcomes whose relative magnitudes are well defined. Here, we propose a class of finite population causal estimands that depend on conditional distributions of the potential outcomes, and provide an interpretable summary of causal effects when no scale is available. We formulate a relaxation of the Fisherian sharp null hypothesis of constant effect that accommodates the scale-free nature of ordinal non-numeric data. We develop a Bayesian procedure to estimate the proposed causal estimands that leverages the rank likelihood. We illustrate these methods with an application to educational outcomes in the General Social Survey.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/LTL2YPGC/Volfovsky et al. - 2015 - Causal inference for ordinal outcomes.pdf}
}

@book{wainwright_high-dimensional_2019,
  title = {High-Dimensional Statistics: A Non-Asymptotic Viewpoint},
  shorttitle = {High-Dimensional Statistics},
  author = {Wainwright, Martin},
  year = {2019},
  series = {Cambridge Series in Statistical and Probabilistic Mathematics},
  number = {48},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York, NY}},
  isbn = {978-1-108-49802-9},
  lccn = {QA276.18 .W35 2019},
  keywords = {Big data,Mathematical statistics,Textbooks},
  file = {/home/alex/Zotero/storage/K34RST4D/Wainwright - 2019 - High-dimensional statistics a non-asymptotic view.pdf}
}

@article{wang_blessings_2019,
  title = {The {{Blessings}} of {{Multiple Causes}}},
  author = {Wang, Yixin and Blei, David M.},
  year = {2019},
  month = oct,
  journal = {Journal of the American Statistical Association},
  volume = {114},
  number = {528},
  pages = {1574--1596},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2019.1686987},
  langid = {english},
  file = {/home/alex/Zotero/storage/38DALCDH/Wang and Blei - 2019 - The Blessings of Multiple Causes.pdf}
}

@article{wang_enhancing_nodate,
  title = {Enhancing {{Model Robustness}} and {{Fairness}} with {{Causality}}: {{A Regularization Approach}}},
  author = {Wang, Zhao and Shu, Kai and Culotta, Aron},
  pages = {11},
  abstract = {Recent work has raised concerns on the risk of spurious correlations and unintended biases in statistical machine learning models that threaten model robustness and fairness. In this paper, we propose a simple and intuitive regularization approach to integrate causal knowledge during model training and build a robust and fair model by emphasizing causal features and de-emphasizing spurious features. Specifically, we first manually identify causal and spurious features with principles inspired from the counterfactual framework of causal inference. Then, we propose a regularization approach to penalize causal and spurious features separately. By adjusting the strength of the penalty for each type of feature, we build a predictive model that relies more on causal features and less on non-causal features. We conduct experiments to evaluate model robustness and fairness on three datasets with multiple metrics. Empirical results show that the new models built with causal awareness significantly improve model robustness with respect to counterfactual texts and model fairness with respect to sensitive attributes.},
  langid = {english},
  file = {/home/alex/Zotero/storage/Y2XBEE89/Wang et al. - Enhancing Model Robustness and Fairness with Causa.pdf}
}

@article{wang_g-computation_2015-1,
  title = {G-Computation Demonstration in Causal Mediation Analysis},
  author = {Wang, Aolin and Arah, Onyebuchi A.},
  year = {2015},
  month = oct,
  journal = {European Journal of Epidemiology},
  volume = {30},
  number = {10},
  pages = {1119--1127},
  issn = {0393-2990, 1573-7284},
  doi = {10.1007/s10654-015-0100-z},
  abstract = {Recent work has considerably advanced the definition, identification and estimation of controlled direct, and natural direct and indirect effects in causal mediation analysis. Despite the various estimation methods and statistical routines being developed, a unified approach for effect estimation under different effect decomposition scenarios is still needed for epidemiologic research. G-computation offers such unification and has been used for total effect and joint controlled direct effect estimation settings, involving different types of exposure and outcome variables. In this study, we demonstrate the utility of parametric g-computation in estimating various components of the total effect, including (i) natural direct and indirect effects, (ii) standard and stochastic controlled direct effects, and (iii) reference and mediated interaction effects, using Monte Carlo simulations in standard statistical software. For each study subject, we estimated their nested potential outcomes corresponding to the (mediated) effects of an intervention on the exposure wherein the mediator was allowed to attain the value it would have under a possible counterfactual exposure intervention, under a pre-specified distribution of the mediator independent of any causes, or under a fixed controlled value. A final regression of the potential outcome on the exposure intervention variable was used to compute point estimates and bootstrap was used to obtain confidence intervals. Through contrasting different potential outcomes, this analytical framework provides an intuitive way of estimating effects under the recently introduced 3- and 4- way effect decomposition. This framework can be extended to complex multivariable and longitudinal mediation settings.},
  langid = {english},
  file = {/home/alex/Zotero/storage/68RFBS3T/Wang and Arah - 2015 - G-computation demonstration in causal mediation an.pdf}
}

@article{wedin_perturbation_1972-1,
  title = {Perturbation Bounds in Connection with Singular Value Decomposition},
  author = {Wedin, Per-{\AA}ke},
  year = {1972},
  month = mar,
  journal = {BIT},
  volume = {12},
  number = {1},
  pages = {99--111},
  issn = {0006-3835, 1572-9125},
  doi = {10.1007/BF01932678},
  abstract = {Let A be an m \texttimes{} n-matrix which is slightly perturbed. In this paper we will derive an estimate of how much the invariant subspaces of AUA and AA H will then be affected. These bounds have the sin 0 theorem for Hermitian linear operators in Davis and Kahan [1] as a special case. They are applicable to computational solution of overdetermined systems of linear equations and especially cover the rank deficient case when the matrix is replaced by one of lower rank.},
  langid = {english},
  file = {/home/alex/Zotero/storage/UVQUBHK9/Wedin - 1972 - Perturbation bounds in connection with singular va.pdf}
}

@incollection{wiberg_permutation_2020,
  title = {Permutation {{Test}} of {{Regression Coefficients}} in {{Social Network Data Analysis}}},
  booktitle = {Quantitative {{Psychology}}},
  author = {Qu, Wen and Liu, Haiyan and Zhang, Zhiyong},
  editor = {Wiberg, Marie and Molenaar, Dylan and Gonz{\'a}lez, Jorge and B{\"o}ckenholt, Ulf and Kim, Jee-Seon},
  year = {2020},
  volume = {322},
  pages = {377--387},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-43469-4_28},
  abstract = {In social and behavioral sciences, researchers are interested in the relationships between individuals' attributes and the formation of social relations within a social network. Logistic modeling is a popular approach to address those research interests (Wasserman and Pattison (1996) Psychometrika 61:401\textendash 425. https://doi.org/10.1007/BF02294547). However, the nature of network data (e.g., small size, non-normality, and dependence) violates the assumptions of logistic regression, which can lead to an unreliable inference. To remedy the consequences of these violations with a normal-based hypothesis test, we present the permutation test procedure within the social network framework. The permutation test, on the significance of a regression parameter, can improve the accuracy of the hypothesis decision. In this study, we conducted a simulation to compare the performance of the permutation test and the asymptotic likelihood ratio test under various conditions. The simulation results confirm the advantages of the permutation test as expected.},
  isbn = {978-3-030-43468-7 978-3-030-43469-4},
  langid = {english},
  file = {/home/alex/Zotero/storage/I2VXELG6/Qu et al. - 2020 - Permutation Test of Regression Coefficients in Soc.pdf}
}

@article{witty_causal_nodate,
  title = {Causal {{Inference}} Using {{Gaussian Processes}} with {{Structured Latent Confounders}}},
  author = {Witty, Sam and Takatsu, Kenta and Jensen, David and Mansinghka, Vikash},
  pages = {11},
  abstract = {Latent confounders\textemdash unobserved variables that influence both treatment and outcome\textemdash can bias estimates of causal effects. In some cases, these confounders are shared across observations, e.g. all students taking a course are influenced by the course's difficulty in addition to any educational interventions they receive individually. This paper shows how to semiparametrically model latent confounders that have this structure and thereby improve estimates of causal effects. The key innovations are a hierarchical Bayesian model, Gaussian processes with structured latent confounders (GP-SLC), and a Monte Carlo inference algorithm for this model based on elliptical slice sampling. GP-SLC provides principled Bayesian uncertainty estimates of individual treatment effect with minimal assumptions about the functional forms relating confounders, covariates, treatment, and outcome. Finally, this paper shows GP-SLC is competitive with or more accurate than widely used causal inference techniques on three benchmark datasets, including the Infant Health and Development Program and a dataset showing the effect of changing temperatures on state-wide energy consumption across New England.},
  langid = {english},
  file = {/home/alex/Zotero/storage/X54HYMYN/Witty et al. - Causal Inference using Gaussian Processes with Str.pdf}
}

@article{xia_multi-scale_2020,
  title = {Multi-Scale Network Regression for Brain-Phenotype Associations},
  author = {Xia, Cedric Huchuan and Ma, Zongming and Cui, Zaixu and Bzdok, Danilo and Thirion, Bertrand and Bassett, Danielle S. and Satterthwaite, Theodore D. and Shinohara, Russell T. and Witten, Daniela M.},
  year = {2020},
  journal = {Human Brain Mapping},
  volume = {41},
  number = {10},
  pages = {2553--2566},
  issn = {1097-0193},
  doi = {10.1002/hbm.24982},
  abstract = {Brain networks are increasingly characterized at different scales, including summary statistics, community connectivity, and individual edges. While research relating brain networks to behavioral measurements has yielded many insights into brain-phenotype relationships, common analytical approaches only consider network information at a single scale. Here, we designed, implemented, and deployed Multi-Scale Network Regression (MSNR), a penalized multivariate approach for modeling brain networks that explicitly respects both edge- and community-level information by assuming a low rank and sparse structure, both encouraging less complex and more interpretable modeling. Capitalizing on a large neuroimaging cohort (n = 1, 051), we demonstrate that MSNR recapitulates interpretable and statistically significant connectivity patterns associated with brain development, sex differences, and motion-related artifacts. Compared to single-scale methods, MSNR achieves a balance between prediction performance and model complexity, with improved interpretability. Together, by jointly exploiting both edge- and community-level information, MSNR has the potential to yield novel insights into brain-behavior relationships.},
  langid = {english},
  keywords = {functional connectivity,multivariate analysis,network neuroscience},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.24982},
  file = {/home/alex/Zotero/storage/KC3HRUPJ/Xia et al. - 2020 - Multi-scale network regression for brain-phenotype.pdf;/home/alex/Zotero/storage/UQN4D3BQ/hbm.html}
}

@article{xie_optimal_2020,
  title = {Optimal {{Bayesian}} Estimation for Random Dot Product Graphs},
  author = {Xie, Fangzheng and Xu, Yanxun},
  year = {2020},
  month = dec,
  journal = {Biometrika},
  volume = {107},
  number = {4},
  pages = {875--889},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asaa031},
  abstract = {We propose and prove the optimality of a Bayesian approach for estimating the latent positions in random dot product graphs, which we call posterior spectral embedding. Unlike classical spectral-based adjacency, or Laplacian spectral embedding, posterior spectral embedding is a fully likelihood-based graph estimation method that takes advantage of the Bernoulli likelihood information of the observed adjacency matrix. We develop a minimax lower bound for estimating the latent positions, and show that posterior spectral embedding achieves this lower bound in the following two senses: it both results in a minimax-optimal posterior contraction rate and yields a point estimator achieving the minimax risk asymptotically. The convergence results are subsequently applied to clustering in stochastic block models with positive semidefinite block probability matrices, strengthening an existing result concerning the number of misclustered vertices. We also study a spectral-based Gaussian spectral embedding as a natural Bayesian analogue of adjacency spectral embedding, but the resulting posterior contraction rate is suboptimal by an extra logarithmic factor. The practical performance of the proposed methodology is illustrated through extensive synthetic examples and the analysis of Wikipedia graph data.},
  langid = {english},
  file = {/home/alex/Zotero/storage/DFVMVN5Z/Xie and Xu - 2020 - Optimal Bayesian estimation for random dot product.pdf}
}

@article{xu_network_2015,
  title = {Network Regularised {{Cox}} Regression and Multiplex Network Models to Predict Disease Comorbidities and Survival of Cancer},
  author = {Xu, Haoming and Moni, Mohammad Ali and Li{\`o}, Pietro},
  year = {2015},
  month = dec,
  journal = {Computational Biology and Chemistry},
  volume = {59},
  pages = {15--31},
  issn = {14769271},
  doi = {10.1016/j.compbiolchem.2015.08.010},
  abstract = {In cancer genomics, gene expression levels provide important molecular signatures for all types of cancer, and this could be very useful for predicting the survival of cancer patients. However, the main challenge of gene expression data analysis is high dimensionality, and microarray is characterised by few number of samples with large number of genes. To overcome this problem, a variety of penalised Cox proportional hazard models have been proposed. We introduce a novel network regularised Cox proportional hazard model and a novel multiplex network model to measure the disease comorbidities and to predict survival of the cancer patient. Our methods are applied to analyse seven microarray cancer gene expression datasets: breast cancer, ovarian cancer, lung cancer, liver cancer, renal cancer and osteosarcoma. Firstly, we applied a principal component analysis to reduce the dimensionality of original gene expression data. Secondly, we applied a network regularised Cox regression model on the reduced gene expression datasets. By using normalised mutual information method and multiplex network model, we predict the comorbidities for the liver cancer based on the integration of diverse set of omics and clinical data, and we find the diseasome associations (disease\textendash gene association) among different cancers based on the identified common significant genes. Finally, we evaluated the precision of the approach with respect to the accuracy of survival prediction using ROC curves. We report that colon cancer, liver cancer and renal cancer share the CXCL5 gene, and breast cancer, ovarian cancer and renal cancer share the CCND2 gene. Our methods are useful to predict survival of the patient and disease comorbidities more accurately and helpful for improvement of the care of patients with comorbidity. Software in Matlab and R is available on our GitHub page: https://github.com/ssnhcom/NetworkRegularisedCox.git.},
  langid = {english},
  file = {/home/alex/Zotero/storage/5374MWP7/Xu et al. - 2015 - Network regularised Cox regression and multiplex n.pdf}
}

@article{yan_statistical_2019,
  title = {Statistical {{Inference}} in a {{Directed Network Model With Covariates}}},
  author = {Yan, Ting and Jiang, Binyan and Fienberg, Stephen E. and Leng, Chenlei},
  year = {2019},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {114},
  number = {526},
  pages = {857--868},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2018.1448829},
  abstract = {Networks are often characterized by node heterogeneity for which nodes exhibit different degrees of interaction and link homophily for which nodes sharing common features tend to associate with each other. In this article, we rigorously study a directed network model that captures the former via node-specific parameterization and the latter by incorporating covariates. In particular, this model quantifies the extent of heterogeneity in terms of outgoingness and incomingness of each node by different parameters, thus allowing the number of heterogeneity parameters to be twice the number of nodes. We study the maximum likelihood estimation of the model and establish the uniform consistency and asymptotic normality of the resulting estimators. Numerical studies demonstrate our theoretical findings and two data analyses confirm the usefulness of our model. Supplementary materials for this article are available online.},
  langid = {english},
  file = {/home/alex/Zotero/storage/52P32KZV/Yan et al. - 2019 - Statistical Inference in a Directed Network Model .pdf}
}

@article{yu_useful_2014,
  title = {A Useful Variant of the {{Davis-Kahan}} Theorem for Statisticians},
  author = {Yu, Yi and Wang, Tengyao and Samworth, Richard J.},
  year = {2014},
  month = may,
  journal = {arXiv:1405.0680 [math, stat]},
  eprint = {1405.0680},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  abstract = {The Davis\textendash Kahan theorem is used in the analysis of many statistical procedures to bound the distance between subspaces spanned by population eigenvectors and their sample versions. It relies on an eigenvalue separation condition between certain relevant population and sample eigenvalues. We present a variant of this result that depends only on a population eigenvalue separation condition, making it more natural and convenient for direct application in statistical contexts, and improving the bounds in some cases. We also provide an extension to situations where the matrices under study may be asymmetric or even non-square, and where interest is in the distance between subspaces spanned by corresponding singular vectors.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {done},
  file = {/home/alex/Zotero/storage/DU9KART3/Yu et al. - 2014 - A useful variant of the Davis--Kahan theorem for s.pdf}
}

@article{yuan_causal_2021,
  title = {Causal {{Network Motifs}}: {{Identifying Heterogeneous Spillover Effects}} in {{A}}/{{B Tests}}},
  shorttitle = {Causal {{Network Motifs}}},
  author = {Yuan, Yuan and Altenburger, Kristen M. and Kooti, Farshad},
  year = {2021},
  month = apr,
  journal = {Proceedings of the Web Conference 2021},
  eprint = {2010.09911},
  eprinttype = {arxiv},
  pages = {3359--3370},
  doi = {10.1145/3442381.3449845},
  abstract = {Randomized experiments, or ``A/B'' tests, remain the gold standard for evaluating the causal effect of a policy intervention or product change. However, experimental settings, such as social networks, where users are interacting and influencing one another, may violate conventional assumptions of no interference for credible causal inference. Existing solutions to the network setting include accounting for the fraction or count of treated neighbors in a user's network, yet most current methods do not account for the local network structure beyond simply counting the number of neighbors. Our study provides an approach that accounts for both the local structure in a user's social network via motifs as well as the treatment assignment conditions of neighbors. We propose a two-part approach. We first introduce and employ ``causal network motifs'', which are network motifs that characterize the assignment conditions in local ego networks; and then we propose a tree-based algorithm for identifying different network interference conditions and estimating their average potential outcomes. Our approach can account for social network theories, such as structural diversity and echo chambers, and also can help specify network interference conditions that are suitable to each experiment. We test our method on a synthetic network setting and on a real-world experiment on a large-scale network, which highlight how accounting for local structures can better account for different interference patterns in networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks,Statistics - Applications},
  file = {/home/alex/Zotero/storage/BK7PG8AT/Yuan et al. - 2021 - Causal Network Motifs Identifying Heterogeneous S.pdf}
}

@article{zajkowski_concentration_2020,
  title = {Concentration of Norms of Random Vectors with Independent P-Sub-Exponential Coordinates},
  author = {Zajkowski, Krzysztof},
  year = {2020},
  month = sep,
  journal = {arXiv:1909.06776 [math]},
  eprint = {1909.06776},
  eprinttype = {arxiv},
  primaryclass = {math},
  abstract = {We present examples of p-sub-exponential random variables for any positive p. We prove two types of concentration of standard p-norms (2-norm is the Euclidean norm) of random vectors with independent p-sub-exponential coordinates around the Lebesgue Lp-norms of these p-norms of random vectors. In the first case p {$\geq$} 1, our estimates depend on the dimension n of random vectors. But in the second one for p {$\geq$} 2, with an additional assumption, we get an estimate that does not depend on n. In other words, we generalize some know concentration results in the Euclidean case to cases of the p-norms of random vectors with independent p-sub-exponential coordinates.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {60E15; 46E30,Mathematics - Probability},
  file = {/home/alex/Zotero/storage/T9IBJFNK/Zajkowski - 2020 - Concentration of norms of random vectors with inde.pdf}
}

@article{zeng_statistical_2021,
  title = {Statistical Methods for Mediation Analysis in the Era of High-Throughput Genomics: {{Current}} Successes and Future Challenges},
  shorttitle = {Statistical Methods for Mediation Analysis in the Era of High-Throughput Genomics},
  author = {Zeng, Ping and Shao, Zhonghe and Zhou, Xiang},
  year = {2021},
  journal = {Computational and Structural Biotechnology Journal},
  volume = {19},
  pages = {3209--3224},
  issn = {20010370},
  doi = {10.1016/j.csbj.2021.05.042},
  abstract = {Mediation analysis investigates the intermediate mechanism through which an exposure exerts its influence on the outcome of interest. Mediation analysis is becoming increasingly popular in high-throughput genomics studies where a common goal is to identify molecular-level traits, such as gene expression or methylation, which actively mediate the genetic or environmental effects on the outcome. Mediation analysis in genomics studies is particularly challenging, however, thanks to the large number of potential mediators measured in these studies as well as the composite null nature of the mediation effect hypothesis. Indeed, while the standard univariate and multivariate mediation methods have been wellestablished for analyzing one or multiple mediators, they are not well-suited for genomics studies with a large number of mediators and often yield conservative p-values and limited power. Consequently, over the past few years many new high-dimensional mediation methods have been developed for analyzing the large number of potential mediators collected in high-throughput genomics studies. In this work, we present a thorough review of these important recent methodological advances in high-dimensional mediation analysis. Specifically, we describe in detail more than ten high-dimensional mediation methods, focusing on their motivations, basic modeling ideas, specific modeling assumptions, practical successes, methodological limitations, as well as future directions. We hope our review will serve as a useful guidance for statisticians and computational biologists who develop methods of highdimensional mediation analysis as well as for analysts who apply mediation methods to highthroughput genomics studies.},
  langid = {english},
  file = {/home/alex/Zotero/storage/VMBK7FRS/Zeng et al. - 2021 - Statistical methods for mediation analysis in the .pdf}
}

@article{zhao_bayesian_2022,
  title = {Bayesian Network Mediation Analysis with Application to Brain Functional Connectome},
  author = {Zhao, Yize and Chen, Tianqi and Cai, Jiachen and Lichenstein, Sarah and Potenza, Marc and Yip, Sarah},
  year = {2022},
  month = jan,
  journal = {arXiv:2201.11695 [stat]},
  eprint = {2201.11695},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Brain functional connectome, the collection of interconnected neural circuits along functional networks, is one of the most cutting edge neuroimaging traits, and has a potential to play a mediating role within the effect pathway between an exposure and an outcome. While existing mediation analytic approaches are capable of providing insight into complex processes, they mainly focus on a univariate mediator or mediator vector, without considering network-variate mediators. To fill the methodological gap and accomplish this exciting and urgent application, in the paper, we propose an integrative mediation analysis under a Bayesian paradigm with networks entailing the mediation effect. To parameterize the network measurements, we introduce individually specified stochastic block models with unknown block allocation, and naturally {${_\ast}$}Correspondence should be directed to: Yize Zhao (yize.zhao@yale.edu), 300 George Street, New Haven, CT 06511.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/HNEDGSKX/Zhao et al. - 2022 - Bayesian network mediation analysis with applicati.pdf}
}

@article{zhao_sparse_2020,
  title = {Sparse {{Principal Component}} Based {{High-Dimensional Mediation Analysis}}},
  author = {Zhao, Yi and Lindquist, Martin A. and Caffo, Brian S.},
  year = {2020},
  month = feb,
  journal = {Computational Statistics \& Data Analysis},
  volume = {142},
  eprint = {1806.06118},
  eprinttype = {arxiv},
  pages = {106835},
  issn = {01679473},
  doi = {10.1016/j.csda.2019.106835},
  abstract = {Causal mediation analysis aims to quantify the intermediate effect of a mediator on the causal pathway from treatment to outcome. With multiple mediators, which are potentially causally dependent, the possible decomposition of pathway effects grows exponentially with the number of mediators. Huang and Pan (2016) introduced a principal component analysis (PCA) based approach to address this challenge, in which the transformed mediators are conditionally independent given the orthogonality of the PCs. However, the transformed mediator PCs, which are linear combinations of original mediators, are difficult to interpret. In this study, we propose a sparse high-dimensional mediation analysis approach by adopting the sparse PCA method introduced by Zou and others (2006) to the mediation setting. We apply the approach to a task-based functional magnetic resonance imaging study, and show that our proposed method is able to detect biologically meaningful results related to the identified mediator.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications},
  file = {/home/alex/Zotero/storage/66KI7B3R/Zhao et al. - 2020 - Sparse Principal Component based High-Dimensional .pdf}
}

@article{zheng_targeted_2012,
  title = {Targeted {{Maximum Likelihood Estimation}} of {{Natural Direct Effects}}},
  author = {Zheng, Wenjing and {van der Laan}, Mark J.},
  year = {2012},
  month = jan,
  journal = {The International Journal of Biostatistics},
  volume = {8},
  number = {1},
  pages = {1--40},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1361},
  abstract = {In many causal inference problems, one is interested in the direct causal effect of an exposure on an outcome of interest that is not mediated by certain intermediate variables. Robins and Greenland (1992) and Pearl (2001) formalized the definition of two types of direct effects (natural and controlled) under the counterfactual framework. The efficient scores (under a nonparametric model) for the various natural effect parameters and their general robustness conditions, as well as an estimating equation based estimator using the efficient score, are provided in Tchetgen Tchetgen and Shpitser (2011b). In this article, we apply the targeted maximum likelihood framework of van der Laan and Rubin (2006) and van der Laan and Rose (2011) to construct a semiparametric efficient, multiply robust, substitution estimator for the natural direct effect which satisfies the efficient score equation derived in Tchetgen Tchetgen and Shpitser (2011b). We note that the robustness conditions in Tchetgen Tchetgen and Shpitser (2011b) may be weakened, thereby placing less reliance on the estimation of the mediator density. More precisely, the proposed estimator is asymptotically unbiased if either one of the following holds: i) the conditional mean outcome given exposure, mediator, and confounders, and the mediated mean outcome difference are consistently estimated; (ii) the exposure mechanism given confounders, and the conditional mean outcome are consistently estimated; or (iii) the exposure mechanism and the mediator density, or the exposure mechanism and the conditional distribution of the exposure given confounders and mediator, are consistently estimated. If all three conditions hold, then the effect estimate is asymptotically efficient. Extensions to the natural indirect effect are also discussed.},
  langid = {english},
  file = {/home/alex/Zotero/storage/6G2CAPB5/Zheng and van der Laan - 2012 - Targeted Maximum Likelihood Estimation of Natural .pdf}
}

@article{zhu_network_2017,
  title = {Network Vector Autoregression},
  author = {Zhu, Xuening and Pan, Rui and Li, Guodong and Liu, Yuewen and Wang, Hansheng},
  year = {2017},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {45},
  number = {3},
  issn = {0090-5364},
  doi = {10.1214/16-AOS1476},
  langid = {english},
  file = {/home/alex/Zotero/storage/GEYJH8QY/Zhu et al. - 2017 - Network vector autoregression.pdf}
}

@article{zhu_network_2021,
  title = {Network {{Functional Varying Coefficient Model}}},
  author = {Zhu, Xuening and Cai, Zhanrui and Ma, Yanyuan},
  year = {2021},
  month = apr,
  journal = {Journal of the American Statistical Association},
  pages = {1--12},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2021.1901718},
  abstract = {We consider functional responses with network dependence observed for each individual at irregular time points. To model both the interindividual dependence and within-individual dynamic correlation, we propose a network functional varying coefficient (NFVC) model. The response of each individual is characterized by a linear combination of responses from its connected nodes and its exogenous covariates. All the model coefficients are allowed to be time dependent. The NFVC model adds to the richness of both the classical network autoregression model and the functional regression models. To overcome the complexity caused by the network interdependence, we devise a special nonparametric least-squarestype estimator, which is feasible when the responses are observed at irregular time points for different individuals. The estimator takes advantage of the sparsity of the network structure to reduce the computational burden. To further conduct the functional principal component analysis, a novel within-individual covariance function estimation method is proposed and studied. Theoretical properties of our estimators, which involve techniques related to empirical processes, nonparametrics, functional data analysis and various concentration inequalities, are analyzed. We analyze a social network dataset to illustrate the powerfulness of the proposed procedure.},
  langid = {english},
  file = {/home/alex/Zotero/storage/QCVEMJZK/Zhu et al. - 2021 - Network Functional Varying Coefficient Model.pdf}
}


